{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SemSeg Pipeline (data.py): https://github.com/HasnainRaz/SemSegPipeline\n",
    "- Semantic Segmentation and the Dataset (prepare dataset): https://d2l.ai/chapter_computer-vision/semantic-segmentation-and-dataset.html\n",
    "- PLC segmentation (custom callback) : https://github.com/ika-rwth-aachen/PCLSegmentation/blob/main/pcl_segmentation/utils/callbacks.py\n",
    "- Human Image Segmentation (data and application ) : https://github.com/nikhilroxtomar/Human-Image-Segmentation-with-DeepLabV3Plus-in-TensorFlow\n",
    "- Deep Resnet and Resnet++ (pytorch) : https://github.com/rishikksh20/ResUnet\n",
    "- Deep Resnet and Resnet++ (original repo and tf) : https://github.com/DebeshJha/ResUNetPlusPlus\n",
    "- Loss functions for image segmentation : https://github.com/JunMa11/SegLoss\n",
    "- Albumentations with tf.data : https://colab.research.google.com/drive/1uUH-asz3CFxlvld8uGx-m3crr4Iepp3u#scrollTo=LWO057_PshWr\n",
    "- DeepLabv3 with (reference_repo) : https://github.com/lattice-ai/DeepLabV3-Plus\n",
    "- tf-segmentation-segmentation (reference_repo) : https://github.com/baudcode/tf-semantic-segmentation/tree/feature/line-detection/tf_semantic_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 09:31:17.655579: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-03 09:31:17.873256: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-03 09:31:17.927189: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-03 09:31:17.927222: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-03 09:31:17.970268: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-03 09:31:18.821043: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-03 09:31:18.821114: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-03 09:31:18.821119: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers import Conv2D,Conv1D\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import initializers\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tf_seg.utils import TensorLike, Tensor, FloatTensorLike,AcceptableDTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_seg.models import resunet_pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 09:31:36.634630: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-10-03 09:31:36.634706: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (yesilyurt): /proc/driver/nvidia/version does not exist\n",
      "2022-10-03 09:31:36.636245: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fb55c35a5b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resunet_pp.ResUnetPlusPlus().build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resunet_pp.ResUnetPlusPlus().build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResUnet++\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 256, 256, 16  448         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 256, 256, 16  64         ['conv2d_41[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_37[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 256, 256, 16  64          ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 256, 256, 16  2320        ['activation_25[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 256, 256, 16  64         ['conv2d_43[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 256, 256, 16  0           ['conv2d_42[0][0]',              \n",
      "                                )                                 'batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7 (Gl  (None, 16)          0           ['add_12[0][0]']                 \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)            (None, 1, 1, 16)     0           ['global_average_pooling2d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 1, 1, 2)      32          ['reshape_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1, 1, 16)     32          ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_10 (Multiply)         (None, 256, 256, 16  0           ['add_12[0][0]',                 \n",
      "                                )                                 'dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 256, 256, 16  64         ['multiply_10[0][0]']            \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_39[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 128, 128, 32  4640        ['activation_26[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 128, 128, 32  128        ['conv2d_44[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_40[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 128, 128, 32  544         ['multiply_10[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 128, 128, 32  9248        ['activation_27[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 128, 128, 32  128        ['conv2d_46[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 128, 128, 32  0           ['conv2d_45[0][0]',              \n",
      "                                )                                 'batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 32)          0           ['add_13[0][0]']                 \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_8 (Reshape)            (None, 1, 1, 32)     0           ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1, 1, 4)      128         ['reshape_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1, 1, 32)     128         ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_11 (Multiply)         (None, 128, 128, 32  0           ['add_13[0][0]',                 \n",
      "                                )                                 'dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 128, 128, 32  128        ['multiply_11[0][0]']            \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_42[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 64, 64, 64)   18496       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 64, 64, 64)  256         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 64, 64, 64)   2112        ['multiply_11[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 64, 64, 64)   36928       ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 64, 64, 64)  256         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 64, 64, 64)   0           ['conv2d_48[0][0]',              \n",
      "                                                                  'batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_9 (Gl  (None, 64)          0           ['add_14[0][0]']                 \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_9 (Reshape)            (None, 1, 1, 64)     0           ['global_average_pooling2d_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 1, 1, 8)      512         ['reshape_9[0][0]']              \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1, 1, 64)     512         ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_12 (Multiply)         (None, 64, 64, 64)   0           ['add_14[0][0]',                 \n",
      "                                                                  'dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 64, 64, 64)  256         ['multiply_12[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 32, 32, 128)  73856       ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 32, 32, 128)  512        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 32, 32, 128)  8320        ['multiply_12[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 32, 32, 128)  147584      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 32, 32, 128)  512        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 32, 32, 128)  0           ['conv2d_51[0][0]',              \n",
      "                                                                  'batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_10 (G  (None, 128)         0           ['add_15[0][0]']                 \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " reshape_10 (Reshape)           (None, 1, 1, 128)    0           ['global_average_pooling2d_10[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 1, 1, 16)     2048        ['reshape_10[0][0]']             \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 1, 1, 128)    2048        ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_13 (Multiply)         (None, 32, 32, 128)  0           ['add_15[0][0]',                 \n",
      "                                                                  'dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 32, 32, 256)  295168      ['multiply_13[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 32, 32, 256)  295168      ['multiply_13[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 32, 32, 256)  295168      ['multiply_13[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 32, 32, 256)  295168      ['multiply_13[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 32, 32, 256)  0           ['batch_normalization_48[0][0]', \n",
      "                                                                  'batch_normalization_49[0][0]', \n",
      "                                                                  'batch_normalization_50[0][0]', \n",
      "                                                                  'batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 64, 64, 64)  256         ['multiply_12[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 32, 32, 256)  65792       ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 64, 64, 256)  147712      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0          ['conv2d_58[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 32, 32, 256)  590080      ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 32, 32, 256)  0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'conv2d_59[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 32, 32, 256)  1024       ['add_17[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 32, 32, 256)  590080      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 32, 32, 256)  0           ['conv2d_60[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_14 (Multiply)         (None, 32, 32, 256)  0           ['activation_35[0][0]',          \n",
      "                                                                  'conv2d_57[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 256)  0          ['multiply_14[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 64, 64, 320)  0           ['up_sampling2d_3[0][0]',        \n",
      "                                                                  'multiply_12[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 64, 64, 320)  1280       ['concatenate_3[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 64, 64, 320)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 64, 64, 128)  368768      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 64, 64, 128)  512        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 64, 64, 128)  41088       ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 64, 64, 128)  147584      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 64, 64, 128)  512        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 64, 64, 128)  0           ['conv2d_62[0][0]',              \n",
      "                                                                  'batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_11 (G  (None, 128)         0           ['add_18[0][0]']                 \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " reshape_11 (Reshape)           (None, 1, 1, 128)    0           ['global_average_pooling2d_11[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 1, 1, 16)     2048        ['reshape_11[0][0]']             \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 1, 1, 128)    2048        ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 128, 128, 32  128        ['multiply_11[0][0]']            \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " multiply_15 (Multiply)         (None, 64, 64, 128)  0           ['add_18[0][0]',                 \n",
      "                                                                  'dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_58[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 64, 64, 128)  512        ['multiply_15[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 128, 128, 12  36992       ['activation_38[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 128)  0          ['conv2d_64[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 64, 64, 128)  147584      ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 64, 64, 128)  0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'conv2d_65[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 64, 64, 128)  512        ['add_19[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 64, 64, 128)  147584      ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 64, 64, 128)  0           ['conv2d_66[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_16 (Multiply)         (None, 64, 64, 128)  0           ['activation_41[0][0]',          \n",
      "                                                                  'multiply_15[0][0]']            \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 12  0          ['multiply_16[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 128, 128, 16  0           ['up_sampling2d_4[0][0]',        \n",
      "                                0)                                'multiply_11[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 128, 128, 16  640        ['concatenate_4[0][0]']          \n",
      " ormalization)                  0)                                                                \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 128, 128, 16  0           ['batch_normalization_61[0][0]'] \n",
      "                                0)                                                                \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 128, 128, 64  92224       ['activation_42[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 128, 128, 64  256        ['conv2d_67[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_62[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 128, 128, 64  10304       ['concatenate_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 128, 128, 64  36928       ['activation_43[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 128, 128, 64  256        ['conv2d_69[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 128, 128, 64  0           ['conv2d_68[0][0]',              \n",
      "                                )                                 'batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_12 (G  (None, 64)          0           ['add_20[0][0]']                 \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " reshape_12 (Reshape)           (None, 1, 1, 64)     0           ['global_average_pooling2d_12[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 1, 1, 8)      512         ['reshape_12[0][0]']             \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 1, 1, 64)     512         ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 256, 256, 16  64         ['multiply_10[0][0]']            \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " multiply_17 (Multiply)         (None, 128, 128, 64  0           ['add_20[0][0]',                 \n",
      "                                )                                 'dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_64[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 128, 128, 64  256        ['multiply_17[0][0]']            \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 256, 256, 64  9280        ['activation_44[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_65[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 128, 128, 64  0          ['conv2d_70[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 128, 128, 64  36928       ['activation_45[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 128, 128, 64  0           ['max_pooling2d_5[0][0]',        \n",
      "                                )                                 'conv2d_71[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 128, 128, 64  256        ['add_21[0][0]']                 \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_66[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 128, 128, 64  36928       ['activation_46[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 128, 128, 64  0           ['conv2d_72[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " multiply_18 (Multiply)         (None, 128, 128, 64  0           ['activation_47[0][0]',          \n",
      "                                )                                 'multiply_17[0][0]']            \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 256, 256, 64  0          ['multiply_18[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 256, 256, 80  0           ['up_sampling2d_5[0][0]',        \n",
      "                                )                                 'multiply_10[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 256, 256, 80  320        ['concatenate_5[0][0]']          \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 256, 256, 80  0           ['batch_normalization_67[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 256, 256, 32  23072       ['activation_48[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 256, 256, 32  128        ['conv2d_73[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 256, 256, 32  0           ['batch_normalization_68[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 256, 256, 32  2592        ['concatenate_5[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 256, 256, 32  9248        ['activation_49[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 256, 256, 32  128        ['conv2d_75[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 256, 256, 32  0           ['conv2d_74[0][0]',              \n",
      "                                )                                 'batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_13 (G  (None, 32)          0           ['add_22[0][0]']                 \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " reshape_13 (Reshape)           (None, 1, 1, 32)     0           ['global_average_pooling2d_13[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 1, 1, 4)      128         ['reshape_13[0][0]']             \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 1, 1, 32)     128         ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_19 (Multiply)         (None, 256, 256, 32  0           ['add_22[0][0]',                 \n",
      "                                )                                 'dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 256, 256, 16  4624        ['multiply_19[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 256, 256, 16  4624        ['multiply_19[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 256, 256, 16  4624        ['multiply_19[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 256, 256, 16  4624        ['multiply_19[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 256, 256, 16  64         ['conv2d_76[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 256, 256, 16  64         ['conv2d_77[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 256, 256, 16  64         ['conv2d_78[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 256, 256, 16  64         ['conv2d_79[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 256, 256, 16  0           ['batch_normalization_70[0][0]', \n",
      "                                )                                 'batch_normalization_71[0][0]', \n",
      "                                                                  'batch_normalization_72[0][0]', \n",
      "                                                                  'batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 256, 256, 16  272         ['add_23[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 256, 256, 1)  17          ['conv2d_80[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,070,385\n",
      "Trainable params: 4,062,993\n",
      "Non-trainable params: 7,392\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute '_attention_block'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attention_block\u001b[49m(np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m3\u001b[39m)), np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m15\u001b[39m)))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute '_attention_block'"
     ]
    }
   ],
   "source": [
    "model._attention_block(np.ones((1, 64, 64, 3)), np.ones((1, 32, 32, 15)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = resunet_pp.ResUnetPlusPlus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fb55c0f0f40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualLayer(Layer):\n",
    "    def __init__(self,n_filter,activation='relu',kernel_size=3,name=\"residual\",**kwargs):\n",
    "        super().__init__(name=name)\n",
    "        assert n_filter is not None ,'n_filter must be specified'\n",
    "\n",
    "        self.activation_name = activation\n",
    "        self.n_filter = n_filter\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "       \n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.activation = keras.layers.Activation(self.activation_name)\n",
    "        \n",
    "        self.conv1 = Conv2D(filters=self.n_filter, kernel_size=self.kernel_size, padding=\"same\",kernel_initializer=initializers.Ones())\n",
    "        self.batch_norm1 = keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv2 = Conv2D(filters=self.n_filter, kernel_size=self.kernel_size,padding=\"same\",kernel_initializer=initializers.Ones())\n",
    "        self.batch_norm2 = keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv_skip = Conv2D(filters=self.n_filter, kernel_size=(1, 1), padding=\"same\",kernel_initializer=initializers.Ones())\n",
    "        self.batch_norm_skip = keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.add = keras.layers.Add()\n",
    "\n",
    "\n",
    "    def call(self,inputs):\n",
    "        \n",
    "        x = self.batch_norm1(inputs)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        x_i = self.conv_skip(inputs)\n",
    "        x_i = self.batch_norm_skip(x_i)\n",
    "        x = self.add([x, x_i])\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_layer = ResidualLayer(n_filter=1, kernel_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = keras.Input((1, 64, 64, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1, 64, 64, 1) dtype=float32 (created by layer 'residual')>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = residual_layer(i)\n",
    "o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=i, outputs=o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1, 64, 64, 3)]    0         \n",
      "                                                                 \n",
      " residual (ResidualLayer)    (None, 1, 64, 64, 1)      30        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 20\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ResidualLayer at 0x7fb4100d1970>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResidualLayer(np.ones((1, 2, 2, 3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dice Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_seg.losses import dice_coef, dice_loss, DiceLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([[1, 0, 1, 0, 0]], dtype=float)\n",
    "p = np.array([[1, 0, 1, 0, 1], [1, 0, 1, 0, 0]], dtype=float)\n",
    "i = 100000\n",
    "p = np.random.choice(2, size=(i)).astype(float)\n",
    "t = np.random.choice(2, size=(i)).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = DiceLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.5006293077604635>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_loss(t, p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from tensorflow.keras.metrics import BinaryAccuracy,binary_accuracy\n",
    "from tensorflow.keras.metrics import MeanMetricWrapper\n",
    "from tensorflow.keras.metrics import MeanIoU,Precision\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_seg.metrics import DiceScore\n",
    "from tf_seg.metrics import MeanMetricWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_score = DiceScore(name=\"dice_score_spece\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([[1, 0, 1, 0, 0]], dtype=float)\n",
    "p = np.array([[1, 0, 1, 0, 1], [1, 0, 1, 0, 0]], dtype=float)\n",
    "i = 100000\n",
    "p = np.random.choice(2, size=(i)).astype(float)\n",
    "t = np.random.choice(2, size=(i)).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_score = MeanIoU(num_classes=2, name=\"mean_iou\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.3309198>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_score(t, p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.49696812>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_score(t, p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.49696812>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_score.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49696812, 1.0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_score.get_weights()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import tensorflow as tf\n",
    "#from tensorflow_addons.image import rotate\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "\n",
    "\n",
    "from tf_seg.data import DataLoader\n",
    "from tf_seg.data import get_camvid_data_loader\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "No training images found  train image length 0 train annot length 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m train_image_paths \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(glob(\u001b[39m\"\u001b[39m\u001b[39m./dataset/camvid/train/*.png\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      6\u001b[0m train_annot_paths \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(glob(\u001b[39m\"\u001b[39m\u001b[39m./dataset/camvid/train_labels/*.png\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m----> 8\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(train_image_paths) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(train_annot_paths) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo training images found  train image length \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(train_image_paths)\u001b[39m}\u001b[39;00m\u001b[39m train annot length \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(train_annot_paths)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: No training images found  train image length 0 train annot length 0"
     ]
    }
   ],
   "source": [
    "# train_image_paths = glob(\"./dataset_v1.0/train_image/*.jpg\")\n",
    "# train_annot_paths = glob(\"./dataset_v1.0/train_annot/*.jpg\")\n",
    "\n",
    "# camvid\n",
    "train_image_paths = sorted(glob(\"./dataset/camvid/train/*.png\"))\n",
    "train_annot_paths = sorted(glob(\"./dataset/camvid/train_labels/*.png\"))\n",
    "\n",
    "assert len(train_image_paths) > 0 and len(train_annot_paths) > 0, f\"No training images found  train image length {len(train_image_paths)} train annot length {len(train_annot_paths)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_annot_paths[:3], train_image_paths[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://storage.googleapis.com/kaggle-data-sets/635428/1132317/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20221006%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20221006T152140Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=2c7e207916903eafc1e58493d3b54304b271a1e6699796219be1de5e7b4f919da977d244432b3b1b0c4539e3c732de920f572028bbb923cae8b12a87f03acc6d4dbf0d6778dd62acaf4a54e39112f1c573316666128591073b34756c441cbc95244ec86df3c69f5ab0eee10ea744776a95f66a2e4e0e6ed01050529c3baa48886fbdbd1495e6b9f392adb9ea1f5d02ed5b58bacf73d8055f4795c914766a8ee85615a575e73fd628baddab50b7b205e8eba31ec5ab6a91322b818ed408bb09b55ad384098c58f988c4c385106793889ebb1bfc1fca234c2caecf35f5b7861f650c2d14ec90ebd7f49c9a2d300b40fa95ba6ce552fcf2eb874b164934ec0c15c4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib.request.urlretrieve(url, filename=\"deneme.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(data_name: str):\n",
    "    \"\"\" Downloads the specified dataset.\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    downloader = getattr(dataset, f\"download_{data_name}_dataset\")\n",
    "    downloader()\n",
    "    # os.remove(\"deneme.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_seg.data.dataset import download_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data(\"camvid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Road,128, 64, 128\n",
    "# RoadShoulder,128, 128, 192\n",
    "# Sidewalk,0, 0, 192\n",
    "# SignSymbol,192, 128, 128\n",
    "# Sky,128, 128, 128\n",
    "\n",
    "CLASSES = [\"Road\", \"Sky\"]\n",
    "palette = [(128, 64, 128), (128, 128, 128)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_loader = DataLoader(train_image_paths, train_annot_paths, image_size=(512, 512), output_type=(tf.float32, tf.float32),one_hot_encoding=True,channels = (3,3),palette=palette,background_adding=True)\n",
    "\n",
    "#dataset = data_loader.load_data(batch_size=12,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (i,m)  in dataset.take(3):\n",
    "#     #plt.imshow(i.numpy().astype(int))\n",
    "#     plt.subplot(1,2,1)\n",
    "#     plt.imshow(tf.cast(i,tf.uint8))\n",
    "#     plt.subplot(1,2,2)\n",
    "#     plt.imshow(m)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 20:46:33.120921: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-03 20:46:33.248106: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-03 20:46:33.252986: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-03 20:46:33.252999: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-03 20:46:33.275057: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-03 20:46:33.866503: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-03 20:46:33.866556: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-03 20:46:33.866561: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds.load(\"oxford_iiit_pet:3.*.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_SIZE = 512\n",
    "BATCH_SIZE = 12\n",
    "\n",
    "transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(IM_SIZE, IM_SIZE),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.HorizontalFlip(),\n",
    "                A.VerticalFlip(),\n",
    "            ],\n",
    "            p=0.3,\n",
    "        ),\n",
    "        A.RandomRotate90(),\n",
    "        # A.RandomGridShuffle(grid=(3, 3), always_apply=False, p=0.5),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, always_apply=False, p=0.5),\n",
    "        # A.Cutout(num_holes=8, max_h_size=8, max_w_size=8, fill_value=0, always_apply=False, p=0.5),\n",
    "        A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), always_apply=False, p=0.5),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomBrightnessContrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbrightness_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcontrast_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbrightness_by_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0malways_apply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mRandomBrightnessContrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImageOnlyTransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Randomly change brightness and contrast of the input image.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m        brightness_limit ((float, float) or float): factor range for changing brightness.\u001b[0m\n",
      "\u001b[0;34m            If limit is a single float, the range will be (-limit, limit). Default: (-0.2, 0.2).\u001b[0m\n",
      "\u001b[0;34m        contrast_limit ((float, float) or float): factor range for changing contrast.\u001b[0m\n",
      "\u001b[0;34m            If limit is a single float, the range will be (-limit, limit). Default: (-0.2, 0.2).\u001b[0m\n",
      "\u001b[0;34m        brightness_by_max (Boolean): If True adjust contrast by image dtype maximum,\u001b[0m\n",
      "\u001b[0;34m            else adjust contrast by image mean.\u001b[0m\n",
      "\u001b[0;34m        p (float): probability of applying the transform. Default: 0.5.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Targets:\u001b[0m\n",
      "\u001b[0;34m        image\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Image types:\u001b[0m\n",
      "\u001b[0;34m        uint8, float32\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mbrightness_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcontrast_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mbrightness_by_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0malways_apply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomBrightnessContrast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrightness_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrightness_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrast_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrast_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrightness_by_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrightness_by_max\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrightness_contrast_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrightness_by_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"alpha\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrast_limit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrast_limit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"beta\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrightness_limit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrightness_limit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mget_transform_init_args_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"brightness_limit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"contrast_limit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"brightness_by_max\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/tf_seg/lib/python3.9/site-packages/albumentations/augmentations/transforms.py\n",
      "\u001b[0;31mType:\u001b[0m           SerializableMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     RandomBrightness, RandomContrast\n"
     ]
    }
   ],
   "source": [
    "A.RandomBrightnessContrast??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_albument(image, mask):\n",
    "    data = {\"image\": image, \"mask\": mask}\n",
    "    data = transforms(**data)\n",
    "    image = data[\"image\"]\n",
    "    mask = data[\"mask\"]\n",
    "    # image = tf.cast(image/255., tf.float32)\n",
    "    return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def process_data(image, mask):\n",
    "    aug_img, aug_mask = tf.numpy_function(func=aug_albument, inp=[image, mask], Tout=[tf.uint8, tf.uint8])\n",
    "    return aug_img, aug_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mimage_paths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmask_paths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mimage_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mchannels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moutput_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'loader'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnormalizing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mone_hot_encoding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpalette\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbackground_adding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "A TensorFlow Dataset API based loader for semantic segmentation problems.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "- https://github.com/HasnainRaz/SemSegPipeline/blob/master/dataloader.py\n",
      "\u001b[0;31mInit docstring:\u001b[0m\n",
      "Initializes the data loader object\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "image_paths : List[str]\n",
      "    List of paths of train images.\n",
      "mask_paths : List[str]\n",
      "    List of paths of train masks (segmentation masks)\n",
      "image_size : Tuple[int]\n",
      "    Tuple, the final height, width of the loaded images.\n",
      "extensions : Tuple[str]\n",
      "    Tuple, the extensions of the images.\n",
      "channels : Tuple[int]\n",
      "    Tuple of ints, image and mask channels.,\n",
      "output_type : Tuple[tf.DType]\n",
      "    Tuple of tf.DType, the output type of the images and masks.\n",
      "name : str, optional\n",
      "    Name of the loader, by default \"loader\"\n",
      "normalizing : bool\n",
      "    Boolean, if True, the images and masks are normalized to [0, 1].\n",
      "pallette : Tuple[int]\n",
      "    Tuple of ints, the color pallette of the images and masks.\n",
      "one_hot_encoding : bool\n",
      "    If True, one hot encodes the masks.\n",
      "background_adding : bool\n",
      "    If True, adds the background class to the mask.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Desktop/tf_seg/tf_seg/data/data.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(\n",
    "    train_image_paths, train_annot_paths, image_size=(512, 512), batch_size=1,output_type=(tf.uint8, tf.float32), one_hot_encoding=True, channels=(3, 3), palette=palette, background_adding=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data_loader.load_data(batch_size=20, shuffle=True, transform_func=process_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t():\n",
    "    for (i, m) in train_dataset.take(100):\n",
    "        pass\n",
    "        # print(i.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-21 10:32:31.094677: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 1.8914273 ,  1.8914273 ,  1.8771276 ],\n",
      "        [ 1.8914273 ,  1.8914273 ,  1.8914273 ],\n",
      "        [ 1.8914273 ,  1.8914273 ,  1.8914273 ],\n",
      "        ...,\n",
      "        [-0.6825015 , -0.61100346, -0.5681047 ],\n",
      "        [-0.63960266, -0.55380505, -0.5109062 ],\n",
      "        [-0.63960266, -0.55380505, -0.52520585]],\n",
      "\n",
      "       [[ 1.8914273 ,  1.8914273 ,  1.8914273 ],\n",
      "        [ 1.8056296 ,  1.8056296 ,  1.8342288 ],\n",
      "        [ 1.7770303 ,  1.7627308 ,  1.8199292 ],\n",
      "        ...,\n",
      "        [-0.6825015 , -0.5967039 , -0.5681047 ],\n",
      "        [-0.6539023 , -0.58240426, -0.52520585],\n",
      "        [-0.63960266, -0.55380505, -0.5109062 ]],\n",
      "\n",
      "       [[ 1.7627308 ,  1.7341316 ,  1.8485284 ],\n",
      "        [ 1.3766415 ,  1.3194431 ,  1.6197348 ],\n",
      "        [ 1.6197348 ,  1.5911355 ,  1.8056296 ],\n",
      "        ...,\n",
      "        [-0.6825015 , -0.5967039 , -0.5681047 ],\n",
      "        [-0.66820186, -0.58240426, -0.5395054 ],\n",
      "        [-0.6539023 , -0.5681047 , -0.55380505]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 1.576836  ,  1.5911355 ,  1.6340344 ],\n",
      "        [ 1.5625364 ,  1.5911355 ,  1.6054351 ],\n",
      "        [ 1.79133   ,  1.8199292 ,  1.7770303 ],\n",
      "        ...,\n",
      "        [-0.4251086 , -0.3965094 , -0.3965094 ],\n",
      "        [-0.3822098 , -0.3822098 , -0.3822098 ],\n",
      "        [-0.410809  , -0.3965094 , -0.3965094 ]],\n",
      "\n",
      "       [[ 1.3194431 ,  1.3337426 ,  1.4767387 ],\n",
      "        [ 1.1478478 ,  1.2193458 ,  1.2336454 ],\n",
      "        [ 0.5901633 ,  0.69026047,  0.561564  ],\n",
      "        ...,\n",
      "        [-0.3965094 , -0.3822098 , -0.3822098 ],\n",
      "        [-0.410809  , -0.3965094 , -0.3965094 ],\n",
      "        [-0.4251086 , -0.410809  , -0.410809  ]],\n",
      "\n",
      "       [[ 0.7045601 ,  0.7188597 ,  0.961953  ],\n",
      "        [ 0.86185575,  0.91905415,  1.0191513 ],\n",
      "        [ 1.5482367 ,  1.5911355 ,  1.576836  ],\n",
      "        ...,\n",
      "        [-0.3822098 , -0.3679102 , -0.3679102 ],\n",
      "        [-0.410809  , -0.410809  , -0.410809  ],\n",
      "        [-0.4251086 , -0.410809  , -0.410809  ]]], dtype=float32)>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n",
      "    outputs = [\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n",
      "    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n",
      "    return ops.convert_to_tensor(value, dtype=dtype)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 1.8914273 ,  1.8914273 ,  1.8771276 ],\n",
      "        [ 1.8914273 ,  1.8914273 ,  1.8914273 ],\n",
      "        [ 1.8914273 ,  1.8914273 ,  1.8914273 ],\n",
      "        ...,\n",
      "        [-0.6825015 , -0.61100346, -0.5681047 ],\n",
      "        [-0.63960266, -0.55380505, -0.5109062 ],\n",
      "        [-0.63960266, -0.55380505, -0.52520585]],\n",
      "\n",
      "       [[ 1.8914273 ,  1.8914273 ,  1.8914273 ],\n",
      "        [ 1.8056296 ,  1.8056296 ,  1.8342288 ],\n",
      "        [ 1.7770303 ,  1.7627308 ,  1.8199292 ],\n",
      "        ...,\n",
      "        [-0.6825015 , -0.5967039 , -0.5681047 ],\n",
      "        [-0.6539023 , -0.58240426, -0.52520585],\n",
      "        [-0.63960266, -0.55380505, -0.5109062 ]],\n",
      "\n",
      "       [[ 1.7627308 ,  1.7341316 ,  1.8485284 ],\n",
      "        [ 1.3766415 ,  1.3194431 ,  1.6197348 ],\n",
      "        [ 1.6197348 ,  1.5911355 ,  1.8056296 ],\n",
      "        ...,\n",
      "        [-0.6825015 , -0.5967039 , -0.5681047 ],\n",
      "        [-0.66820186, -0.58240426, -0.5395054 ],\n",
      "        [-0.6539023 , -0.5681047 , -0.55380505]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 1.576836  ,  1.5911355 ,  1.6340344 ],\n",
      "        [ 1.5625364 ,  1.5911355 ,  1.6054351 ],\n",
      "        [ 1.79133   ,  1.8199292 ,  1.7770303 ],\n",
      "        ...,\n",
      "        [-0.4251086 , -0.3965094 , -0.3965094 ],\n",
      "        [-0.3822098 , -0.3822098 , -0.3822098 ],\n",
      "        [-0.410809  , -0.3965094 , -0.3965094 ]],\n",
      "\n",
      "       [[ 1.3194431 ,  1.3337426 ,  1.4767387 ],\n",
      "        [ 1.1478478 ,  1.2193458 ,  1.2336454 ],\n",
      "        [ 0.5901633 ,  0.69026047,  0.561564  ],\n",
      "        ...,\n",
      "        [-0.3965094 , -0.3822098 , -0.3822098 ],\n",
      "        [-0.410809  , -0.3965094 , -0.3965094 ],\n",
      "        [-0.4251086 , -0.410809  , -0.410809  ]],\n",
      "\n",
      "       [[ 0.7045601 ,  0.7188597 ,  0.961953  ],\n",
      "        [ 0.86185575,  0.91905415,  1.0191513 ],\n",
      "        [ 1.5482367 ,  1.5911355 ,  1.576836  ],\n",
      "        ...,\n",
      "        [-0.3822098 , -0.3679102 , -0.3679102 ],\n",
      "        [-0.410809  , -0.410809  , -0.410809  ],\n",
      "        [-0.4251086 , -0.410809  , -0.410809  ]]], dtype=float32)>\n",
      "\n",
      "\n",
      "2022-09-21 10:32:31.103304: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[-3.3483422e-01, -3.3483422e-01, -3.0699056e-01],\n",
      "        [-4.1836518e-01, -4.3228701e-01, -4.0444335e-01],\n",
      "        [-4.6013066e-01, -4.6013066e-01, -4.0444335e-01],\n",
      "        ...,\n",
      "        [-9.0562916e-01, -8.9170730e-01, -8.9170730e-01],\n",
      "        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01],\n",
      "        [-8.6386365e-01, -8.4994185e-01, -8.4994185e-01]],\n",
      "\n",
      "       [[-9.8163158e-02, -9.8163158e-02, -9.8163158e-02],\n",
      "        [-2.9306874e-01, -3.0699056e-01, -3.0699056e-01],\n",
      "        [-4.6013066e-01, -4.6013066e-01, -4.3228701e-01],\n",
      "        ...,\n",
      "        [-9.3347281e-01, -9.1955096e-01, -9.1955096e-01],\n",
      "        [-8.9170730e-01, -8.7778550e-01, -8.7778550e-01],\n",
      "        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01]],\n",
      "\n",
      "       [[-7.1036670e-04, -7.1036670e-04, -2.8554022e-02],\n",
      "        [-2.8554022e-02, -2.8554022e-02, -5.6397676e-02],\n",
      "        [-3.3483422e-01, -3.3483422e-01, -3.6267787e-01],\n",
      "        ...,\n",
      "        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01],\n",
      "        [-8.4994185e-01, -8.3601999e-01, -8.3601999e-01],\n",
      "        [-8.9170730e-01, -8.6386365e-01, -8.6386365e-01]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-7.3856723e-01, -6.8287992e-01, -6.4111441e-01],\n",
      "        [-7.1072358e-01, -6.5503627e-01, -6.1327076e-01],\n",
      "        [-6.6895807e-01, -6.1327076e-01, -5.7150531e-01],\n",
      "        ...,\n",
      "        [-2.2345960e-01, -2.7914691e-01, -3.3483422e-01],\n",
      "        [-1.8169412e-01, -2.5130326e-01, -2.7914691e-01],\n",
      "        [-1.6777229e-01, -2.5130326e-01, -2.7914691e-01]],\n",
      "\n",
      "       [[-8.2209820e-01, -7.5248903e-01, -7.2464538e-01],\n",
      "        [-7.8033268e-01, -7.2464538e-01, -6.8287992e-01],\n",
      "        [-7.2464538e-01, -6.6895807e-01, -6.2719262e-01],\n",
      "        ...,\n",
      "        [-1.8169412e-01, -2.2345960e-01, -3.3483422e-01],\n",
      "        [-2.7914691e-01, -3.3483422e-01, -4.1836518e-01],\n",
      "        [-1.3992864e-01, -2.0953777e-01, -2.7914691e-01]],\n",
      "\n",
      "       [[-8.0817634e-01, -7.5248903e-01, -7.1072358e-01],\n",
      "        [-7.9425454e-01, -7.3856723e-01, -6.9680172e-01],\n",
      "        [-7.5248903e-01, -6.8287992e-01, -6.6895807e-01],\n",
      "        ...,\n",
      "        [-7.1036670e-04, -4.2475849e-02, -1.5385047e-01],\n",
      "        [-2.5130326e-01, -2.9306874e-01, -4.0444335e-01],\n",
      "        [-2.5130326e-01, -3.2091239e-01, -4.1836518e-01]]], dtype=float32)>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n",
      "    outputs = [\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n",
      "    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n",
      "    return ops.convert_to_tensor(value, dtype=dtype)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[-3.3483422e-01, -3.3483422e-01, -3.0699056e-01],\n",
      "        [-4.1836518e-01, -4.3228701e-01, -4.0444335e-01],\n",
      "        [-4.6013066e-01, -4.6013066e-01, -4.0444335e-01],\n",
      "        ...,\n",
      "        [-9.0562916e-01, -8.9170730e-01, -8.9170730e-01],\n",
      "        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01],\n",
      "        [-8.6386365e-01, -8.4994185e-01, -8.4994185e-01]],\n",
      "\n",
      "       [[-9.8163158e-02, -9.8163158e-02, -9.8163158e-02],\n",
      "        [-2.9306874e-01, -3.0699056e-01, -3.0699056e-01],\n",
      "        [-4.6013066e-01, -4.6013066e-01, -4.3228701e-01],\n",
      "        ...,\n",
      "        [-9.3347281e-01, -9.1955096e-01, -9.1955096e-01],\n",
      "        [-8.9170730e-01, -8.7778550e-01, -8.7778550e-01],\n",
      "        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01]],\n",
      "\n",
      "       [[-7.1036670e-04, -7.1036670e-04, -2.8554022e-02],\n",
      "        [-2.8554022e-02, -2.8554022e-02, -5.6397676e-02],\n",
      "        [-3.3483422e-01, -3.3483422e-01, -3.6267787e-01],\n",
      "        ...,\n",
      "        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01],\n",
      "        [-8.4994185e-01, -8.3601999e-01, -8.3601999e-01],\n",
      "        [-8.9170730e-01, -8.6386365e-01, -8.6386365e-01]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-7.3856723e-01, -6.8287992e-01, -6.4111441e-01],\n",
      "        [-7.1072358e-01, -6.5503627e-01, -6.1327076e-01],\n",
      "        [-6.6895807e-01, -6.1327076e-01, -5.7150531e-01],\n",
      "        ...,\n",
      "        [-2.2345960e-01, -2.7914691e-01, -3.3483422e-01],\n",
      "        [-1.8169412e-01, -2.5130326e-01, -2.7914691e-01],\n",
      "        [-1.6777229e-01, -2.5130326e-01, -2.7914691e-01]],\n",
      "\n",
      "       [[-8.2209820e-01, -7.5248903e-01, -7.2464538e-01],\n",
      "        [-7.8033268e-01, -7.2464538e-01, -6.8287992e-01],\n",
      "        [-7.2464538e-01, -6.6895807e-01, -6.2719262e-01],\n",
      "        ...,\n",
      "        [-1.8169412e-01, -2.2345960e-01, -3.3483422e-01],\n",
      "        [-2.7914691e-01, -3.3483422e-01, -4.1836518e-01],\n",
      "        [-1.3992864e-01, -2.0953777e-01, -2.7914691e-01]],\n",
      "\n",
      "       [[-8.0817634e-01, -7.5248903e-01, -7.1072358e-01],\n",
      "        [-7.9425454e-01, -7.3856723e-01, -6.9680172e-01],\n",
      "        [-7.5248903e-01, -6.8287992e-01, -6.6895807e-01],\n",
      "        ...,\n",
      "        [-7.1036670e-04, -4.2475849e-02, -1.5385047e-01],\n",
      "        [-2.5130326e-01, -2.9306874e-01, -4.0444335e-01],\n",
      "        [-2.5130326e-01, -3.2091239e-01, -4.1836518e-01]]], dtype=float32)>\n",
      "\n",
      "\n",
      "2022-09-21 10:32:31.104280: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 1.3783756 ,  1.3916041 ,  1.3386906 ],\n",
      "        [ 1.3916041 ,  1.3916041 ,  1.3916041 ],\n",
      "        [ 1.3916041 ,  1.3916041 ,  1.3916041 ],\n",
      "        ...,\n",
      "        [-0.3413106 , -0.14288525,  0.611131  ],\n",
      "        [ 0.90215486,  1.0873518 ,  1.3651474 ],\n",
      "        [ 0.6508161 ,  1.0344384 ,  1.1799504 ]],\n",
      "\n",
      "       [[ 0.981525  ,  0.981525  ,  0.99475336],\n",
      "        [ 1.3519189 ,  1.3519189 ,  1.3519189 ],\n",
      "        [ 1.3916041 ,  1.3916041 ,  1.3916041 ],\n",
      "        ...,\n",
      "        [-0.39422402, -0.19579868,  0.69050115],\n",
      "        [-0.2751688 , -0.06351512,  0.611131  ],\n",
      "        [ 0.38624898,  0.59790266,  0.8624698 ]],\n",
      "\n",
      "       [[ 1.1005802 ,  1.1005802 ,  1.0079817 ],\n",
      "        [ 1.3916041 ,  1.3783756 ,  1.3122339 ],\n",
      "        [ 1.3916041 ,  1.3916041 ,  1.3783756 ],\n",
      "        ...,\n",
      "        [ 1.1270369 ,  1.3386906 ,  1.3916041 ],\n",
      "        [-0.15611361,  0.09522515,  0.75664294],\n",
      "        [ 0.75664294,  0.90215486,  1.2328638 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 1.2990055 ,  1.2593205 ,  1.1931787 ],\n",
      "        [ 1.2725488 ,  1.2328638 ,  1.1534936 ],\n",
      "        [ 1.2196354 ,  1.1799504 ,  1.1005802 ],\n",
      "        ...,\n",
      "        [-0.9762717 , -0.92335826, -0.9365866 ],\n",
      "        [-1.174697  , -1.1217836 , -1.1350119 ],\n",
      "        [-1.0556418 , -1.0027283 , -1.0159568 ]],\n",
      "\n",
      "       [[ 1.1931787 ,  1.1402652 ,  1.1005802 ],\n",
      "        [ 1.0476668 ,  1.0079817 ,  0.94183993],\n",
      "        [ 1.0476668 ,  1.0079817 ,  0.9286116 ],\n",
      "        ...,\n",
      "        [-0.9101299 , -0.8572165 , -0.8572165 ],\n",
      "        [-0.9365866 , -0.8836732 , -0.8836732 ],\n",
      "        [-1.0027283 , -0.949815  , -0.949815  ]],\n",
      "\n",
      "       [[ 1.2593205 ,  1.2064071 ,  1.1667219 ],\n",
      "        [ 1.0873518 ,  1.0344384 ,  0.99475336],\n",
      "        [ 1.1402652 ,  1.0873518 ,  1.0344384 ],\n",
      "        ...,\n",
      "        [-1.0556418 , -1.0027283 , -1.0159568 ],\n",
      "        [-0.7249329 , -0.6720195 , -0.68524784],\n",
      "        [-0.92335826, -0.8572165 , -0.87044483]]], dtype=float32)>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n",
      "    outputs = [\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n",
      "    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n",
      "    return ops.convert_to_tensor(value, dtype=dtype)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 1.3783756 ,  1.3916041 ,  1.3386906 ],\n",
      "        [ 1.3916041 ,  1.3916041 ,  1.3916041 ],\n",
      "        [ 1.3916041 ,  1.3916041 ,  1.3916041 ],\n",
      "        ...,\n",
      "        [-0.3413106 , -0.14288525,  0.611131  ],\n",
      "        [ 0.90215486,  1.0873518 ,  1.3651474 ],\n",
      "        [ 0.6508161 ,  1.0344384 ,  1.1799504 ]],\n",
      "\n",
      "       [[ 0.981525  ,  0.981525  ,  0.99475336],\n",
      "        [ 1.3519189 ,  1.3519189 ,  1.3519189 ],\n",
      "        [ 1.3916041 ,  1.3916041 ,  1.3916041 ],\n",
      "        ...,\n",
      "        [-0.39422402, -0.19579868,  0.69050115],\n",
      "        [-0.2751688 , -0.06351512,  0.611131  ],\n",
      "        [ 0.38624898,  0.59790266,  0.8624698 ]],\n",
      "\n",
      "       [[ 1.1005802 ,  1.1005802 ,  1.0079817 ],\n",
      "        [ 1.3916041 ,  1.3783756 ,  1.3122339 ],\n",
      "        [ 1.3916041 ,  1.3916041 ,  1.3783756 ],\n",
      "        ...,\n",
      "        [ 1.1270369 ,  1.3386906 ,  1.3916041 ],\n",
      "        [-0.15611361,  0.09522515,  0.75664294],\n",
      "        [ 0.75664294,  0.90215486,  1.2328638 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 1.2990055 ,  1.2593205 ,  1.1931787 ],\n",
      "        [ 1.2725488 ,  1.2328638 ,  1.1534936 ],\n",
      "        [ 1.2196354 ,  1.1799504 ,  1.1005802 ],\n",
      "        ...,\n",
      "        [-0.9762717 , -0.92335826, -0.9365866 ],\n",
      "        [-1.174697  , -1.1217836 , -1.1350119 ],\n",
      "        [-1.0556418 , -1.0027283 , -1.0159568 ]],\n",
      "\n",
      "       [[ 1.1931787 ,  1.1402652 ,  1.1005802 ],\n",
      "        [ 1.0476668 ,  1.0079817 ,  0.94183993],\n",
      "        [ 1.0476668 ,  1.0079817 ,  0.9286116 ],\n",
      "        ...,\n",
      "        [-0.9101299 , -0.8572165 , -0.8572165 ],\n",
      "        [-0.9365866 , -0.8836732 , -0.8836732 ],\n",
      "        [-1.0027283 , -0.949815  , -0.949815  ]],\n",
      "\n",
      "       [[ 1.2593205 ,  1.2064071 ,  1.1667219 ],\n",
      "        [ 1.0873518 ,  1.0344384 ,  0.99475336],\n",
      "        [ 1.1402652 ,  1.0873518 ,  1.0344384 ],\n",
      "        ...,\n",
      "        [-1.0556418 , -1.0027283 , -1.0159568 ],\n",
      "        [-0.7249329 , -0.6720195 , -0.68524784],\n",
      "        [-0.92335826, -0.8572165 , -0.87044483]]], dtype=float32)>\n",
      "\n",
      "\n",
      "2022-09-21 10:32:31.105287: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        [ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        [ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        ...,\n",
      "        [ 1.2350588 ,  1.3025639 ,  1.4206978 ],\n",
      "        [ 1.6232132 ,  1.6400895 ,  1.6400895 ],\n",
      "        [-0.03066242, -0.55382717,  0.45874977]],\n",
      "\n",
      "       [[ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        [ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        [ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        ...,\n",
      "        [ 1.5894606 ,  1.606337  ,  1.606337  ],\n",
      "        [ 1.555708  ,  1.6400895 ,  1.6400895 ],\n",
      "        [-0.18254897, -0.72258997,  0.12122411]],\n",
      "\n",
      "       [[ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        [ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        [ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        ...,\n",
      "        [ 1.5388318 ,  1.6400895 ,  1.6232132 ],\n",
      "        [ 1.6400895 ,  1.6400895 ,  1.6400895 ],\n",
      "        [-0.11504383, -0.6719611 ,  0.07059527]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.77321887, -0.75634253, -0.73946625],\n",
      "        [-0.75634253, -0.75634253, -0.73946625],\n",
      "        [-0.79009515, -0.79009515, -0.73946625],\n",
      "        ...,\n",
      "        [ 0.2393581 ,  0.34061578,  0.49250233],\n",
      "        [ 0.12122411,  0.25623438,  0.35749206],\n",
      "        [ 0.12122411,  0.25623438,  0.28998694]],\n",
      "\n",
      "       [[-0.75634253, -0.75634253, -0.72258997],\n",
      "        [-0.77321887, -0.77321887, -0.75634253],\n",
      "        [-0.77321887, -0.77321887, -0.72258997],\n",
      "        ...,\n",
      "        [ 0.17185296,  0.25623438,  0.4081209 ],\n",
      "        [ 0.34061578,  0.45874977,  0.59376   ],\n",
      "        [ 0.18872924,  0.3237395 ,  0.4081209 ]],\n",
      "\n",
      "       [[-0.72258997, -0.72258997, -0.6888374 ],\n",
      "        [-0.75634253, -0.75634253, -0.73946625],\n",
      "        [-0.77321887, -0.77321887, -0.72258997],\n",
      "        ...,\n",
      "        [-0.5369509 , -0.48632205, -0.3175592 ],\n",
      "        [ 0.25623438,  0.35749206,  0.5093786 ],\n",
      "        [ 0.2393581 ,  0.37436834,  0.47562605]]], dtype=float32)>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n",
      "    outputs = [\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n",
      "    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n",
      "    return ops.convert_to_tensor(value, dtype=dtype)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        [ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        [ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        ...,\n",
      "        [ 1.2350588 ,  1.3025639 ,  1.4206978 ],\n",
      "        [ 1.6232132 ,  1.6400895 ,  1.6400895 ],\n",
      "        [-0.03066242, -0.55382717,  0.45874977]],\n",
      "\n",
      "       [[ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        [ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        [ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        ...,\n",
      "        [ 1.5894606 ,  1.606337  ,  1.606337  ],\n",
      "        [ 1.555708  ,  1.6400895 ,  1.6400895 ],\n",
      "        [-0.18254897, -0.72258997,  0.12122411]],\n",
      "\n",
      "       [[ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        [ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        [ 1.4713267 ,  1.6400895 ,  1.6400895 ],\n",
      "        ...,\n",
      "        [ 1.5388318 ,  1.6400895 ,  1.6232132 ],\n",
      "        [ 1.6400895 ,  1.6400895 ,  1.6400895 ],\n",
      "        [-0.11504383, -0.6719611 ,  0.07059527]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.77321887, -0.75634253, -0.73946625],\n",
      "        [-0.75634253, -0.75634253, -0.73946625],\n",
      "        [-0.79009515, -0.79009515, -0.73946625],\n",
      "        ...,\n",
      "        [ 0.2393581 ,  0.34061578,  0.49250233],\n",
      "        [ 0.12122411,  0.25623438,  0.35749206],\n",
      "        [ 0.12122411,  0.25623438,  0.28998694]],\n",
      "\n",
      "       [[-0.75634253, -0.75634253, -0.72258997],\n",
      "        [-0.77321887, -0.77321887, -0.75634253],\n",
      "        [-0.77321887, -0.77321887, -0.72258997],\n",
      "        ...,\n",
      "        [ 0.17185296,  0.25623438,  0.4081209 ],\n",
      "        [ 0.34061578,  0.45874977,  0.59376   ],\n",
      "        [ 0.18872924,  0.3237395 ,  0.4081209 ]],\n",
      "\n",
      "       [[-0.72258997, -0.72258997, -0.6888374 ],\n",
      "        [-0.75634253, -0.75634253, -0.73946625],\n",
      "        [-0.77321887, -0.77321887, -0.72258997],\n",
      "        ...,\n",
      "        [-0.5369509 , -0.48632205, -0.3175592 ],\n",
      "        [ 0.25623438,  0.35749206,  0.5093786 ],\n",
      "        [ 0.2393581 ,  0.37436834,  0.47562605]]], dtype=float32)>\n",
      "\n",
      "\n",
      "2022-09-21 10:32:31.111724: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 0.9442201 ,  0.4934756 ,  0.04273105],\n",
      "        [ 1.3593795 ,  0.89677334,  0.3629969 ],\n",
      "        [ 1.5610285 ,  1.3356562 ,  0.7544329 ],\n",
      "        ...,\n",
      "        [ 1.027252  ,  1.3356562 ,  1.3356562 ],\n",
      "        [ 1.027252  ,  1.3356562 ,  1.3356562 ],\n",
      "        [ 1.027252  ,  1.3356562 ,  1.3356562 ]],\n",
      "\n",
      "       [[ 1.2051774 ,  0.77815634,  0.42230538],\n",
      "        [ 1.0509754 ,  0.7069861 ,  0.16134803],\n",
      "        [ 1.5610285 ,  1.50172   ,  0.9204967 ],\n",
      "        ...,\n",
      "        [ 0.908635  ,  1.3356562 ,  1.3356562 ],\n",
      "        [ 0.908635  ,  1.3356562 ,  1.3356562 ],\n",
      "        [ 0.908635  ,  1.3356562 ,  1.3356562 ]],\n",
      "\n",
      "       [[ 1.5610285 ,  1.3119327 ,  0.908635  ],\n",
      "        [ 0.5053373 ,  0.17320973, -0.41987517],\n",
      "        [ 0.81374145,  0.4104437 , -0.01657744],\n",
      "        ...,\n",
      "        [ 0.908635  ,  1.3356562 ,  1.3356562 ],\n",
      "        [ 0.908635  ,  1.3356562 ,  1.3356562 ],\n",
      "        [ 0.908635  ,  1.3356562 ,  1.3356562 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.8824814 , -0.8468963 , -0.8468963 ],\n",
      "        [-1.0248218 , -0.98923665, -0.8706197 ],\n",
      "        [-0.8706197 , -0.8706197 , -0.7638644 ],\n",
      "        ...,\n",
      "        [-0.8943431 , -0.7994495 , -0.5978006 ],\n",
      "        [-0.7520027 , -0.62152404, -0.50290704],\n",
      "        [-1.0010984 , -0.8706197 , -0.74014103]],\n",
      "\n",
      "       [[-0.8824814 , -0.858758  , -0.7994495 ],\n",
      "        [-1.0604068 , -0.98923665, -0.8943431 ],\n",
      "        [-0.858758  , -0.858758  , -0.7638644 ],\n",
      "        ...,\n",
      "        [-1.0604068 , -0.9655133 , -0.7994495 ],\n",
      "        [-0.98923665, -0.90620476, -0.7757261 ],\n",
      "        [-1.0010984 , -0.9180665 , -0.7875878 ]],\n",
      "\n",
      "       [[-0.7875878 , -0.8468963 , -0.7994495 ],\n",
      "        [-1.0604068 , -1.1197153 , -0.94178987],\n",
      "        [-0.7875878 , -0.858758  , -0.7282793 ],\n",
      "        ...,\n",
      "        [-0.98923665, -0.8350346 , -0.7164176 ],\n",
      "        [-1.0010984 , -0.858758  , -0.7282793 ],\n",
      "        [-1.0485451 , -0.90620476, -0.7638644 ]]], dtype=float32)>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n",
      "    outputs = [\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n",
      "    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n",
      "    return ops.convert_to_tensor(value, dtype=dtype)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 0.9442201 ,  0.4934756 ,  0.04273105],\n",
      "        [ 1.3593795 ,  0.89677334,  0.3629969 ],\n",
      "        [ 1.5610285 ,  1.3356562 ,  0.7544329 ],\n",
      "        ...,\n",
      "        [ 1.027252  ,  1.3356562 ,  1.3356562 ],\n",
      "        [ 1.027252  ,  1.3356562 ,  1.3356562 ],\n",
      "        [ 1.027252  ,  1.3356562 ,  1.3356562 ]],\n",
      "\n",
      "       [[ 1.2051774 ,  0.77815634,  0.42230538],\n",
      "        [ 1.0509754 ,  0.7069861 ,  0.16134803],\n",
      "        [ 1.5610285 ,  1.50172   ,  0.9204967 ],\n",
      "        ...,\n",
      "        [ 0.908635  ,  1.3356562 ,  1.3356562 ],\n",
      "        [ 0.908635  ,  1.3356562 ,  1.3356562 ],\n",
      "        [ 0.908635  ,  1.3356562 ,  1.3356562 ]],\n",
      "\n",
      "       [[ 1.5610285 ,  1.3119327 ,  0.908635  ],\n",
      "        [ 0.5053373 ,  0.17320973, -0.41987517],\n",
      "        [ 0.81374145,  0.4104437 , -0.01657744],\n",
      "        ...,\n",
      "        [ 0.908635  ,  1.3356562 ,  1.3356562 ],\n",
      "        [ 0.908635  ,  1.3356562 ,  1.3356562 ],\n",
      "        [ 0.908635  ,  1.3356562 ,  1.3356562 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.8824814 , -0.8468963 , -0.8468963 ],\n",
      "        [-1.0248218 , -0.98923665, -0.8706197 ],\n",
      "        [-0.8706197 , -0.8706197 , -0.7638644 ],\n",
      "        ...,\n",
      "        [-0.8943431 , -0.7994495 , -0.5978006 ],\n",
      "        [-0.7520027 , -0.62152404, -0.50290704],\n",
      "        [-1.0010984 , -0.8706197 , -0.74014103]],\n",
      "\n",
      "       [[-0.8824814 , -0.858758  , -0.7994495 ],\n",
      "        [-1.0604068 , -0.98923665, -0.8943431 ],\n",
      "        [-0.858758  , -0.858758  , -0.7638644 ],\n",
      "        ...,\n",
      "        [-1.0604068 , -0.9655133 , -0.7994495 ],\n",
      "        [-0.98923665, -0.90620476, -0.7757261 ],\n",
      "        [-1.0010984 , -0.9180665 , -0.7875878 ]],\n",
      "\n",
      "       [[-0.7875878 , -0.8468963 , -0.7994495 ],\n",
      "        [-1.0604068 , -1.1197153 , -0.94178987],\n",
      "        [-0.7875878 , -0.858758  , -0.7282793 ],\n",
      "        ...,\n",
      "        [-0.98923665, -0.8350346 , -0.7164176 ],\n",
      "        [-1.0010984 , -0.858758  , -0.7282793 ],\n",
      "        [-1.0485451 , -0.90620476, -0.7638644 ]]], dtype=float32)>\n",
      "\n",
      "\n",
      "2022-09-21 10:32:31.116878: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        ...,\n",
      "        [-0.9490654 , -0.8126454 , -0.8126454 ],\n",
      "        [-0.8994581 , -0.7630381 , -0.7630381 ],\n",
      "        [-0.92426175, -0.78784174, -0.78784174]],\n",
      "\n",
      "       [[ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        ...,\n",
      "        [-0.93666357, -0.7754399 , -0.6886271 ],\n",
      "        [-1.04828   , -0.8746545 , -0.78784174],\n",
      "        [-1.1722982 , -1.0606818 , -0.92426175]],\n",
      "\n",
      "       [[ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        ...,\n",
      "        [-0.6142162 , -0.58941257, -0.4405907 ],\n",
      "        [-0.7134308 , -0.6142162 , -0.49019802],\n",
      "        [-1.04828   , -0.9614672 , -0.837449  ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        ...,\n",
      "        [-0.98627084, -0.7754399 , -0.80024356],\n",
      "        [-1.1474946 , -0.8746545 , -0.84985083],\n",
      "        [-1.7179784 , -1.5071474 , -1.5939602 ]],\n",
      "\n",
      "       [[ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        ...,\n",
      "        [-0.837449  , -0.8870563 , -0.8250472 ],\n",
      "        [-1.0110745 , -0.99867266, -0.8746545 ],\n",
      "        [-1.5815583 , -1.5691565 , -1.5195493 ]],\n",
      "\n",
      "       [[ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        ...,\n",
      "        [-0.92426175, -0.8994581 , -0.8250472 ],\n",
      "        [-0.9118599 , -0.92426175, -0.78784174],\n",
      "        [-1.0234764 , -1.0358782 , -0.973869  ]]], dtype=float32)>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n",
      "    outputs = [\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n",
      "    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n",
      "    return ops.convert_to_tensor(value, dtype=dtype)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        ...,\n",
      "        [-0.9490654 , -0.8126454 , -0.8126454 ],\n",
      "        [-0.8994581 , -0.7630381 , -0.7630381 ],\n",
      "        [-0.92426175, -0.78784174, -0.78784174]],\n",
      "\n",
      "       [[ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        ...,\n",
      "        [-0.93666357, -0.7754399 , -0.6886271 ],\n",
      "        [-1.04828   , -0.8746545 , -0.78784174],\n",
      "        [-1.1722982 , -1.0606818 , -0.92426175]],\n",
      "\n",
      "       [[ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        ...,\n",
      "        [-0.6142162 , -0.58941257, -0.4405907 ],\n",
      "        [-0.7134308 , -0.6142162 , -0.49019802],\n",
      "        [-1.04828   , -0.9614672 , -0.837449  ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        ...,\n",
      "        [-0.98627084, -0.7754399 , -0.80024356],\n",
      "        [-1.1474946 , -0.8746545 , -0.84985083],\n",
      "        [-1.7179784 , -1.5071474 , -1.5939602 ]],\n",
      "\n",
      "       [[ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        ...,\n",
      "        [-0.837449  , -0.8870563 , -0.8250472 ],\n",
      "        [-1.0110745 , -0.99867266, -0.8746545 ],\n",
      "        [-1.5815583 , -1.5691565 , -1.5195493 ]],\n",
      "\n",
      "       [[ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        [ 1.2584589 ,  1.2584589 ,  1.2584589 ],\n",
      "        ...,\n",
      "        [-0.92426175, -0.8994581 , -0.8250472 ],\n",
      "        [-0.9118599 , -0.92426175, -0.78784174],\n",
      "        [-1.0234764 , -1.0358782 , -0.973869  ]]], dtype=float32)>\n",
      "\n",
      "\n",
      "2022-09-21 10:32:31.117010: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[-0.054068  , -0.1416957 , -0.3607649 ],\n",
      "        [-0.6236479 , -0.72588027, -0.8135079 ],\n",
      "        [-0.6674618 , -0.74048483, -0.8135079 ],\n",
      "        ...,\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ],\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ],\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ]],\n",
      "\n",
      "       [[-0.09788185, -0.17090492, -0.28774184],\n",
      "        [-0.52141565, -0.60904336, -0.59443873],\n",
      "        [-0.75508946, -0.8427172 , -0.8427172 ],\n",
      "        ...,\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ],\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ],\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ]],\n",
      "\n",
      "       [[ 0.00435045, -0.054068  , -0.03946339],\n",
      "        [-0.24392799, -0.30234644, -0.2585326 ],\n",
      "        [-0.5652295 , -0.6236479 , -0.60904336],\n",
      "        ...,\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ],\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ],\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.696671  , -0.696671  , -0.72588027],\n",
      "        [-0.6820664 , -0.6820664 , -0.71127564],\n",
      "        [-0.6820664 , -0.6820664 , -0.71127564],\n",
      "        ...,\n",
      "        [-0.01025416,  0.04816429,  0.03355968],\n",
      "        [-0.3607649 , -0.30234644, -0.31695107],\n",
      "        [ 0.13579197,  0.19421044,  0.17960583]],\n",
      "\n",
      "       [[-0.4776018 , -0.4776018 , -0.4776018 ],\n",
      "        [-0.52141565, -0.52141565, -0.5360203 ],\n",
      "        [-0.5798341 , -0.5798341 , -0.59443873],\n",
      "        ...,\n",
      "        [-0.06867262, -0.03946339, -0.03946339],\n",
      "        [-0.03946339, -0.01025416, -0.01025416],\n",
      "        [ 0.12118737,  0.15039659,  0.13579197]],\n",
      "\n",
      "       [[-0.41918334, -0.41918334, -0.44839257],\n",
      "        [-0.41918334, -0.41918334, -0.44839257],\n",
      "        [-0.41918334, -0.41918334, -0.44839257],\n",
      "        ...,\n",
      "        [-0.21471876, -0.1563003 , -0.17090492],\n",
      "        [-0.12709108, -0.06867262, -0.09788185],\n",
      "        [ 0.22341967,  0.28183812,  0.2672335 ]]], dtype=float32)>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n",
      "    outputs = [\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n",
      "    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n",
      "    return ops.convert_to_tensor(value, dtype=dtype)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[-0.054068  , -0.1416957 , -0.3607649 ],\n",
      "        [-0.6236479 , -0.72588027, -0.8135079 ],\n",
      "        [-0.6674618 , -0.74048483, -0.8135079 ],\n",
      "        ...,\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ],\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ],\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ]],\n",
      "\n",
      "       [[-0.09788185, -0.17090492, -0.28774184],\n",
      "        [-0.52141565, -0.60904336, -0.59443873],\n",
      "        [-0.75508946, -0.8427172 , -0.8427172 ],\n",
      "        ...,\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ],\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ],\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ]],\n",
      "\n",
      "       [[ 0.00435045, -0.054068  , -0.03946339],\n",
      "        [-0.24392799, -0.30234644, -0.2585326 ],\n",
      "        [-0.5652295 , -0.6236479 , -0.60904336],\n",
      "        ...,\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ],\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ],\n",
      "        [ 2.1512287 ,  2.1512287 ,  2.1512287 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.696671  , -0.696671  , -0.72588027],\n",
      "        [-0.6820664 , -0.6820664 , -0.71127564],\n",
      "        [-0.6820664 , -0.6820664 , -0.71127564],\n",
      "        ...,\n",
      "        [-0.01025416,  0.04816429,  0.03355968],\n",
      "        [-0.3607649 , -0.30234644, -0.31695107],\n",
      "        [ 0.13579197,  0.19421044,  0.17960583]],\n",
      "\n",
      "       [[-0.4776018 , -0.4776018 , -0.4776018 ],\n",
      "        [-0.52141565, -0.52141565, -0.5360203 ],\n",
      "        [-0.5798341 , -0.5798341 , -0.59443873],\n",
      "        ...,\n",
      "        [-0.06867262, -0.03946339, -0.03946339],\n",
      "        [-0.03946339, -0.01025416, -0.01025416],\n",
      "        [ 0.12118737,  0.15039659,  0.13579197]],\n",
      "\n",
      "       [[-0.41918334, -0.41918334, -0.44839257],\n",
      "        [-0.41918334, -0.41918334, -0.44839257],\n",
      "        [-0.41918334, -0.41918334, -0.44839257],\n",
      "        ...,\n",
      "        [-0.21471876, -0.1563003 , -0.17090492],\n",
      "        [-0.12709108, -0.06867262, -0.09788185],\n",
      "        [ 0.22341967,  0.28183812,  0.2672335 ]]], dtype=float32)>\n",
      "\n",
      "\n",
      "2022-09-21 10:32:31.118260: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[-0.9202193 , -0.93400985, -0.8236856 ],\n",
      "        [-1.044334  , -0.93400985, -0.89263827],\n",
      "        [-0.97538143, -0.90642875, -0.83747613],\n",
      "        ...,\n",
      "        [-1.0581247 , -0.9615909 , -0.989172  ],\n",
      "        [-0.35480756, -0.38238862, -0.3685981 ],\n",
      "        [-0.83747613, -0.8236856 , -0.8236856 ]],\n",
      "\n",
      "       [[-0.9478004 , -0.9202193 , -0.8650572 ],\n",
      "        [-1.0719151 , -1.0167531 , -0.989172  ],\n",
      "        [-0.90642875, -0.97538143, -0.80989504],\n",
      "        ...,\n",
      "        [-1.1408678 , -1.044334  , -1.0719151 ],\n",
      "        [-0.7271519 , -0.7409424 , -0.7409424 ],\n",
      "        [-1.1546583 , -1.1408678 , -1.1408678 ]],\n",
      "\n",
      "       [[-1.1270772 , -1.0029625 , -0.9202193 ],\n",
      "        [-1.0581247 , -0.989172  , -0.9478004 ],\n",
      "        [-0.9202193 , -1.0029625 , -0.83747613],\n",
      "        ...,\n",
      "        [-1.0029625 , -0.90642875, -0.93400985],\n",
      "        [-0.6444087 , -0.67198974, -0.65819925],\n",
      "        [-1.0994962 , -1.0857056 , -1.0857056 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 1.1069887 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 0.9415023 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.0518266 ,  1.2311034 ,  1.2311034 ],\n",
      "        ...,\n",
      "        [ 1.1759413 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.1759413 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.1759413 ,  1.2311034 ,  1.2311034 ]],\n",
      "\n",
      "       [[ 1.1069887 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 0.9966644 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.0518266 ,  1.2311034 ,  1.2311034 ],\n",
      "        ...,\n",
      "        [ 1.1621507 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.1621507 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.1621507 ,  1.2311034 ,  1.2311034 ]],\n",
      "\n",
      "       [[ 1.038036  ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.038036  ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 0.9966644 ,  1.2311034 ,  1.2311034 ],\n",
      "        ...,\n",
      "        [ 1.2035223 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.2035223 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.2035223 ,  1.2311034 ,  1.2311034 ]]], dtype=float32)>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n",
      "    outputs = [\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n",
      "    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n",
      "    return ops.convert_to_tensor(value, dtype=dtype)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[-0.9202193 , -0.93400985, -0.8236856 ],\n",
      "        [-1.044334  , -0.93400985, -0.89263827],\n",
      "        [-0.97538143, -0.90642875, -0.83747613],\n",
      "        ...,\n",
      "        [-1.0581247 , -0.9615909 , -0.989172  ],\n",
      "        [-0.35480756, -0.38238862, -0.3685981 ],\n",
      "        [-0.83747613, -0.8236856 , -0.8236856 ]],\n",
      "\n",
      "       [[-0.9478004 , -0.9202193 , -0.8650572 ],\n",
      "        [-1.0719151 , -1.0167531 , -0.989172  ],\n",
      "        [-0.90642875, -0.97538143, -0.80989504],\n",
      "        ...,\n",
      "        [-1.1408678 , -1.044334  , -1.0719151 ],\n",
      "        [-0.7271519 , -0.7409424 , -0.7409424 ],\n",
      "        [-1.1546583 , -1.1408678 , -1.1408678 ]],\n",
      "\n",
      "       [[-1.1270772 , -1.0029625 , -0.9202193 ],\n",
      "        [-1.0581247 , -0.989172  , -0.9478004 ],\n",
      "        [-0.9202193 , -1.0029625 , -0.83747613],\n",
      "        ...,\n",
      "        [-1.0029625 , -0.90642875, -0.93400985],\n",
      "        [-0.6444087 , -0.67198974, -0.65819925],\n",
      "        [-1.0994962 , -1.0857056 , -1.0857056 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 1.1069887 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 0.9415023 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.0518266 ,  1.2311034 ,  1.2311034 ],\n",
      "        ...,\n",
      "        [ 1.1759413 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.1759413 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.1759413 ,  1.2311034 ,  1.2311034 ]],\n",
      "\n",
      "       [[ 1.1069887 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 0.9966644 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.0518266 ,  1.2311034 ,  1.2311034 ],\n",
      "        ...,\n",
      "        [ 1.1621507 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.1621507 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.1621507 ,  1.2311034 ,  1.2311034 ]],\n",
      "\n",
      "       [[ 1.038036  ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.038036  ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 0.9966644 ,  1.2311034 ,  1.2311034 ],\n",
      "        ...,\n",
      "        [ 1.2035223 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.2035223 ,  1.2311034 ,  1.2311034 ],\n",
      "        [ 1.2035223 ,  1.2311034 ,  1.2311034 ]]], dtype=float32)>\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\narray([[[-3.3483422e-01, -3.3483422e-01, -3.0699056e-01],\n        [-4.1836518e-01, -4.3228701e-01, -4.0444335e-01],\n        [-4.6013066e-01, -4.6013066e-01, -4.0444335e-01],\n        ...,\n        [-9.0562916e-01, -8.9170730e-01, -8.9170730e-01],\n        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01],\n        [-8.6386365e-01, -8.4994185e-01, -8.4994185e-01]],\n\n       [[-9.8163158e-02, -9.8163158e-02, -9.8163158e-02],\n        [-2.9306874e-01, -3.0699056e-01, -3.0699056e-01],\n        [-4.6013066e-01, -4.6013066e-01, -4.3228701e-01],\n        ...,\n        [-9.3347281e-01, -9.1955096e-01, -9.1955096e-01],\n        [-8.9170730e-01, -8.7778550e-01, -8.7778550e-01],\n        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01]],\n\n       [[-7.1036670e-04, -7.1036670e-04, -2.8554022e-02],\n        [-2.8554022e-02, -2.8554022e-02, -5.6397676e-02],\n        [-3.3483422e-01, -3.3483422e-01, -3.6267787e-01],\n        ...,\n        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01],\n        [-8.4994185e-01, -8.3601999e-01, -8.3601999e-01],\n        [-8.9170730e-01, -8.6386365e-01, -8.6386365e-01]],\n\n       ...,\n\n       [[-7.3856723e-01, -6.8287992e-01, -6.4111441e-01],\n        [-7.1072358e-01, -6.5503627e-01, -6.1327076e-01],\n        [-6.6895807e-01, -6.1327076e-01, -5.7150531e-01],\n        ...,\n        [-2.2345960e-01, -2.7914691e-01, -3.3483422e-01],\n        [-1.8169412e-01, -2.5130326e-01, -2.7914691e-01],\n        [-1.6777229e-01, -2.5130326e-01, -2.7914691e-01]],\n\n       [[-8.2209820e-01, -7.5248903e-01, -7.2464538e-01],\n        [-7.8033268e-01, -7.2464538e-01, -6.8287992e-01],\n        [-7.2464538e-01, -6.6895807e-01, -6.2719262e-01],\n        ...,\n        [-1.8169412e-01, -2.2345960e-01, -3.3483422e-01],\n        [-2.7914691e-01, -3.3483422e-01, -4.1836518e-01],\n        [-1.3992864e-01, -2.0953777e-01, -2.7914691e-01]],\n\n       [[-8.0817634e-01, -7.5248903e-01, -7.1072358e-01],\n        [-7.9425454e-01, -7.3856723e-01, -6.9680172e-01],\n        [-7.5248903e-01, -6.8287992e-01, -6.6895807e-01],\n        ...,\n        [-7.1036670e-04, -4.2475849e-02, -1.5385047e-01],\n        [-2.5130326e-01, -2.9306874e-01, -4.0444335e-01],\n        [-2.5130326e-01, -3.2091239e-01, -4.1836518e-01]]], dtype=float32)>\nTraceback (most recent call last):\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n    outputs = [\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n    return ops.convert_to_tensor(value, dtype=dtype)\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n    return func(*args, **kwargs)\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n    raise ValueError(\n\nValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\narray([[[-3.3483422e-01, -3.3483422e-01, -3.0699056e-01],\n        [-4.1836518e-01, -4.3228701e-01, -4.0444335e-01],\n        [-4.6013066e-01, -4.6013066e-01, -4.0444335e-01],\n        ...,\n        [-9.0562916e-01, -8.9170730e-01, -8.9170730e-01],\n        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01],\n        [-8.6386365e-01, -8.4994185e-01, -8.4994185e-01]],\n\n       [[-9.8163158e-02, -9.8163158e-02, -9.8163158e-02],\n        [-2.9306874e-01, -3.0699056e-01, -3.0699056e-01],\n        [-4.6013066e-01, -4.6013066e-01, -4.3228701e-01],\n        ...,\n        [-9.3347281e-01, -9.1955096e-01, -9.1955096e-01],\n        [-8.9170730e-01, -8.7778550e-01, -8.7778550e-01],\n        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01]],\n\n       [[-7.1036670e-04, -7.1036670e-04, -2.8554022e-02],\n        [-2.8554022e-02, -2.8554022e-02, -5.6397676e-02],\n        [-3.3483422e-01, -3.3483422e-01, -3.6267787e-01],\n        ...,\n        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01],\n        [-8.4994185e-01, -8.3601999e-01, -8.3601999e-01],\n        [-8.9170730e-01, -8.6386365e-01, -8.6386365e-01]],\n\n       ...,\n\n       [[-7.3856723e-01, -6.8287992e-01, -6.4111441e-01],\n        [-7.1072358e-01, -6.5503627e-01, -6.1327076e-01],\n        [-6.6895807e-01, -6.1327076e-01, -5.7150531e-01],\n        ...,\n        [-2.2345960e-01, -2.7914691e-01, -3.3483422e-01],\n        [-1.8169412e-01, -2.5130326e-01, -2.7914691e-01],\n        [-1.6777229e-01, -2.5130326e-01, -2.7914691e-01]],\n\n       [[-8.2209820e-01, -7.5248903e-01, -7.2464538e-01],\n        [-7.8033268e-01, -7.2464538e-01, -6.8287992e-01],\n        [-7.2464538e-01, -6.6895807e-01, -6.2719262e-01],\n        ...,\n        [-1.8169412e-01, -2.2345960e-01, -3.3483422e-01],\n        [-2.7914691e-01, -3.3483422e-01, -4.1836518e-01],\n        [-1.3992864e-01, -2.0953777e-01, -2.7914691e-01]],\n\n       [[-8.0817634e-01, -7.5248903e-01, -7.1072358e-01],\n        [-7.9425454e-01, -7.3856723e-01, -6.9680172e-01],\n        [-7.5248903e-01, -6.8287992e-01, -6.6895807e-01],\n        ...,\n        [-7.1036670e-04, -4.2475849e-02, -1.5385047e-01],\n        [-2.5130326e-01, -2.9306874e-01, -4.0444335e-01],\n        [-2.5130326e-01, -3.2091239e-01, -4.1836518e-01]]], dtype=float32)>\n\n\n\t [[{{function_node __inference__map_fucntion_3787}}{{node EagerPyFunc}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ti \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m ti)\n",
      "Cell \u001b[0;32mIn [51], line 2\u001b[0m, in \u001b[0;36mt\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mt\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (i, m) \u001b[38;5;129;01min\u001b[39;00m train_dataset\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    765\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 766\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    767\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    768\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 749\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    750\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    751\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    752\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    754\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    755\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3017\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3015\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3016\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 3017\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   3018\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m   3019\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7208\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7209\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\narray([[[-3.3483422e-01, -3.3483422e-01, -3.0699056e-01],\n        [-4.1836518e-01, -4.3228701e-01, -4.0444335e-01],\n        [-4.6013066e-01, -4.6013066e-01, -4.0444335e-01],\n        ...,\n        [-9.0562916e-01, -8.9170730e-01, -8.9170730e-01],\n        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01],\n        [-8.6386365e-01, -8.4994185e-01, -8.4994185e-01]],\n\n       [[-9.8163158e-02, -9.8163158e-02, -9.8163158e-02],\n        [-2.9306874e-01, -3.0699056e-01, -3.0699056e-01],\n        [-4.6013066e-01, -4.6013066e-01, -4.3228701e-01],\n        ...,\n        [-9.3347281e-01, -9.1955096e-01, -9.1955096e-01],\n        [-8.9170730e-01, -8.7778550e-01, -8.7778550e-01],\n        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01]],\n\n       [[-7.1036670e-04, -7.1036670e-04, -2.8554022e-02],\n        [-2.8554022e-02, -2.8554022e-02, -5.6397676e-02],\n        [-3.3483422e-01, -3.3483422e-01, -3.6267787e-01],\n        ...,\n        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01],\n        [-8.4994185e-01, -8.3601999e-01, -8.3601999e-01],\n        [-8.9170730e-01, -8.6386365e-01, -8.6386365e-01]],\n\n       ...,\n\n       [[-7.3856723e-01, -6.8287992e-01, -6.4111441e-01],\n        [-7.1072358e-01, -6.5503627e-01, -6.1327076e-01],\n        [-6.6895807e-01, -6.1327076e-01, -5.7150531e-01],\n        ...,\n        [-2.2345960e-01, -2.7914691e-01, -3.3483422e-01],\n        [-1.8169412e-01, -2.5130326e-01, -2.7914691e-01],\n        [-1.6777229e-01, -2.5130326e-01, -2.7914691e-01]],\n\n       [[-8.2209820e-01, -7.5248903e-01, -7.2464538e-01],\n        [-7.8033268e-01, -7.2464538e-01, -6.8287992e-01],\n        [-7.2464538e-01, -6.6895807e-01, -6.2719262e-01],\n        ...,\n        [-1.8169412e-01, -2.2345960e-01, -3.3483422e-01],\n        [-2.7914691e-01, -3.3483422e-01, -4.1836518e-01],\n        [-1.3992864e-01, -2.0953777e-01, -2.7914691e-01]],\n\n       [[-8.0817634e-01, -7.5248903e-01, -7.1072358e-01],\n        [-7.9425454e-01, -7.3856723e-01, -6.9680172e-01],\n        [-7.5248903e-01, -6.8287992e-01, -6.6895807e-01],\n        ...,\n        [-7.1036670e-04, -4.2475849e-02, -1.5385047e-01],\n        [-2.5130326e-01, -2.9306874e-01, -4.0444335e-01],\n        [-2.5130326e-01, -3.2091239e-01, -4.1836518e-01]]], dtype=float32)>\nTraceback (most recent call last):\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n    outputs = [\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n    return ops.convert_to_tensor(value, dtype=dtype)\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n    return func(*args, **kwargs)\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n    raise ValueError(\n\nValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\narray([[[-3.3483422e-01, -3.3483422e-01, -3.0699056e-01],\n        [-4.1836518e-01, -4.3228701e-01, -4.0444335e-01],\n        [-4.6013066e-01, -4.6013066e-01, -4.0444335e-01],\n        ...,\n        [-9.0562916e-01, -8.9170730e-01, -8.9170730e-01],\n        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01],\n        [-8.6386365e-01, -8.4994185e-01, -8.4994185e-01]],\n\n       [[-9.8163158e-02, -9.8163158e-02, -9.8163158e-02],\n        [-2.9306874e-01, -3.0699056e-01, -3.0699056e-01],\n        [-4.6013066e-01, -4.6013066e-01, -4.3228701e-01],\n        ...,\n        [-9.3347281e-01, -9.1955096e-01, -9.1955096e-01],\n        [-8.9170730e-01, -8.7778550e-01, -8.7778550e-01],\n        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01]],\n\n       [[-7.1036670e-04, -7.1036670e-04, -2.8554022e-02],\n        [-2.8554022e-02, -2.8554022e-02, -5.6397676e-02],\n        [-3.3483422e-01, -3.3483422e-01, -3.6267787e-01],\n        ...,\n        [-8.7778550e-01, -8.6386365e-01, -8.6386365e-01],\n        [-8.4994185e-01, -8.3601999e-01, -8.3601999e-01],\n        [-8.9170730e-01, -8.6386365e-01, -8.6386365e-01]],\n\n       ...,\n\n       [[-7.3856723e-01, -6.8287992e-01, -6.4111441e-01],\n        [-7.1072358e-01, -6.5503627e-01, -6.1327076e-01],\n        [-6.6895807e-01, -6.1327076e-01, -5.7150531e-01],\n        ...,\n        [-2.2345960e-01, -2.7914691e-01, -3.3483422e-01],\n        [-1.8169412e-01, -2.5130326e-01, -2.7914691e-01],\n        [-1.6777229e-01, -2.5130326e-01, -2.7914691e-01]],\n\n       [[-8.2209820e-01, -7.5248903e-01, -7.2464538e-01],\n        [-7.8033268e-01, -7.2464538e-01, -6.8287992e-01],\n        [-7.2464538e-01, -6.6895807e-01, -6.2719262e-01],\n        ...,\n        [-1.8169412e-01, -2.2345960e-01, -3.3483422e-01],\n        [-2.7914691e-01, -3.3483422e-01, -4.1836518e-01],\n        [-1.3992864e-01, -2.0953777e-01, -2.7914691e-01]],\n\n       [[-8.0817634e-01, -7.5248903e-01, -7.1072358e-01],\n        [-7.9425454e-01, -7.3856723e-01, -6.9680172e-01],\n        [-7.5248903e-01, -6.8287992e-01, -6.6895807e-01],\n        ...,\n        [-7.1036670e-04, -4.2475849e-02, -1.5385047e-01],\n        [-2.5130326e-01, -2.9306874e-01, -4.0444335e-01],\n        [-2.5130326e-01, -3.2091239e-01, -4.1836518e-01]]], dtype=float32)>\n\n\n\t [[{{function_node __inference__map_fucntion_3787}}{{node EagerPyFunc}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "ti = time.time()\n",
    "t()\n",
    "print(time.time() - ti)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti = time.time()\n",
    "t()\n",
    "print(time.time() - ti)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 s  1.06 s per loop (mean  std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "train_dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-21 10:55:33.607632: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        [ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        [ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        ...,\n",
      "        [ 0.83722067,  1.2784507 ,  1.2784507 ],\n",
      "        [ 0.95647204,  1.2784507 ,  1.2784507 ],\n",
      "        [ 0.95647204,  1.2784507 ,  1.2784507 ]],\n",
      "\n",
      "       [[ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        [ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        [ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        ...,\n",
      "        [ 0.86107093,  1.2784507 ,  1.2784507 ],\n",
      "        [ 0.9087715 ,  1.2784507 ,  1.2784507 ],\n",
      "        [ 0.8491458 ,  1.2784507 ,  1.2784507 ]],\n",
      "\n",
      "       [[ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        [ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        [ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        ...,\n",
      "        [ 0.86107093,  1.2784507 ,  1.2784507 ],\n",
      "        [ 0.9206966 ,  1.2784507 ,  1.2784507 ],\n",
      "        [ 0.8252955 ,  1.2784507 ,  1.2784507 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.00246105,  0.0501616 ,  0.08593702],\n",
      "        [-0.7249723 , -0.6772718 , -0.64149636],\n",
      "        [-1.1662024 , -1.1185019 , -1.0827265 ],\n",
      "        ...,\n",
      "        [-0.59379584, -0.5818707 , -0.5818707 ],\n",
      "        [-0.4626193 , -0.45069417, -0.45069417],\n",
      "        [-0.42684388, -0.41491875, -0.41491875]],\n",
      "\n",
      "       [[-0.5699456 , -0.522245  , -0.4864696 ],\n",
      "        [-0.9754002 , -0.9276997 , -0.89192426],\n",
      "        [-1.0231007 , -0.9754002 , -0.9396248 ],\n",
      "        ...,\n",
      "        [-0.62957126, -0.6176461 , -0.6176461 ],\n",
      "        [-0.85614884, -0.8442237 , -0.8442237 ],\n",
      "        [-0.5818707 , -0.60572094, -0.60572094]],\n",
      "\n",
      "       [[-0.29566738, -0.24796684, -0.21219142],\n",
      "        [-0.5580204 , -0.5103198 , -0.47454444],\n",
      "        [-0.20026629, -0.15256573, -0.11679032],\n",
      "        ...,\n",
      "        [-0.53417015, -0.522245  , -0.522245  ],\n",
      "        [-0.9276997 , -0.9038494 , -0.9038494 ],\n",
      "        [-0.43876904, -0.41491875, -0.41491875]]], dtype=float32)>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n",
      "    outputs = [\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n",
      "    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n",
      "    return ops.convert_to_tensor(value, dtype=dtype)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        [ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        [ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        ...,\n",
      "        [ 0.83722067,  1.2784507 ,  1.2784507 ],\n",
      "        [ 0.95647204,  1.2784507 ,  1.2784507 ],\n",
      "        [ 0.95647204,  1.2784507 ,  1.2784507 ]],\n",
      "\n",
      "       [[ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        [ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        [ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        ...,\n",
      "        [ 0.86107093,  1.2784507 ,  1.2784507 ],\n",
      "        [ 0.9087715 ,  1.2784507 ,  1.2784507 ],\n",
      "        [ 0.8491458 ,  1.2784507 ,  1.2784507 ]],\n",
      "\n",
      "       [[ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        [ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        [ 1.2784507 ,  1.2784507 ,  1.2784507 ],\n",
      "        ...,\n",
      "        [ 0.86107093,  1.2784507 ,  1.2784507 ],\n",
      "        [ 0.9206966 ,  1.2784507 ,  1.2784507 ],\n",
      "        [ 0.8252955 ,  1.2784507 ,  1.2784507 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.00246105,  0.0501616 ,  0.08593702],\n",
      "        [-0.7249723 , -0.6772718 , -0.64149636],\n",
      "        [-1.1662024 , -1.1185019 , -1.0827265 ],\n",
      "        ...,\n",
      "        [-0.59379584, -0.5818707 , -0.5818707 ],\n",
      "        [-0.4626193 , -0.45069417, -0.45069417],\n",
      "        [-0.42684388, -0.41491875, -0.41491875]],\n",
      "\n",
      "       [[-0.5699456 , -0.522245  , -0.4864696 ],\n",
      "        [-0.9754002 , -0.9276997 , -0.89192426],\n",
      "        [-1.0231007 , -0.9754002 , -0.9396248 ],\n",
      "        ...,\n",
      "        [-0.62957126, -0.6176461 , -0.6176461 ],\n",
      "        [-0.85614884, -0.8442237 , -0.8442237 ],\n",
      "        [-0.5818707 , -0.60572094, -0.60572094]],\n",
      "\n",
      "       [[-0.29566738, -0.24796684, -0.21219142],\n",
      "        [-0.5580204 , -0.5103198 , -0.47454444],\n",
      "        [-0.20026629, -0.15256573, -0.11679032],\n",
      "        ...,\n",
      "        [-0.53417015, -0.522245  , -0.522245  ],\n",
      "        [-0.9276997 , -0.9038494 , -0.9038494 ],\n",
      "        [-0.43876904, -0.41491875, -0.41491875]]], dtype=float32)>\n",
      "\n",
      "\n",
      "2022-09-21 10:55:33.612741: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[-3.3975163e-01, -1.4919980e-01,  2.7587736e-01],\n",
      "        [-4.1304079e-01, -9.0568468e-02,  1.7327252e-01],\n",
      "        [-5.5961913e-01, -2.3714679e-01,  9.9983357e-02],\n",
      "        ...,\n",
      "        [ 1.5950823e+00,  1.3165834e+00,  8.4753287e-01],\n",
      "        [ 3.3450869e-01,  2.1724603e-01, -1.3454197e-01],\n",
      "        [ 7.8890151e-01,  6.2766534e-01,  4.0779784e-01]],\n",
      "\n",
      "       [[-4.2769864e-01, -2.3714679e-01,  1.8793036e-01],\n",
      "        [-3.5440946e-01, -4.6594970e-02,  1.7327252e-01],\n",
      "        [-5.1564562e-01, -1.9317330e-01,  1.4395685e-01],\n",
      "        ...,\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [ 7.3027021e-01,  5.8369184e-01, -2.6214721e-03],\n",
      "        [ 2.4745522e+00,  2.4012630e+00,  2.0641329e+00]],\n",
      "\n",
      "       [[-4.2769864e-01, -2.3714679e-01,  1.8793036e-01],\n",
      "        [-3.5440946e-01, -3.1937137e-02,  1.8793036e-01],\n",
      "        [-5.1564562e-01, -1.4919980e-01,  1.4395685e-01],\n",
      "        ...,\n",
      "        [ 7.5958586e-01,  6.4232320e-01, -6.1252806e-02],\n",
      "        [ 2.6357884e+00,  2.7090776e+00,  2.5918150e+00],\n",
      "        [ 1.8882389e+00,  1.8002919e+00,  1.6243980e+00]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        ...,\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01]],\n",
      "\n",
      "       [[-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        ...,\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01]],\n",
      "\n",
      "       [[-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        ...,\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01]]], dtype=float32)>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n",
      "    outputs = [\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n",
      "    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n",
      "    return ops.convert_to_tensor(value, dtype=dtype)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[-3.3975163e-01, -1.4919980e-01,  2.7587736e-01],\n",
      "        [-4.1304079e-01, -9.0568468e-02,  1.7327252e-01],\n",
      "        [-5.5961913e-01, -2.3714679e-01,  9.9983357e-02],\n",
      "        ...,\n",
      "        [ 1.5950823e+00,  1.3165834e+00,  8.4753287e-01],\n",
      "        [ 3.3450869e-01,  2.1724603e-01, -1.3454197e-01],\n",
      "        [ 7.8890151e-01,  6.2766534e-01,  4.0779784e-01]],\n",
      "\n",
      "       [[-4.2769864e-01, -2.3714679e-01,  1.8793036e-01],\n",
      "        [-3.5440946e-01, -4.6594970e-02,  1.7327252e-01],\n",
      "        [-5.1564562e-01, -1.9317330e-01,  1.4395685e-01],\n",
      "        ...,\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [ 7.3027021e-01,  5.8369184e-01, -2.6214721e-03],\n",
      "        [ 2.4745522e+00,  2.4012630e+00,  2.0641329e+00]],\n",
      "\n",
      "       [[-4.2769864e-01, -2.3714679e-01,  1.8793036e-01],\n",
      "        [-3.5440946e-01, -3.1937137e-02,  1.8793036e-01],\n",
      "        [-5.1564562e-01, -1.4919980e-01,  1.4395685e-01],\n",
      "        ...,\n",
      "        [ 7.5958586e-01,  6.4232320e-01, -6.1252806e-02],\n",
      "        [ 2.6357884e+00,  2.7090776e+00,  2.5918150e+00],\n",
      "        [ 1.8882389e+00,  1.8002919e+00,  1.6243980e+00]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        ...,\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01]],\n",
      "\n",
      "       [[-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        ...,\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01]],\n",
      "\n",
      "       [[-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        ...,\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01],\n",
      "        [-7.0619744e-01, -7.0619744e-01, -7.0619744e-01]]], dtype=float32)>\n",
      "\n",
      "\n",
      "2022-09-21 10:55:33.619136: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 0.11867719, -0.03268285, -0.25972292],\n",
      "        [ 0.83006936,  0.6787093 ,  0.43653327],\n",
      "        [ 0.70898134,  0.5576213 ,  0.30030924],\n",
      "        ...,\n",
      "        [-0.7894831 , -0.72893906, -0.68353105],\n",
      "        [-0.8046191 , -0.75921106, -0.69866705],\n",
      "        [-0.8197551 , -0.75921106, -0.71380305]],\n",
      "\n",
      "       [[-0.13863489, -0.35053894, -0.592715  ],\n",
      "        [ 0.45166928,  0.20949322, -0.00241085],\n",
      "        [ 0.4970773 ,  0.27003723,  0.04299717],\n",
      "        ...,\n",
      "        [-0.75921106, -0.74407506, -0.68353105],\n",
      "        [-0.8046191 , -0.7894831 , -0.72893906],\n",
      "        [-0.8046191 , -0.7894831 , -0.72893906]],\n",
      "\n",
      "       [[ 0.37598926,  0.14894919, -0.10836288],\n",
      "        [-0.06295487, -0.28999493, -0.532171  ],\n",
      "        [-0.1689069 , -0.39594695, -0.592715  ],\n",
      "        ...,\n",
      "        [-0.8046191 , -0.7894831 , -0.71380305],\n",
      "        [-0.8046191 , -0.8046191 , -0.72893906],\n",
      "        [-0.7894831 , -0.8046191 , -0.69866705]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 2.404214  ,  2.2528539 ,  1.4506456 ],\n",
      "        [ 2.404214  ,  2.2225819 ,  1.4203736 ],\n",
      "        [ 2.404214  ,  2.2528539 ,  1.4506456 ],\n",
      "        ...,\n",
      "        [-0.592715  , -0.592715  , -0.532171  ],\n",
      "        [-0.71380305, -0.71380305, -0.69866705],\n",
      "        [-0.36567494, -0.36567494, -0.42621896]],\n",
      "\n",
      "       [[ 2.404214  ,  2.2679899 ,  1.5414616 ],\n",
      "        [ 2.404214  ,  2.2528539 ,  1.5111896 ],\n",
      "        [ 2.404214  ,  2.2679899 ,  1.5263256 ],\n",
      "        ...,\n",
      "        [-0.35053894, -0.35053894, -0.35053894],\n",
      "        [-0.36567494, -0.36567494, -0.41108295],\n",
      "        [-0.25972292, -0.25972292, -0.30513093]],\n",
      "\n",
      "       [[ 2.404214  ,  2.298262  ,  1.5111896 ],\n",
      "        [ 2.404214  ,  2.298262  ,  1.5111896 ],\n",
      "        [ 2.404214  ,  2.328534  ,  1.5414616 ],\n",
      "        ...,\n",
      "        [-0.30513093, -0.30513093, -0.36567494],\n",
      "        [-0.1689069 , -0.1689069 , -0.22945091],\n",
      "        [-0.13863489, -0.13863489, -0.1991789 ]]], dtype=float32)>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n",
      "    outputs = [\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n",
      "    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n",
      "    return ops.convert_to_tensor(value, dtype=dtype)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 0.11867719, -0.03268285, -0.25972292],\n",
      "        [ 0.83006936,  0.6787093 ,  0.43653327],\n",
      "        [ 0.70898134,  0.5576213 ,  0.30030924],\n",
      "        ...,\n",
      "        [-0.7894831 , -0.72893906, -0.68353105],\n",
      "        [-0.8046191 , -0.75921106, -0.69866705],\n",
      "        [-0.8197551 , -0.75921106, -0.71380305]],\n",
      "\n",
      "       [[-0.13863489, -0.35053894, -0.592715  ],\n",
      "        [ 0.45166928,  0.20949322, -0.00241085],\n",
      "        [ 0.4970773 ,  0.27003723,  0.04299717],\n",
      "        ...,\n",
      "        [-0.75921106, -0.74407506, -0.68353105],\n",
      "        [-0.8046191 , -0.7894831 , -0.72893906],\n",
      "        [-0.8046191 , -0.7894831 , -0.72893906]],\n",
      "\n",
      "       [[ 0.37598926,  0.14894919, -0.10836288],\n",
      "        [-0.06295487, -0.28999493, -0.532171  ],\n",
      "        [-0.1689069 , -0.39594695, -0.592715  ],\n",
      "        ...,\n",
      "        [-0.8046191 , -0.7894831 , -0.71380305],\n",
      "        [-0.8046191 , -0.8046191 , -0.72893906],\n",
      "        [-0.7894831 , -0.8046191 , -0.69866705]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 2.404214  ,  2.2528539 ,  1.4506456 ],\n",
      "        [ 2.404214  ,  2.2225819 ,  1.4203736 ],\n",
      "        [ 2.404214  ,  2.2528539 ,  1.4506456 ],\n",
      "        ...,\n",
      "        [-0.592715  , -0.592715  , -0.532171  ],\n",
      "        [-0.71380305, -0.71380305, -0.69866705],\n",
      "        [-0.36567494, -0.36567494, -0.42621896]],\n",
      "\n",
      "       [[ 2.404214  ,  2.2679899 ,  1.5414616 ],\n",
      "        [ 2.404214  ,  2.2528539 ,  1.5111896 ],\n",
      "        [ 2.404214  ,  2.2679899 ,  1.5263256 ],\n",
      "        ...,\n",
      "        [-0.35053894, -0.35053894, -0.35053894],\n",
      "        [-0.36567494, -0.36567494, -0.41108295],\n",
      "        [-0.25972292, -0.25972292, -0.30513093]],\n",
      "\n",
      "       [[ 2.404214  ,  2.298262  ,  1.5111896 ],\n",
      "        [ 2.404214  ,  2.298262  ,  1.5111896 ],\n",
      "        [ 2.404214  ,  2.328534  ,  1.5414616 ],\n",
      "        ...,\n",
      "        [-0.30513093, -0.30513093, -0.36567494],\n",
      "        [-0.1689069 , -0.1689069 , -0.22945091],\n",
      "        [-0.13863489, -0.13863489, -0.1991789 ]]], dtype=float32)>\n",
      "\n",
      "\n",
      "2022-09-21 10:55:33.623526: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[-1.2930928 , -1.6268424 , -1.4290649 ],\n",
      "        [-0.5267052 , -0.77392703, -0.5637885 ],\n",
      "        [-0.6626772 , -0.88517684, -1.0582322 ],\n",
      "        ...,\n",
      "        [ 0.93190366,  0.93190366,  0.93190366],\n",
      "        [ 0.93190366,  0.93190366,  0.93190366],\n",
      "        [ 0.93190366,  0.93190366,  0.93190366]],\n",
      "\n",
      "       [[-1.0582322 , -1.4043428 , -1.305454  ],\n",
      "        [-0.61323285, -0.84809357, -0.6873994 ],\n",
      "        [-0.58851063, -0.8110103 , -0.9717045 ],\n",
      "        ...,\n",
      "        [ 0.93190366,  0.93190366,  0.93190366],\n",
      "        [ 0.93190366,  0.93190366,  0.93190366],\n",
      "        [ 0.93190366,  0.93190366,  0.93190366]],\n",
      "\n",
      "       [[-0.90989906, -1.2560096 , -1.2065653 ],\n",
      "        [-0.7492049 , -0.9964267 , -0.84809357],\n",
      "        [-0.5143441 , -0.73684376, -0.90989906],\n",
      "        ...,\n",
      "        [ 0.93190366,  0.93190366,  0.93190366],\n",
      "        [ 0.93190366,  0.93190366,  0.93190366],\n",
      "        [ 0.93190366,  0.93190366,  0.93190366]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-1.5526758 , -1.5279536 , -1.5155926 ],\n",
      "        [-1.3178151 , -1.305454  , -1.2807318 ],\n",
      "        [-1.1571208 , -1.1447598 , -1.1200376 ],\n",
      "        ...,\n",
      "        [-0.60087174, -0.60087174, -0.6255939 ],\n",
      "        [-1.0087878 , -1.0087878 , -1.03351   ],\n",
      "        [-0.88517684, -0.88517684, -0.90989906]],\n",
      "\n",
      "       [[-1.181843  , -1.2189263 , -1.1447598 ],\n",
      "        [-0.9964267 , -0.9717045 , -0.95934343],\n",
      "        [-1.2683707 , -1.2560096 , -1.2312875 ],\n",
      "        ...,\n",
      "        [-0.32892773, -0.32892773, -0.366011  ],\n",
      "        [-0.4896219 , -0.4896219 , -0.46489972],\n",
      "        [-0.13115025, -0.13115025, -0.18059462]],\n",
      "\n",
      "       [[-1.1571208 , -1.1323987 , -1.1323987 ],\n",
      "        [-1.1200376 , -1.0953155 , -1.0829543 ],\n",
      "        [-1.1447598 , -1.1200376 , -1.0953155 ],\n",
      "        ...,\n",
      "        [-0.32892773, -0.32892773, -0.366011  ],\n",
      "        [-0.40309426, -0.40309426, -0.39073318],\n",
      "        [-0.08170588, -0.08170588, -0.13115025]]], dtype=float32)>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n",
      "    outputs = [\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n",
      "    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n",
      "    return ops.convert_to_tensor(value, dtype=dtype)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[-1.2930928 , -1.6268424 , -1.4290649 ],\n",
      "        [-0.5267052 , -0.77392703, -0.5637885 ],\n",
      "        [-0.6626772 , -0.88517684, -1.0582322 ],\n",
      "        ...,\n",
      "        [ 0.93190366,  0.93190366,  0.93190366],\n",
      "        [ 0.93190366,  0.93190366,  0.93190366],\n",
      "        [ 0.93190366,  0.93190366,  0.93190366]],\n",
      "\n",
      "       [[-1.0582322 , -1.4043428 , -1.305454  ],\n",
      "        [-0.61323285, -0.84809357, -0.6873994 ],\n",
      "        [-0.58851063, -0.8110103 , -0.9717045 ],\n",
      "        ...,\n",
      "        [ 0.93190366,  0.93190366,  0.93190366],\n",
      "        [ 0.93190366,  0.93190366,  0.93190366],\n",
      "        [ 0.93190366,  0.93190366,  0.93190366]],\n",
      "\n",
      "       [[-0.90989906, -1.2560096 , -1.2065653 ],\n",
      "        [-0.7492049 , -0.9964267 , -0.84809357],\n",
      "        [-0.5143441 , -0.73684376, -0.90989906],\n",
      "        ...,\n",
      "        [ 0.93190366,  0.93190366,  0.93190366],\n",
      "        [ 0.93190366,  0.93190366,  0.93190366],\n",
      "        [ 0.93190366,  0.93190366,  0.93190366]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-1.5526758 , -1.5279536 , -1.5155926 ],\n",
      "        [-1.3178151 , -1.305454  , -1.2807318 ],\n",
      "        [-1.1571208 , -1.1447598 , -1.1200376 ],\n",
      "        ...,\n",
      "        [-0.60087174, -0.60087174, -0.6255939 ],\n",
      "        [-1.0087878 , -1.0087878 , -1.03351   ],\n",
      "        [-0.88517684, -0.88517684, -0.90989906]],\n",
      "\n",
      "       [[-1.181843  , -1.2189263 , -1.1447598 ],\n",
      "        [-0.9964267 , -0.9717045 , -0.95934343],\n",
      "        [-1.2683707 , -1.2560096 , -1.2312875 ],\n",
      "        ...,\n",
      "        [-0.32892773, -0.32892773, -0.366011  ],\n",
      "        [-0.4896219 , -0.4896219 , -0.46489972],\n",
      "        [-0.13115025, -0.13115025, -0.18059462]],\n",
      "\n",
      "       [[-1.1571208 , -1.1323987 , -1.1323987 ],\n",
      "        [-1.1200376 , -1.0953155 , -1.0829543 ],\n",
      "        [-1.1447598 , -1.1200376 , -1.0953155 ],\n",
      "        ...,\n",
      "        [-0.32892773, -0.32892773, -0.366011  ],\n",
      "        [-0.40309426, -0.40309426, -0.39073318],\n",
      "        [-0.08170588, -0.08170588, -0.13115025]]], dtype=float32)>\n",
      "\n",
      "\n",
      "2022-09-21 10:55:33.626953: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 1.2501386 ,  1.2640423 ,  0.3185944 ],\n",
      "        [-1.349843  , -1.349843  , -1.349843  ],\n",
      "        [-1.349843  , -1.349843  , -1.349843  ],\n",
      "        ...,\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ],\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ],\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ]],\n",
      "\n",
      "       [[-0.20974411, -0.32097328,  0.6522819 ],\n",
      "        [-1.349843  , -1.349843  , -1.349843  ],\n",
      "        [ 1.0554876 ,  0.95816207,  1.7228626 ],\n",
      "        ...,\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ],\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ],\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ]],\n",
      "\n",
      "       [[ 2.1955867 ,  2.1955867 ,  2.1955867 ],\n",
      "        [ 2.1955867 ,  2.1955867 ,  2.1955867 ],\n",
      "        [ 0.5549564 ,  0.81912565,  0.94425845],\n",
      "        ...,\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ],\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ],\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.37658787, -0.37658787, -0.37658787],\n",
      "        [-0.44610608, -0.44610608, -0.44610608],\n",
      "        [-0.5156243 , -0.5156243 , -0.5156243 ],\n",
      "        ...,\n",
      "        [-0.36268422, -0.33487692, -0.20974411],\n",
      "        [-0.5156243 , -0.36268422, -0.27926233],\n",
      "        [-0.73808265, -0.61294985, -0.52952796]],\n",
      "\n",
      "       [[-0.58514255, -0.5990462 , -0.5990462 ],\n",
      "        [-0.55733526, -0.5712389 , -0.5712389 ],\n",
      "        [-0.34878057, -0.34878057, -0.34878057],\n",
      "        ...,\n",
      "        [-0.64075714, -0.58514255, -0.50172067],\n",
      "        [-0.52952796, -0.5434316 , -0.44610608],\n",
      "        [-0.9744446 , -0.87711906, -0.76588994]],\n",
      "\n",
      "       [[-0.47391337, -0.43220243, -0.43220243],\n",
      "        [-0.47391337, -0.43220243, -0.43220243],\n",
      "        [-0.36268422, -0.36268422, -0.36268422],\n",
      "        ...,\n",
      "        [-0.50172067, -0.44610608, -0.36268422],\n",
      "        [-0.44610608, -0.43220243, -0.34878057],\n",
      "        [-0.55733526, -0.36268422, -0.33487692]]], dtype=float32)>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n",
      "    outputs = [\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n",
      "    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n",
      "    return ops.convert_to_tensor(value, dtype=dtype)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 1.2501386 ,  1.2640423 ,  0.3185944 ],\n",
      "        [-1.349843  , -1.349843  , -1.349843  ],\n",
      "        [-1.349843  , -1.349843  , -1.349843  ],\n",
      "        ...,\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ],\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ],\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ]],\n",
      "\n",
      "       [[-0.20974411, -0.32097328,  0.6522819 ],\n",
      "        [-1.349843  , -1.349843  , -1.349843  ],\n",
      "        [ 1.0554876 ,  0.95816207,  1.7228626 ],\n",
      "        ...,\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ],\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ],\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ]],\n",
      "\n",
      "       [[ 2.1955867 ,  2.1955867 ,  2.1955867 ],\n",
      "        [ 2.1955867 ,  2.1955867 ,  2.1955867 ],\n",
      "        [ 0.5549564 ,  0.81912565,  0.94425845],\n",
      "        ...,\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ],\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ],\n",
      "        [ 1.5699224 ,  1.5699224 ,  1.5699224 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.37658787, -0.37658787, -0.37658787],\n",
      "        [-0.44610608, -0.44610608, -0.44610608],\n",
      "        [-0.5156243 , -0.5156243 , -0.5156243 ],\n",
      "        ...,\n",
      "        [-0.36268422, -0.33487692, -0.20974411],\n",
      "        [-0.5156243 , -0.36268422, -0.27926233],\n",
      "        [-0.73808265, -0.61294985, -0.52952796]],\n",
      "\n",
      "       [[-0.58514255, -0.5990462 , -0.5990462 ],\n",
      "        [-0.55733526, -0.5712389 , -0.5712389 ],\n",
      "        [-0.34878057, -0.34878057, -0.34878057],\n",
      "        ...,\n",
      "        [-0.64075714, -0.58514255, -0.50172067],\n",
      "        [-0.52952796, -0.5434316 , -0.44610608],\n",
      "        [-0.9744446 , -0.87711906, -0.76588994]],\n",
      "\n",
      "       [[-0.47391337, -0.43220243, -0.43220243],\n",
      "        [-0.47391337, -0.43220243, -0.43220243],\n",
      "        [-0.36268422, -0.36268422, -0.36268422],\n",
      "        ...,\n",
      "        [-0.50172067, -0.44610608, -0.36268422],\n",
      "        [-0.44610608, -0.43220243, -0.34878057],\n",
      "        [-0.55733526, -0.36268422, -0.33487692]]], dtype=float32)>\n",
      "\n",
      "\n",
      "2022-09-21 10:55:33.629327: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 0.00714847, -0.04636787, -0.15340054],\n",
      "        [ 0.03390664, -0.0196097 , -0.22029597],\n",
      "        [ 0.11418115,  0.06066481, -0.12664238],\n",
      "        ...,\n",
      "        [-0.1935378 , -0.20691688,  0.14093931],\n",
      "        [-0.18015872, -0.15340054,  0.04728572],\n",
      "        [-0.23367505, -0.1935378 ,  0.03390664]],\n",
      "\n",
      "       [[-0.05974695, -0.07312604, -0.1935378 ],\n",
      "        [-0.08650512, -0.11326329, -0.32732865],\n",
      "        [ 0.08742297,  0.07404389, -0.14002146],\n",
      "        ...,\n",
      "        [-0.11326329, -0.00623062,  0.22121382],\n",
      "        [-0.20691688, -0.1935378 ,  0.04728572],\n",
      "        [-0.42098224, -0.39422408, -0.14002146]],\n",
      "\n",
      "       [[ 0.38176283,  0.26135108,  0.18107657],\n",
      "        [ 0.11418115, -0.00623062, -0.18015872],\n",
      "        [-0.07312604, -0.1935378 , -0.36746588],\n",
      "        ...,\n",
      "        [-0.14002146, -0.0196097 ,  0.14093931],\n",
      "        [-0.7822175 , -0.64842665, -0.4343613 ],\n",
      "        [-0.32732865, -0.38084498,  0.03390664]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.34070772, -0.34070772, -0.34070772],\n",
      "        [-0.2871914 , -0.2871914 , -0.2871914 ],\n",
      "        [-0.32732865, -0.32732865, -0.32732865],\n",
      "        ...,\n",
      "        [-0.7420803 , -0.5949103 , -0.5146358 ],\n",
      "        [-0.35408682, -0.23367505, -0.15340054],\n",
      "        [-0.23367505, -0.07312604, -0.12664238]],\n",
      "\n",
      "       [[-0.4477404 , -0.4477404 , -0.4477404 ],\n",
      "        [-0.20691688, -0.20691688, -0.20691688],\n",
      "        [-0.30057046, -0.30057046, -0.30057046],\n",
      "        ...,\n",
      "        [-0.5949103 , -0.541394  , -0.47449857],\n",
      "        [-0.38084498, -0.2871914 , -0.1935378 ],\n",
      "        [-0.4343613 , -0.24705413, -0.24705413]],\n",
      "\n",
      "       [[-0.31394956, -0.31394956, -0.31394956],\n",
      "        [-0.31394956, -0.31394956, -0.31394956],\n",
      "        [-0.31394956, -0.31394956, -0.31394956],\n",
      "        ...,\n",
      "        [-0.36746588, -0.35408682, -0.24705413],\n",
      "        [-0.42098224, -0.40760314, -0.2738123 ],\n",
      "        [-0.5949103 , -0.541394  , -0.47449857]]], dtype=float32)>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n",
      "    outputs = [\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n",
      "    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n",
      "    return ops.convert_to_tensor(value, dtype=dtype)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[ 0.00714847, -0.04636787, -0.15340054],\n",
      "        [ 0.03390664, -0.0196097 , -0.22029597],\n",
      "        [ 0.11418115,  0.06066481, -0.12664238],\n",
      "        ...,\n",
      "        [-0.1935378 , -0.20691688,  0.14093931],\n",
      "        [-0.18015872, -0.15340054,  0.04728572],\n",
      "        [-0.23367505, -0.1935378 ,  0.03390664]],\n",
      "\n",
      "       [[-0.05974695, -0.07312604, -0.1935378 ],\n",
      "        [-0.08650512, -0.11326329, -0.32732865],\n",
      "        [ 0.08742297,  0.07404389, -0.14002146],\n",
      "        ...,\n",
      "        [-0.11326329, -0.00623062,  0.22121382],\n",
      "        [-0.20691688, -0.1935378 ,  0.04728572],\n",
      "        [-0.42098224, -0.39422408, -0.14002146]],\n",
      "\n",
      "       [[ 0.38176283,  0.26135108,  0.18107657],\n",
      "        [ 0.11418115, -0.00623062, -0.18015872],\n",
      "        [-0.07312604, -0.1935378 , -0.36746588],\n",
      "        ...,\n",
      "        [-0.14002146, -0.0196097 ,  0.14093931],\n",
      "        [-0.7822175 , -0.64842665, -0.4343613 ],\n",
      "        [-0.32732865, -0.38084498,  0.03390664]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.34070772, -0.34070772, -0.34070772],\n",
      "        [-0.2871914 , -0.2871914 , -0.2871914 ],\n",
      "        [-0.32732865, -0.32732865, -0.32732865],\n",
      "        ...,\n",
      "        [-0.7420803 , -0.5949103 , -0.5146358 ],\n",
      "        [-0.35408682, -0.23367505, -0.15340054],\n",
      "        [-0.23367505, -0.07312604, -0.12664238]],\n",
      "\n",
      "       [[-0.4477404 , -0.4477404 , -0.4477404 ],\n",
      "        [-0.20691688, -0.20691688, -0.20691688],\n",
      "        [-0.30057046, -0.30057046, -0.30057046],\n",
      "        ...,\n",
      "        [-0.5949103 , -0.541394  , -0.47449857],\n",
      "        [-0.38084498, -0.2871914 , -0.1935378 ],\n",
      "        [-0.4343613 , -0.24705413, -0.24705413]],\n",
      "\n",
      "       [[-0.31394956, -0.31394956, -0.31394956],\n",
      "        [-0.31394956, -0.31394956, -0.31394956],\n",
      "        [-0.31394956, -0.31394956, -0.31394956],\n",
      "        ...,\n",
      "        [-0.36746588, -0.35408682, -0.24705413],\n",
      "        [-0.42098224, -0.40760314, -0.2738123 ],\n",
      "        [-0.5949103 , -0.541394  , -0.47449857]]], dtype=float32)>\n",
      "\n",
      "\n",
      "2022-09-21 10:55:33.633366: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        ...,\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n",
      "\n",
      "       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        ...,\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n",
      "\n",
      "       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        ...,\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        ...,\n",
      "        [ 1.651318  ,  2.0487971 ,  2.7714868 ],\n",
      "        [ 1.651318  ,  1.5429145 ,  0.7298887 ],\n",
      "        [ 1.651318  ,  1.8139231 ,  2.2114024 ]],\n",
      "\n",
      "       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        ...,\n",
      "        [ 1.651318  ,  2.0849316 ,  2.6992178 ],\n",
      "        [ 1.651318  ,  1.3803093 ,  0.49501452],\n",
      "        [ 1.651318  ,  1.8500576 ,  1.8319904 ]],\n",
      "\n",
      "       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        ...,\n",
      "        [ 1.651318  ,  2.121066  ,  2.7714868 ],\n",
      "        [ 1.651318  ,  1.2899731 ,  0.38661107],\n",
      "        [ 1.651318  ,  1.8861921 ,  2.03073   ]]], dtype=float32)>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n",
      "    outputs = [\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n",
      "    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n",
      "    return ops.convert_to_tensor(value, dtype=dtype)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        ...,\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n",
      "\n",
      "       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        ...,\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n",
      "\n",
      "       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        ...,\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        ...,\n",
      "        [ 1.651318  ,  2.0487971 ,  2.7714868 ],\n",
      "        [ 1.651318  ,  1.5429145 ,  0.7298887 ],\n",
      "        [ 1.651318  ,  1.8139231 ,  2.2114024 ]],\n",
      "\n",
      "       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        ...,\n",
      "        [ 1.651318  ,  2.0849316 ,  2.6992178 ],\n",
      "        [ 1.651318  ,  1.3803093 ,  0.49501452],\n",
      "        [ 1.651318  ,  1.8500576 ,  1.8319904 ]],\n",
      "\n",
      "       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        [-0.5348182 , -0.5348182 , -0.5348182 ],\n",
      "        ...,\n",
      "        [ 1.651318  ,  2.121066  ,  2.7714868 ],\n",
      "        [ 1.651318  ,  1.2899731 ,  0.38661107],\n",
      "        [ 1.651318  ,  1.8861921 ,  2.03073   ]]], dtype=float32)>\n",
      "\n",
      "\n",
      "2022-09-21 10:55:33.633519: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[-0.9251155 , -0.9251155 , -0.4812083 ],\n",
      "        [-0.3958415 , -0.49828166,  0.11635912],\n",
      "        [ 1.7041811 ,  1.7041811 ,  2.0627215 ],\n",
      "        ...,\n",
      "        [-0.10559449,  0.09928577,  0.11635912],\n",
      "        [-0.3958415 , -0.22510797, -0.08852114],\n",
      "        [ 0.03099235,  0.18465254,  0.47489956]],\n",
      "\n",
      "       [[-0.9251155 , -0.9251155 , -0.4812083 ],\n",
      "        [-0.41291487, -0.49828166,  0.09928577],\n",
      "        [ 1.7041811 ,  1.7041811 ,  2.0627215 ],\n",
      "        ...,\n",
      "        [-0.46413493, -0.27632803, -0.15681456],\n",
      "        [ 0.21879925,  0.40660617,  0.59441304],\n",
      "        [ 0.6627065 ,  0.83344   ,  1.1407604 ]],\n",
      "\n",
      "       [[-0.9251155 , -0.9251155 , -0.4812083 ],\n",
      "        [-0.3958415 , -0.49828166,  0.11635912],\n",
      "        [ 1.7041811 ,  1.7041811 ,  2.0456483 ],\n",
      "        ...,\n",
      "        [-0.10559449,  0.0480657 ,  0.30416602],\n",
      "        [ 0.543193  ,  0.71392655,  0.98710024],\n",
      "        [ 0.8163667 ,  0.9529535 ,  1.2432005 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.20803462, -0.20803462, -0.17388791],\n",
      "        [-0.24218133, -0.24218133, -0.20803462],\n",
      "        [-0.2592547 , -0.2592547 , -0.22510797],\n",
      "        ...,\n",
      "        [-0.87389547, -0.8226754 , -0.805602  ],\n",
      "        [-0.87389547, -0.8226754 , -0.805602  ],\n",
      "        [-0.87389547, -0.8226754 , -0.805602  ]],\n",
      "\n",
      "       [[-0.19096126, -0.19096126, -0.1397412 ],\n",
      "        [-0.27632803, -0.27632803, -0.22510797],\n",
      "        [-0.2592547 , -0.2592547 , -0.20803462],\n",
      "        ...,\n",
      "        [-0.87389547, -0.8226754 , -0.7885287 ],\n",
      "        [-0.87389547, -0.805602  , -0.77145535],\n",
      "        [-0.83974874, -0.7885287 , -0.7373086 ]],\n",
      "\n",
      "       [[-0.17388791, -0.17388791, -0.1397412 ],\n",
      "        [-0.27632803, -0.27632803, -0.24218133],\n",
      "        [-0.2592547 , -0.2592547 , -0.22510797],\n",
      "        ...,\n",
      "        [-0.87389547, -0.8226754 , -0.805602  ],\n",
      "        [-0.87389547, -0.805602  , -0.805602  ],\n",
      "        [-0.8568221 , -0.805602  , -0.7885287 ]]], dtype=float32)>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n",
      "    outputs = [\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n",
      "    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n",
      "    return ops.convert_to_tensor(value, dtype=dtype)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\n",
      "array([[[-0.9251155 , -0.9251155 , -0.4812083 ],\n",
      "        [-0.3958415 , -0.49828166,  0.11635912],\n",
      "        [ 1.7041811 ,  1.7041811 ,  2.0627215 ],\n",
      "        ...,\n",
      "        [-0.10559449,  0.09928577,  0.11635912],\n",
      "        [-0.3958415 , -0.22510797, -0.08852114],\n",
      "        [ 0.03099235,  0.18465254,  0.47489956]],\n",
      "\n",
      "       [[-0.9251155 , -0.9251155 , -0.4812083 ],\n",
      "        [-0.41291487, -0.49828166,  0.09928577],\n",
      "        [ 1.7041811 ,  1.7041811 ,  2.0627215 ],\n",
      "        ...,\n",
      "        [-0.46413493, -0.27632803, -0.15681456],\n",
      "        [ 0.21879925,  0.40660617,  0.59441304],\n",
      "        [ 0.6627065 ,  0.83344   ,  1.1407604 ]],\n",
      "\n",
      "       [[-0.9251155 , -0.9251155 , -0.4812083 ],\n",
      "        [-0.3958415 , -0.49828166,  0.11635912],\n",
      "        [ 1.7041811 ,  1.7041811 ,  2.0456483 ],\n",
      "        ...,\n",
      "        [-0.10559449,  0.0480657 ,  0.30416602],\n",
      "        [ 0.543193  ,  0.71392655,  0.98710024],\n",
      "        [ 0.8163667 ,  0.9529535 ,  1.2432005 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.20803462, -0.20803462, -0.17388791],\n",
      "        [-0.24218133, -0.24218133, -0.20803462],\n",
      "        [-0.2592547 , -0.2592547 , -0.22510797],\n",
      "        ...,\n",
      "        [-0.87389547, -0.8226754 , -0.805602  ],\n",
      "        [-0.87389547, -0.8226754 , -0.805602  ],\n",
      "        [-0.87389547, -0.8226754 , -0.805602  ]],\n",
      "\n",
      "       [[-0.19096126, -0.19096126, -0.1397412 ],\n",
      "        [-0.27632803, -0.27632803, -0.22510797],\n",
      "        [-0.2592547 , -0.2592547 , -0.20803462],\n",
      "        ...,\n",
      "        [-0.87389547, -0.8226754 , -0.7885287 ],\n",
      "        [-0.87389547, -0.805602  , -0.77145535],\n",
      "        [-0.83974874, -0.7885287 , -0.7373086 ]],\n",
      "\n",
      "       [[-0.17388791, -0.17388791, -0.1397412 ],\n",
      "        [-0.27632803, -0.27632803, -0.24218133],\n",
      "        [-0.2592547 , -0.2592547 , -0.22510797],\n",
      "        ...,\n",
      "        [-0.87389547, -0.8226754 , -0.805602  ],\n",
      "        [-0.87389547, -0.805602  , -0.805602  ],\n",
      "        [-0.8568221 , -0.805602  , -0.7885287 ]]], dtype=float32)>\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\narray([[[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n\n       ...,\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [ 1.651318  ,  2.0487971 ,  2.7714868 ],\n        [ 1.651318  ,  1.5429145 ,  0.7298887 ],\n        [ 1.651318  ,  1.8139231 ,  2.2114024 ]],\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [ 1.651318  ,  2.0849316 ,  2.6992178 ],\n        [ 1.651318  ,  1.3803093 ,  0.49501452],\n        [ 1.651318  ,  1.8500576 ,  1.8319904 ]],\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [ 1.651318  ,  2.121066  ,  2.7714868 ],\n        [ 1.651318  ,  1.2899731 ,  0.38661107],\n        [ 1.651318  ,  1.8861921 ,  2.03073   ]]], dtype=float32)>\nTraceback (most recent call last):\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n    outputs = [\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n    return ops.convert_to_tensor(value, dtype=dtype)\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n    return func(*args, **kwargs)\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n    raise ValueError(\n\nValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\narray([[[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n\n       ...,\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [ 1.651318  ,  2.0487971 ,  2.7714868 ],\n        [ 1.651318  ,  1.5429145 ,  0.7298887 ],\n        [ 1.651318  ,  1.8139231 ,  2.2114024 ]],\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [ 1.651318  ,  2.0849316 ,  2.6992178 ],\n        [ 1.651318  ,  1.3803093 ,  0.49501452],\n        [ 1.651318  ,  1.8500576 ,  1.8319904 ]],\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [ 1.651318  ,  2.121066  ,  2.7714868 ],\n        [ 1.651318  ,  1.2899731 ,  0.38661107],\n        [ 1.651318  ,  1.8861921 ,  2.03073   ]]], dtype=float32)>\n\n\n\t [[{{function_node __inference__map_fucntion_3787}}{{node EagerPyFunc}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m i, m \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    765\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 766\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    767\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    768\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 749\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    750\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    751\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    752\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    754\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    755\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3017\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3015\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3016\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 3017\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   3018\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m   3019\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7208\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7209\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\narray([[[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n\n       ...,\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [ 1.651318  ,  2.0487971 ,  2.7714868 ],\n        [ 1.651318  ,  1.5429145 ,  0.7298887 ],\n        [ 1.651318  ,  1.8139231 ,  2.2114024 ]],\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [ 1.651318  ,  2.0849316 ,  2.6992178 ],\n        [ 1.651318  ,  1.3803093 ,  0.49501452],\n        [ 1.651318  ,  1.8500576 ,  1.8319904 ]],\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [ 1.651318  ,  2.121066  ,  2.7714868 ],\n        [ 1.651318  ,  1.2899731 ,  0.38661107],\n        [ 1.651318  ,  1.8861921 ,  2.03073   ]]], dtype=float32)>\nTraceback (most recent call last):\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in _call\n    outputs = [\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 164, in <listcomp>\n    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 131, in _convert\n    return ops.convert_to_tensor(value, dtype=dtype)\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n    return func(*args, **kwargs)\n\n  File \"/home/yesilyurt/miniconda3/envs/tf_seg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1599, in convert_to_tensor\n    raise ValueError(\n\nValueError: Tensor conversion requested dtype uint8 for Tensor with dtype float32: <tf.Tensor: shape=(512, 512, 3), dtype=float32, numpy=\narray([[[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ]],\n\n       ...,\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [ 1.651318  ,  2.0487971 ,  2.7714868 ],\n        [ 1.651318  ,  1.5429145 ,  0.7298887 ],\n        [ 1.651318  ,  1.8139231 ,  2.2114024 ]],\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [ 1.651318  ,  2.0849316 ,  2.6992178 ],\n        [ 1.651318  ,  1.3803093 ,  0.49501452],\n        [ 1.651318  ,  1.8500576 ,  1.8319904 ]],\n\n       [[-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        [-0.5348182 , -0.5348182 , -0.5348182 ],\n        ...,\n        [ 1.651318  ,  2.121066  ,  2.7714868 ],\n        [ 1.651318  ,  1.2899731 ,  0.38661107],\n        [ 1.651318  ,  1.8861921 ,  2.03073   ]]], dtype=float32)>\n\n\n\t [[{{function_node __inference__map_fucntion_3787}}{{node EagerPyFunc}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "i, m = train_dataset.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Camvid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "\n",
    "\n",
    "source = \"http://web4.cs.ucl.ac.uk/staff/g.brostow/MotionSegRecData/files/701_StillsRaw_full.zip\"\n",
    "target = '701_StillsRaw_full.zip'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reporthook(count, block_size, total_size):\n",
    "    global start_time\n",
    "    if count == 0:\n",
    "        start_time = time.time()\n",
    "        return\n",
    "    duration = time.time() - start_time\n",
    "    progress_size = int(count * block_size)\n",
    "    speed = progress_size / (1024.**2 * duration)\n",
    "    percent = count * block_size * 100. / total_size\n",
    "    sys.stdout.write(\"\\r%d%% | %d MB | %.2f MB/s | %d sec elapsed\" %\n",
    "                    (percent, progress_size / (1024.**2), speed, duration))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "if not os.path.isdir('701_StillsRaw') and not os.path.isfile('701_StillsRaw_full.zip'):\n",
    "    \n",
    "    if (sys.version_info < (3, 0)):\n",
    "        import urllib\n",
    "        urllib.urlretrieve(source, target, reporthook)\n",
    "    \n",
    "    else:\n",
    "        import urllib.request\n",
    "        urllib.request.urlretrieve(source, target, reporthook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(source, target,lambda c,b,t: print(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from tensorflow.keras.utils import image_dataset_from_directory\n",
    "#from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "#from tensorflow_addons.image import rotate\n",
    "#from glob import glob\n",
    "#from tf_seg.data import DataLoader\n",
    "\n",
    "from tf_seg.data.aug import jax_random_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"dataset/camvid/train/0001TP_009210.png\"\n",
    "mask_path = \"dataset/camvid/train_labels/0001TP_009210_L.png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_content = tf.io.read_file(image_path)\n",
    "mask_content = tf.io.read_file(mask_path)\n",
    "\n",
    "image = tf.image.decode_png(image_content, channels=3)\n",
    "mask = tf.image.decode_png(mask_content, channels=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, m = image.numpy(), mask.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "jax_random_crop(i,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Union\n",
    "from warnings import warn\n",
    "\n",
    "import os \n",
    "from omegaconf import DictConfig, ListConfig, OmegaConf\n",
    "\n",
    "from tf_seg.config import get_config\n",
    "from tf_seg.models import get_model_builder\n",
    "\n",
    "from tf_seg.data import get_camvid_data_loader\n",
    "from tf_seg.data import get_data_loader    \n",
    "\n",
    "#from tf_seg.config import CONFIG_LOAD_STYLE_LIB,CONFIG_FILE_EXTENSION,CONFIG_STORE_PATH\n",
    "#from tf_seq.config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config function\n",
    "\n",
    "# parameter\n",
    "config_name = \"test\"\n",
    "config_path = None\n",
    "\n",
    "# constant parameters get from constant.py\n",
    "# CONFIG_STORE_PATH = \"./config\"\n",
    "# CONFIG_FILE_EXTENSION = \".yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(config_name, config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get_model function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder = get_model_builder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_seg.models import model_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "from tensorflow.keras.models import Model\n",
    "from omegaconf import DictConfig, ListConfig\n",
    "\n",
    "\n",
    "def pascal_case_to_snake_case(s:str)->str:\n",
    "    \"\"\"Convert class name to snake case name.\"\"\"\n",
    "    return \"\".join([\"_\"+i.lower() if i.isupper() else i for i in s]).lstrip(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_builder(config:Union[DictConfig, ListConfig])->Model:\n",
    "    \"\"\"Get keras model from config file\"\"\"\n",
    "    class_name = pascal_case_to_snake_case(config.model.class_name)\n",
    "    model = model_lib[class_name]\n",
    "\n",
    "    model_config = config.model.copy()    \n",
    "    model_config.pop(\"class_name\")\n",
    "    \n",
    "    return model(**model_config) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders =get_data_loader(config,train_data=True,val_data=True,test_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = loaders[0].load_data(batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset.take(1):\n",
    "    plt.imshow(tf.squeeze(i[1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get_aug function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_seg.transformers import get_transformer\n",
    "from tf_seg.utils import AlbumentatiosWrapper\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(config_name, config_path)\n",
    "aug_config = config.augmentation\n",
    "aug_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = get_transformer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_config = config.augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = get_transformer(config)\n",
    "lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get_config function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(\n",
    "    config_filename: Optional[str] = None, config_path: Optional[Union[Path, str]] = None, config_file_extension: Optional[str] = CONFIG_FILE_EXTENSION, config_store_path: \"str\" = CONFIG_STORE_PATH\n",
    ") -> Union[DictConfig, ListConfig]:\n",
    "\n",
    "    \"\"\"\n",
    "    Get configurable parameters from config file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config_filename : str, optional\n",
    "        Name of the config file. The default is None.\n",
    "    config_path : Union[Path, str], optional\n",
    "        Path of the config file. The default is None.\n",
    "    config_file_extension : str, optional\n",
    "        File extension of the config file. The default is \".yaml\".\n",
    "    config_store_path : str\n",
    "        Path of the config store. The default is \"./config\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    config : Union[DictConfig, ListConfig]\n",
    "        Configurable parameters.\n",
    "\n",
    "    \"\"\"\n",
    "    assert os.path.isdir(config_store_path), f\"{config_store_path} is not a directory\"\n",
    "\n",
    "    if config_path is None:\n",
    "        config_path = Path(f\"{config_store_path}/{config_name}{config_file_extension}\")\n",
    "\n",
    "    config = OmegaConf.load(config_path)\n",
    "\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(config_name)\n",
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_base_config_exist(config: Union[DictConfig, ListConfig]) -> bool:\n",
    "    \"\"\"check if base config exist in config file\"\"\"\n",
    "\n",
    "    if \"base\" in config.keys():\n",
    "        if config[\"base\"] is None:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def load_yaml_style_config(yaml_path: str) -> Union[DictConfig, ListConfig]:\n",
    "    \"\"\"load config from yaml file\"\"\"\n",
    "    assert os.path.isfile(yaml_path), f\"{yaml_path} is not a file\"\n",
    "    config = OmegaConf.load(yaml_path)\n",
    "    return config\n",
    "\n",
    "\n",
    "def load_module_style_config(module_path: str) -> Union[DictConfig, ListConfig]:\n",
    "    \"\"\"load config from python module\"\"\"\n",
    "    raise NotImplementedError(\"load_mdule_style_config is not implemented\")\n",
    "\n",
    "\n",
    "def load_base_config(config):\n",
    "    \"\"\"load base config from base parameter\"\"\"\n",
    "\n",
    "    # find file extension\n",
    "    load_style = os.path.splitext(config[\"base\"])[1]\n",
    "\n",
    "    print(\"load style :\", load_style)\n",
    "\n",
    "    if load_style == \".py\":  # module style\n",
    "        raise NotImplementedError(\"load_style is not implemented\")\n",
    "\n",
    "    elif load_style == \".yaml\" or load_style == \".yml\":\n",
    "        return load_yaml_style_config(config[\"base\"])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"load_style is not valid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extact_config(config: Union[DictConfig, ListConfig]) -> Union[DictConfig, ListConfig]:\n",
    "    \"\"\"\"Extract parent base config and merge with child configs\"\"\"\n",
    "\n",
    "    first_config_keys = list(config.keys())\n",
    "    buffer_config_dict = {}\n",
    "    f_config = config.copy()\n",
    "\n",
    "    for first_k in first_config_keys:\n",
    "\n",
    "        sub_config = f_config[first_k]\n",
    "\n",
    "        if check_base_config_exist(sub_config):\n",
    "            buffer_config = load_base_config(sub_config)\n",
    "            sub_config.pop(\"base\")\n",
    "            buffer_config.merge_with(sub_config)\n",
    "            sub_config = buffer_config\n",
    "\n",
    "        else:\n",
    "            if \"base\" in sub_config.keys():\n",
    "                sub_config.pop(\"base\")\n",
    "\n",
    "        f_config[first_k] = sub_config\n",
    "\n",
    "    return f_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_config[\"augmentation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_config.pop(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b_k in b.keys():\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.merge_with(sub_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# from tensorflow.keras import initializers\n",
    "# from tensorflow.keras.layers import Conv2D,Conv1D\n",
    "# from tensorflow.keras.layers import BatchNormalization\n",
    "# from tensorflow.keras.layers import Layer\n",
    "# from tensorflow.keras.losses import Loss\n",
    "# from tensorflow.keras import Model\n",
    "# from tensorflow.keras import initializers\n",
    "\n",
    "from tf_seg.models import Unet,ResUnet\n",
    "from tf_seg.backbones import get_backbone \n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.python.keras.engine import keras_tensor\n",
    "from tensorflow.keras.layers import Conv2D,Conv2DTranspose,Concatenate\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Done Work**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = None #\"EfficientNetB1\"#\"ResNet50\"\n",
    "\n",
    "n_filters = [8, 16, 32, 64, 128,256]#, 512, 1024]\n",
    "model=Unet(backbone=backbone,n_filters=n_filters,input_shape=(256, 256,3)).build_model()\n",
    "\n",
    "out = model(np.ones((1,256,256,3)))\n",
    "keras.utils.plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append(\"appendix/keras-unet-collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet_collection import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.unet_2d((1024, 1024, 3), [16, 32,312], n_labels=2,backbone=\"EfficientNetB1\")\n",
    "#model = models.unet_2d((1024, 1024, 3), [64, 128, 256, 512, 1024], n_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input((1024,1024,3))\n",
    "#backbone = get_backbone(\"ResNet50\",\"imagenet\",input_tensor,depth=4,freeze_backbone=True,freeze_batch_norm=False)\n",
    "backbone = get_backbone(\"ResNet50V2\",\"imagenet\",input_tensor,depth=5,freeze_backbone=True,freeze_batch_norm=False)\n",
    "backbone(input_tensor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model= Unet(backbone=\"ResNet50\",n_filters=[16,32,64]).build_model()\n",
    "model= Unet(backbone=None,n_filters=[32,64,128,256,512,1024]).build_model()\n",
    "\n",
    "\n",
    "connection_list = model[0]\n",
    "decode_n_filters= model[1]\n",
    "inputs = model[2]\n",
    "bridge = model[3]\n",
    "\n",
    "final_activation = \"relu\"\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = \"ResNet50\"\n",
    "n_filters = [32,64,128,256,512]\n",
    "#encoder_output= Unet(backbone=None,n_filters=[32,64,128,256,512]).build_model()\n",
    "encoder_output= Unet(backbone=backbone,n_filters=n_filters).build_model()\n",
    "\n",
    "inputs = encoder_output[0]\n",
    "bridge = encoder_output[-1]\n",
    "connection_list = encoder_output[1:-1][::-1]\n",
    "inputs,bridge,connection_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if backbone is None:\n",
    "#     decoder_n_filters = n_filters[:-1][::-1]\n",
    "decoder_n_filters = n_filters[:-1][::-1]\n",
    "decoder_n_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = bridge\n",
    "\n",
    "for n,c in enumerate(connection_list):\n",
    "\n",
    "    print(\"connection :\",c.shape,n)\n",
    "    d=Conv2DTranspose(decoder_n_filters[n], (3, 3), padding=\"same\", strides=(2, 2))(d)\n",
    "    print(d.shape)\n",
    "    d = Concatenate()([d,c])\n",
    "    print(\"after concat :\",d.shape)\n",
    "    d = Unet()._conv_block(d,decoder_n_filters[n],pool=False)\n",
    "\n",
    "print(\"last shape :\",d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = len(connection_list)\n",
    "\n",
    "if len(decoder_n_filters)>depth:\n",
    "    n_remain_block = len(decoder_n_filters) - depth\n",
    "    print(decoder_n_filters[-1*n_remain_block:])\n",
    "\n",
    "    remain_decoder_n_filter=decoder_n_filters[-1*n_remain_block:]\n",
    "    for fltr in remain_decoder_n_filter:\n",
    "        print(fltr)\n",
    "        d=Conv2DTranspose(fltr, (3, 3), padding=\"same\", strides=(2, 2))(d)\n",
    "        d = Unet()._conv_block(d,fltr,pool=False)\n",
    "    \n",
    "print(\"last shape :\", d.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not backbone is None:\n",
    "# not bigger n_filters 6\n",
    "#  not smaller n_filters 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Optional, List\n",
    "from omegaconf import DictConfig, ListConfig\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Trainer:\n",
    "    \"Trainer class for training a model\"\n",
    "\n",
    "    def __init__(self, config: Union[DictConfig, ListConfig], model: Model,\n",
    "                 train_data: Dataset, val_data: Optional[Dataset] = None,\n",
    "                 callbacks: Optional[List[Callback]] = None) -> None:\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        config: Union[DictConfig, ListConfig]\n",
    "            Configuration for training\n",
    "        model: tf.keras.Model\n",
    "            Model to be trained\n",
    "        train_data: tf.data.Dataset\n",
    "            Dataset for training\n",
    "        val_data: tf.data.Dataset,default: None\n",
    "            Dataset for validation\n",
    "        callbacks: tf.keras.callbacks.Callback,default: None\n",
    "            keras Callbacks for training\n",
    "\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.model:Model = model\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.callbacks = callbacks\n",
    "\n",
    "        self._check_params()\n",
    "\n",
    "    def _check_params(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "        \"Train tf keras model\"\n",
    "        \n",
    "        self.model.fit(self.train_data,\n",
    "                       epochs=self.config.epochs,\n",
    "                       callbacks=self.callbacks,\n",
    "                       validation_data=self.val_data)\n",
    "\n",
    "    def evaluate(self):\n",
    "        if self.val_data: \n",
    "            self.model.evaluate(self.val_data)\n",
    "        else:\n",
    "            raise ValueError(\"Validation data is not provided\")\n",
    "            \n",
    "    def save(self, filename):\n",
    "        self.model.save(filename)\n",
    "\n",
    "    def test(self, data):\n",
    "        self.model.evaluate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Starting training; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop training; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "    def on_test_begin(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Start testing; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_test_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop testing; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_predict_begin(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Start predicting; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_predict_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop predicting; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Training: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Training: end of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_test_batch_begin(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Evaluating: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Evaluating: end of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_predict_batch_begin(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Predicting: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_predict_batch_end(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Predicting: end of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau,Callback\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay,PiecewiseConstantDecay\n",
    "from tf_seg.utils import  snake_case_to_pascal_case\n",
    "from tf_seg.callbacks import get_callbacks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "config_name = \"test\"\n",
    "config_path = None\n",
    "config = get_config(config_name, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_callbacks(config.callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\"a\":12}\n",
    "b = {\"b\":12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.less(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_config  = config.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c_config.keys():\n",
    "    print(snake_case_to_pascal_case(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 100\n",
    "x1 = np.random.randint(1,10,(size,10,1))\n",
    "y1 = x1.max(axis=1) #+ np.random.rand(size)\n",
    "x1 = np.concatenate((x1,np.ones((size,1,1))),axis=1)\n",
    "\n",
    "\n",
    "x2 = np.random.randint(1,10,(size,10,1))\n",
    "y2 = x2.min(axis=1) #+ np.random.rand(size)\n",
    "x2 = np.concatenate((x2,np.zeros((size,1,1))),axis=1)\n",
    "\n",
    "x = np.concatenate((x1,x2))\n",
    "y = np.concatenate((y1,y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_dim):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(1, input_dim=input_dim,use_bias=False))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Nadam(learning_rate=0.001),\n",
    "        loss=tf.keras.losses.mae,\n",
    "        metrics=[\"mae\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model(input_dim=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomCallbacks(keras.callbacks.Callback):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.epoch_level = 10\n",
    "#     def on_train_begin(self,logs=None):\n",
    "#         print(self.model)\n",
    "#         #print(logs.keys())\n",
    "            \n",
    "#     def on_epoch_end(self,epoch,logs=None):\n",
    "#         #print(\"training epoch end:\",logs.keys())\n",
    "#         print(self.dataset)\n",
    "#         if epoch% self.epoch_level==0:\n",
    "#             print(f\"Epoch : {epoch} , loss : {logs}\")\n",
    "#     # def on_batch_end(self,batch,logs=None):\n",
    "#     #     print(\"     => training batch end:\",logs.keys())\n",
    "class MeasureTotalTime(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        print(self.model)\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.total_time = time.time() - self.start_time\n",
    "        print(\"Total training time: %s\" % self.total_time)\n",
    "\n",
    "\n",
    "class UpdateBestWeights(Callback):\n",
    "    def __init__(self, metric_name: str, mode:str):\n",
    "        \"\"\"\n",
    "        Update best weights on end of training\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        metric_name : str\n",
    "            Name of the metric to use for determining the best weights\n",
    "        mode : str\n",
    "            One of {min, max}\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "       \n",
    "        self.metric_name = metric_name\n",
    "        self.best_weights = None\n",
    "        self.best_metric = None\n",
    "\n",
    "        if mode == 'max':\n",
    "            self.monitor_op = np.greater\n",
    "            self.best_metric = -np.Inf\n",
    "        elif mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "            self.best_metric = np.Inf\n",
    "        else:\n",
    "            raise ValueError('Mode {} not understood'.format(mode))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metric = logs[self.metric_name]\n",
    "        if self.monitor_op(metric, self.best_metric):\n",
    "            self.best_metric = metric\n",
    "            self.best_weights = self.model.get_weights()\n",
    "\n",
    "    def on_train_end(self, logs=None):       \n",
    "        self.model.set_weights(self.best_weights)\n",
    "     \n",
    "\n",
    "\n",
    "update_model = UpdateBestWeights(metric_name='val_loss',mode='min')\n",
    "tl_tm = MeasureTotalTime() \n",
    "lr = LearningRateScheduler(PolynomialDecay(0.9,100,power=1),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y,validation_data=(x,y), epochs=10,batch_size=120,callbacks=[tl_tm,update_model],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.losses.mae(y.reshape(-1), model.predict(x).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x,y,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf_seg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5e709fba4ec28a962ef38eca2f061f4aade275491a1bcbd59d8088c0d7c25f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
