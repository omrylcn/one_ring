{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQGhhQVvIazA",
        "outputId": "f6e14d0c-32e3-4ced-e39a-513ec1b3ec8e"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mlflow\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,backend as K\n",
        "from tensorflow.keras.metrics import Recall,Precision\n",
        "import  tensorflow_addons as tfa\n",
        "import logging\n",
        "\n",
        "import one_ring\n",
        "from one_ring.config import get_config\n",
        "from one_ring.data import get_data_loader,get_camvid_data_loader\n",
        "from one_ring.transformers import Transformer\n",
        "from one_ring.models import Unet,DeepLabV3Plus,AttUnet\n",
        "from one_ring.losses import FocalTverskyLoss, DiceLoss,BASNetHybridLoss,JaccardLoss,LogCoshDiceLoss,ComboLoss,BoundaryDoULoss\n",
        "from one_ring.train import Trainer\n",
        "from one_ring.callbacks import get_callbacks\n",
        "from one_ring.losses import FocalTverskyLoss, DiceLoss,LogCoshDiceLoss,binary_focal_loss,categorical_focal_loss,FocalLoss,sym_unified_focal_loss,SymmetricUnifiedFocalLoss\n",
        "from one_ring.metrics import DiceScore,JaccardScore\n",
        "from one_ring.callbacks import ORLearningRateCallback\n",
        "from one_ring.scheduler import ORLearningRateScheduler\n",
        "from one_ring.utils import generate_overlay_image,calculate_confusion_matrix_and_report,plot_history_dict\n",
        "\n",
        "print('tensorflow version :',tf.__version__)\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"always\")\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # create a dateste\n",
        "    # X = np.random.normal(1,2,(100,224,224,3)).astype(np.float32)\n",
        "    # y = np.random.normal(1,2,(100,224,224,12)).astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "    # # create a dataset\n",
        "    # dataset = tf.data.Dataset.from_tensor_slices((X,y))\n",
        "\n",
        "    # dataset = dataset.batch(10)\n",
        "\n",
        "    # # split the dataset\n",
        "    # train_dataset = dataset.take(70)\n",
        "    # val_dataset = dataset.skip(70)\n",
        "\n",
        "\n",
        "    # # create most simple  model\n",
        "    # model = keras.Sequential()\n",
        "    # model.add(layers.Input(shape=(224,224,3)))\n",
        "    # model.add(layers.Conv2D(1,3,activation='relu',padding='same'))\n",
        "\n",
        "    # model.summary()\n",
        "\n",
        "\n",
        "    # model.compile(optimizer='adam',loss=BoundaryDoULoss(1),metrics=[DiceScore()])\n",
        "    # model.fit(train_dataset,epochs=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def log_albumentation(cfg,prefix):\n",
        "   \n",
        "    #     # assume composee\n",
        "    #     tr_cfg = cfg[\"transform\"][\"transforms\"]\n",
        "\n",
        "    #     for t in tr_cfg:\n",
        "    #         # Use the transformation class name as part of the parameter name\n",
        "    #         class_name = t['__class_fullname__'].split('.')[-1]  # Extracts the class name without the full module path\n",
        "    #         param_name = f\"{prefix}_{class_name}\"\n",
        "            \n",
        "    #         # Prepare a dictionary with the parameters, excluding '__class_fullname__'\n",
        "    #         params = {k: v for k, v in t.items() if k != '__class_fullname__'}\n",
        "            \n",
        "    #         # Log the parameters of each transformation as a separate parameter, converting the dictionary to a JSON string\n",
        "    #         mlflow.log_param(param_name,params)\n",
        "\n",
        "\n",
        "    # prefix = \"aug\"\n",
        "    # # Log the augmentation type\n",
        "    # mlflow.log_param(f\"{prefix}_type\", cfg.aug_type)\n",
        "\n",
        "    # # for train\n",
        "\n",
        "    # log_albumentation(cfg[\"train\"],prefix=\"aug_train\")\n",
        "    # log_albumentation(cfg[\"test\"],prefix=\"aug_test\")\n",
        "\n",
        "\n",
        "    # For the complex nested structure like cfg.train, consider logging key aspects or entire structure as a JSON string\n",
        "    # Given the request to adjust, we're focusing on the transformations specifically"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = get_config(config_filename=\"spinal_cord\")\n",
        "cfg = config[\"augmentation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "config = get_config(config_filename=\"spinal_cord\")\n",
        "train_data_loader, val_data_loader = get_data_loader(config.data, train_data=True, val_data=True, test_data=False)\n",
        "\n",
        "\n",
        "IM_SIZE = config.data[\"image_size\"][0]\n",
        "aug_config = {\n",
        "    \"aug_prob\": 0.1,\n",
        "    #\"random_contrast_limit\": 0.4,\n",
        "    #\"random_brightness_limit\": 0.3,\n",
        "    \"rotate_limit\": 10,\n",
        "}\n",
        "tracing_object = {\"mlflow\":{\"augmentation\":aug_config}}\n",
        "\n",
        "train_transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(IM_SIZE, IM_SIZE),\n",
        "        #A.GaussNoise(var_limit=(10.0, 50.0), p=aug_config[\"aug_prob\"]),\n",
        "        #A.CLAHE(p=aug_config[\"aug_prob\"]),\n",
        "       # A.RandomBrightnessContrast(p=aug_config[\"aug_prob\"], brightness_limit=aug_config[\"random_brightness_limit\"], contrast_limit=aug_config[\"random_contrast_limit\"]),\n",
        "       # A.RandomGamma(p=aug_config[\"aug_prob\"]),\n",
        "        A.HorizontalFlip(p=aug_config[\"aug_prob\"]),\n",
        "        A.VerticalFlip(p=aug_config[\"aug_prob\"]),\n",
        "        A.Rotate(limit=aug_config[\"rotate_limit\"], p=aug_config[\"aug_prob\"]),\n",
        "        A.RandomSizedCrop(min_max_height=(180, 224), height=IM_SIZE, width=IM_SIZE, p=aug_config[\"aug_prob\"]),\n",
        "    ]\n",
        ")\n",
        "test_transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(IM_SIZE, IM_SIZE),\n",
        "        # A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]\n",
        ")\n",
        "\n",
        "tr_transforms_object = Transformer(config.augmentation, \"train\", train_transforms)#.from_dict()\n",
        "ts_transforms_object = Transformer(config.augmentation, \"test\", test_transforms)#.from_dict()\n",
        "train_dataset = train_data_loader.load_data(transform_func=tr_transforms_object)\n",
        "val_dataset = val_data_loader.load_data(transform_func=ts_transforms_object, shuffle=False)\n",
        "\n",
        "#callbacks = get_callbacks(config.callbacks)\n",
        "callbacks = {}\n",
        "\n",
        "steps_per_epoch = len(train_dataset)\n",
        "lr_schedule = ORLearningRateScheduler(\n",
        "    strategy=config.train.lr_scheduler[\"name\"],\n",
        "    total_epochs=config.train.epochs,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    **config.train.lr_scheduler[\"params\"]\n",
        ").get()\n",
        "callbacks[\"lr_sch\"] = ORLearningRateCallback(lr_schedule)\n",
        "\n",
        "\n",
        "log_dir = f\"board_logs/{config.train.experiment_name}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "callbacks[\"tensorboard\"] = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_images=True, write_graph=True, update_freq='epoch')#, profile_batch='500,520')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_name = \"boundary_dou_loss\"\n",
        "params = {\n",
        "    \"gamma\": 4/3,\n",
        "    \"alpha\": 0.4,\n",
        "    \"loss_weight\": 0.4\n",
        "}\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "loss_dict = {\n",
        "    \"focal_loss\": FocalLoss,\n",
        "    \"dice_loss\": DiceLoss,\n",
        "    \"jaccard_loss\": JaccardLoss,\n",
        "    \"log_cosh_dice_loss\": LogCoshDiceLoss,\n",
        "    \"focal_tversky_loss\": FocalTverskyLoss,\n",
        "    \"symmetric_unified_focal_loss\": SymmetricUnifiedFocalLoss,\n",
        "    \"boundary_dou_loss\": BoundaryDoULoss\n",
        "}\n",
        "\n",
        "metrics_dict= {\n",
        "    \"recal\":Recall,\n",
        "    \"precision\":Precision,\n",
        "    \"jaccard_score\":JaccardScore\n",
        "}\n",
        "\n",
        "loss = loss_dict[loss_name](**params)\n",
        "metrics = [m() for m in metrics_dict.values()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#model = AttUnet(**config.model).build_model()\n",
        "model = DeepLabV3Plus(**config.model).build_model()\n",
        "#model = Unet(**config.model).build_model()\n",
        "\n",
        "#model.summary()\n",
        "#keras.utils.plot_model(model, show_shapes=True, to_file=f'{model.name}_model.png')\n",
        "trainer = Trainer(config, model, train_dataset, val_dataset, callbacks=list(callbacks.values()), metrics=metrics,loss=loss,tracing_object=tracing_object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.load(\"models/20240908202630\",setup_components = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #trainer.compile()\n",
        "# print(trainer.loss)\n",
        "# print(trainer.optimizer)\n",
        "# print(trainer.callbacks)\n",
        "# print(trainer.metrics)\n",
        "history = trainer.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.finalize_training()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.load(trainer.save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.loaded_metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.models.load_model(\"models/20240908190040/saved_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.load(\"models/20240908190040\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.saver.save(\n",
        "    \"test\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Saving a model\n",
        "saver = ModelSaver(model, config, processors)\n",
        "saver.save(\n",
        "    path=\"model_directory\",\n",
        "    train_ds=train_dataset,\n",
        "    val_ds=val_dataset,\n",
        "    custom_objects=custom_objects,\n",
        "    additional_metadata={\"training_iteration\": 1, \"best_val_loss\": 0.1}\n",
        ")\n",
        "\n",
        "# Loading a model\n",
        "loaded_data = saver.load(\n",
        "    path=\"model_directory\",\n",
        "    compile=True,\n",
        "    custom_objects=custom_objects\n",
        ")\n",
        "loaded_model = loaded_data['model']\n",
        "loaded_metadata = loaded_data['metadata']\n",
        "loaded_processors = loaded_data['processors']\n",
        "\n",
        "# Updating a model after retraining\n",
        "saver.update_model(\n",
        "    new_model=retrained_model,\n",
        "    path=\"model_directory\",\n",
        "    additional_metadata={\"training_iteration\": 2, \"best_val_loss\": 0.05}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = trainer.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = tf.keras.models.load_model(\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#model.evaluate(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlflow.log_param(\"loss_name\",loss_name)\n",
        "[mlflow.log_param(f\"loss_{k}\",v) for k,v in params.items()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.end()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_binary_differece(target, pred):\n",
        "    # Calculate differences\n",
        "    tp = (pred == 1) & (target == 1)  # True Positives\n",
        "    fp = (pred == 1) & (target == 0)  # False Positives\n",
        "    fn = (pred == 0) & (target == 1)  # False Negatives\n",
        "\n",
        "    # Create an RGB image where each difference is colored differently\n",
        "    # Initialize with zeros (black) for the background\n",
        "    diff_image = np.zeros(target.shape + (3,), dtype=np.uint8)\n",
        "\n",
        "    # Assign colors (R, G, B)\n",
        "    # True Positives in green\n",
        "    diff_image[tp] = [0, 255, 0]\n",
        "    # False Positives in red\n",
        "    diff_image[fp] = [255, 0, 0]\n",
        "    # False Negatives in blue\n",
        "    diff_image[fn] = [0, 0, 255]\n",
        "\n",
        "    diff_image_corrected = np.squeeze(diff_image, axis=2)\n",
        "\n",
        "    return diff_image_corrected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "threshold = 0.6\n",
        "for i in val_dataset:\n",
        "    pred_logits = model.predict(i[0])\n",
        "\n",
        "    for n in range(len(i[0])): \n",
        "        image = i[0][n].numpy().astype(np.uint8)\n",
        "        pred_logit = pred_logits[n]\n",
        "     #   print(pred_logit.shape)\n",
        "        pred_value = np.where(pred_logit>threshold,1,0).reshape(224,224,1)\n",
        "        pred_mask = (pred_value*255).astype(np.uint8)\n",
        "\n",
        "    #    print(pred_mask.shape, image.shape)\n",
        "        overlay = generate_overlay_image(pred_mask, image, alpha=0.3)\n",
        "        target = i[1][n].numpy()\n",
        "        np.unique(target,return_counts=True)    \n",
        "\n",
        "        plt.figure(figsize=(20,10))\n",
        "        plt.subplot(1,3,1)\n",
        "        plt.title('target')\n",
        "        plt.imshow(target)\n",
        "        plt.grid(True)\n",
        "        plt.subplot(1,3,2)\n",
        "        plt.title('pred')\n",
        "        plt.imshow(pred_value)\n",
        "        plt.grid(True)\n",
        "        plt.subplot(1,3,3)\n",
        "        plt.imshow(overlay)\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "        #print(pred_value.shape, target.shape)\n",
        "\n",
        "        cm,cr = calculate_confusion_matrix_and_report(pred_value, target)\n",
        "        print(cm)\n",
        "        print(cr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy = tf.keras.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target = i[1][n]\n",
        "pred_logit.shape,target.shape\n",
        "\n",
        "a = accuracy(tf.squeeze(target),tf.squeeze(pred_logit))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss = DiceLoss()\n",
        "from one_ring.losses import dice_coef"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_value = (pred_logit>0.5).astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dice_coef(target,pred_logit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dice_coef(target,pred_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove dimension\n",
        "tf.squeeze(target).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sequence Exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = get_config(config_filename=\"spinal_cord\")\n",
        "train_data_loader, val_data_loader = get_data_loader(config.data, train_data=True, val_data=True, test_data=False)\n",
        "\n",
        "IM_SIZE = config.data[\"image_size\"][0]\n",
        "\n",
        "aug_config = {\n",
        "    \"aug_prob\": 0.1,\n",
        "    #\"random_contrast_limit\": 0.4,\n",
        "    #\"random_brightness_limit\": 0.3,\n",
        "    \"rotate_limit\": 10,\n",
        "}\n",
        "tracing_object = {\"mlflow\":{\"augmentation\":aug_config}}\n",
        "\n",
        "train_transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(IM_SIZE, IM_SIZE),\n",
        "        #A.GaussNoise(var_limit=(10.0, 50.0), p=aug_config[\"aug_prob\"]),\n",
        "        #A.CLAHE(p=aug_config[\"aug_prob\"]),\n",
        "       # A.RandomBrightnessContrast(p=aug_config[\"aug_prob\"], brightness_limit=aug_config[\"random_brightness_limit\"], contrast_limit=aug_config[\"random_contrast_limit\"]),\n",
        "       # A.RandomGamma(p=aug_config[\"aug_prob\"]),\n",
        "        A.HorizontalFlip(p=aug_config[\"aug_prob\"]),\n",
        "        A.VerticalFlip(p=aug_config[\"aug_prob\"]),\n",
        "        A.Rotate(limit=aug_config[\"rotate_limit\"], p=aug_config[\"aug_prob\"]),\n",
        "        A.RandomSizedCrop(min_max_height=(180, 224), height=IM_SIZE, width=IM_SIZE, p=aug_config[\"aug_prob\"]),\n",
        "    ]\n",
        ")\n",
        "test_transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(IM_SIZE, IM_SIZE),\n",
        "        # A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]\n",
        ")\n",
        "\n",
        "tr_transforms_object = Transformer(config.augmentation, \"train\", train_transforms)#.from_dict()\n",
        "ts_transforms_object = Transformer(config.augmentation, \"test\", test_transforms)#.from_dict()\n",
        "train_dataset = train_data_loader.load_data(transform_func=tr_transforms_object)\n",
        "val_dataset = val_data_loader.load_data(transform_func=ts_transforms_object, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for gamma in [5/4,4/3,3/2,2]:\n",
        "    for i in range(1,6):\n",
        "\n",
        "\n",
        "        callbacks = get_callbacks(config.callbacks)\n",
        "\n",
        "        steps_per_epoch = len(train_dataset)\n",
        "        lr_schedule = ORLearningRateScheduler(\n",
        "            strategy=config.trainer.lr_scheduler[\"name\"],\n",
        "            total_epochs=config.trainer.epochs,\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            **config.trainer.lr_scheduler[\"params\"]\n",
        "        ).get()\n",
        "\n",
        "\n",
        "\n",
        "        log_dir = f\"board_logs/{config.trainer.experiment_name}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        callbacks[\"tensorboard\"] = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_images=True, write_graph=True, update_freq='epoch')#, profile_batch='500,520')\n",
        "\n",
        "        #callbacks[\"lr_sch\"]= tf.keras.callbacks.LearningRateScheduler(cosine_decay_scheduler)\n",
        "\n",
        "        # callbacks[\"lr_sch\"] = OneRingLearningRateScheduler(cosine_decay_scheduler)\n",
        "        callbacks[\"lr_sch\"] = ORLearningRateCallback(lr_schedule)\n",
        "\n",
        "\n",
        "        #gamma = 4/3\n",
        "        alpha = 0.2*i\n",
        "\n",
        "        losses = [FocalTverskyLoss(gamma=gamma,alpha=alpha)]\n",
        "        #losses = [LogCoshDiceLoss()]\n",
        "        # losses = [BASNetHybridLoss()]\n",
        "        # losses = [JaccardLoss()]\n",
        "        #losses = [DiceLoss()]\n",
        "\n",
        "        #losses  = [ComboLoss(alpha=alpha)]\n",
        "        metrics = [Recall(),Precision()]\n",
        "\n",
        "        model = AttUnet(**config.model).build_model()\n",
        "        #model = Unet(**config.model).build_model()\n",
        "        #model.summary()\n",
        "        #keras.utils.plot_model(model, show_shapes=True, to_file='model.png')\n",
        "        trainer = Trainer(config, model, train_dataset, val_dataset, callbacks=callbacks, metrics=metrics,losses=losses,tracing_object=tracing_object)\n",
        "        trainer.fit(continue_training=True)\n",
        "        model = trainer._model\n",
        "        print(alpha,model.evaluate(val_dataset))\n",
        "\n",
        "        mlflow.log_param(\"loss_alpha\",alpha)\n",
        "        mlflow.log_param(\"loss_gamma\",gamma)\n",
        "\n",
        "        trainer.end()\n",
        "        \n",
        "        [m.reset_states() for m in metrics]\n",
        "        \n",
        "        del model, trainer,losses\n",
        "        tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# scores = model.evaluate(val_dataset, verbose=1)\n",
        "\n",
        "# save_path = f\"best/\"\n",
        "# os.makedirs(save_path,exist_ok=True)\n",
        "# model_name = save_path+f\"d-{config.data.name}-dsc-{scores[1]:.4f}\"\n",
        "# #model.save(model_name)\n",
        "# trainer.save(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_binary_differece(target, pred):\n",
        "    # Calculate differences\n",
        "    tp = (pred == 1) & (target == 1)  # True Positives\n",
        "    fp = (pred == 1) & (target == 0)  # False Positives\n",
        "    fn = (pred == 0) & (target == 1)  # False Negatives\n",
        "\n",
        "    # Create an RGB image where each difference is colored differently\n",
        "    # Initialize with zeros (black) for the background\n",
        "    diff_image = np.zeros(target.shape + (3,), dtype=np.uint8)\n",
        "\n",
        "    # Assign colors (R, G, B)\n",
        "    # True Positives in green\n",
        "    diff_image[tp] = [0, 255, 0]\n",
        "    # False Positives in red\n",
        "    diff_image[fp] = [255, 0, 0]\n",
        "    # False Negatives in blue\n",
        "    diff_image[fn] = [0, 0, 255]\n",
        "\n",
        "    diff_image_corrected = np.squeeze(diff_image, axis=2)\n",
        "\n",
        "    return diff_image_corrected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "threshold = 0.6\n",
        "for i in val_dataset:\n",
        "    pred_logits = model.predict(i[0])\n",
        "\n",
        "\n",
        "\n",
        "    for n in range(len(i[0])): \n",
        "        image = i[0][n].numpy().astype(np.uint8)\n",
        "        pred_logit = pred_logits[n]\n",
        "     #   print(pred_logit.shape)\n",
        "        pred_value = np.where(pred_logit>threshold,1,0).reshape(224,224,1)\n",
        "        pred_mask = (pred_value*255).astype(np.uint8)\n",
        "\n",
        "    #    print(pred_mask.shape, image.shape)\n",
        "        overlay = generate_overlay_image(pred_mask, image, alpha=0.3)\n",
        "        target = i[1][n].numpy()\n",
        "        np.unique(target,return_counts=True)    \n",
        "\n",
        "        plt.figure(figsize=(20,10))\n",
        "        plt.subplot(1,3,1)\n",
        "        plt.title('target')\n",
        "        plt.imshow(target)\n",
        "        plt.grid(True)\n",
        "        plt.subplot(1,3,2)\n",
        "        plt.title('pred')\n",
        "        plt.imshow(pred_value)\n",
        "        plt.grid(True)\n",
        "        plt.subplot(1,3,3)\n",
        "        plt.imshow(overlay)\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "        #print(pred_value.shape, target.shape)\n",
        "\n",
        "        cm,cr = calculate_confusion_matrix_and_report(pred_value, target)\n",
        "        print(cm)\n",
        "        print(cr)\n",
        "\n",
        "        # diff_image_corrected = calculate_binary_differece(target, pred_value)\n",
        "        # im = diff_image_corrected[150:350, 150:350]\n",
        "        \n",
        "        # plt.figure(figsize=(10,10))\n",
        "        # plt.imshow(im,cmap='gray')\n",
        "        # plt.grid(True)\n",
        "        # plt.show()\n",
        "\n",
        "\n",
        "    \n",
        "        \n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1T1hRjlQ-OMq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbryLV7n-Nzz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
