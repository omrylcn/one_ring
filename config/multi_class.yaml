# not using tuple !
#base: null
trainer:
  experiment_name: test_camvid
  save_model_path: loss_focal_tversky_exp
  save_model: false
  epochs: 10
  lr: {"start": 0.001, "end": 0.0001}
  optimizer: { name: adam, params: {} }
  losses:  null #[dice_loss]  #[[dice_loss] #[binary_crossentropy]
  metrics: [dice_score]
  verbose: 1
  deploy_onnx: false
  lr_scheduler: 
    "name": cosine_decay_with_warmup  #, cosine_decay_restarts,cosine_decay_no_warmup
    "params": {"min_lr": 0.0001,"max_lr": 0.003, "warmup_epochs": 5}
    
data:
  base: null
  name: custom_camvid
  function_name: camvid #custom # it is used camvid dataset to generate binary data
  path: ./datasets/CamVid 
  classes: ["Animal", "Archway", "Bicyclist", "Bridge", "Building", "Car", "CartLuggagePram", "Child", "Column_Pole", "Fence", "LaneMkgsDriv", "LaneMkgsNonDriv", "Misc_Text", "MotorcycleScooter", "OtherMoving", "ParkingBlock", "Pedestrian", "Road", "RoadShoulder", "Sidewalk", "SignSymbol", "Sky", "SUVPickupTruck", "TrafficCone", "TrafficLight", "Train", "Tree", "Truck_Bus", "Tunnel", "VegetationMisc", "Void", "Wall"]
  normalizing: false
  palette: [[64,128,64],
            [192,0,128],
            [0,128, 192],
            [0, 128, 64],
            [128, 0, 0],
            [64, 0, 128],
            [64, 0, 192],
            [192, 128, 64],
            [192, 192, 128],
            [64, 64, 128],
            [128, 0, 192],
            [192, 0, 64],
            [128, 128, 64],
            [192, 0, 192],
            [128, 64, 64],
            [64, 192, 128],
            [64, 64, 0],
            [128, 64, 128],
            [128, 128, 192],
            [0, 0, 192],
            [192, 128, 128],
            [128, 128, 128],
            [64, 128,192],
            [0, 0, 64],
            [0, 64, 64],
            [192, 64, 128],
            [128, 128, 0],
            [192, 128, 192],
            [64, 0, 64],
            [192, 192, 0],
            [0, 0, 0],
            [64, 192, 0]]
  one_hot_encoding: true # target output shape
  background_adding: false # add target background class
  image_size: [224, 224]
  batch_size: 4 #
  output_type: [tf.float32, tf.float32] # this is for camvid data types after data processing
  channels: [3, 3] # image and mask channels

augmentation:
  base: null #./config/_base/aug_file.yaml
  aug_type: albumentations # only albumentations
  load_style: file # module
  train: 
    __version__: 1.3.1
    transform:
      __class_fullname__: Compose
      additional_targets: {}
      bbox_params: null
      is_check_shapes: true
      keypoint_params: null
      p: 1.0
      transforms:
      - __class_fullname__: Resize
        always_apply: false
        height: 224
        interpolation: 1
        p: 1
        width: 224
      - __class_fullname__: HorizontalFlip
        always_apply: false
        p: 0.1
      - __class_fullname__: VerticalFlip
        always_apply: false
        p: 0.1
      - __class_fullname__: Rotate
        always_apply: false
        border_mode: 4
        crop_border: false
        interpolation: 1
        limit:
        - -10
        - 10
        mask_value: null
        p: 0.1
        rotate_method: largest_box
        value: null
      - __class_fullname__: RandomSizedCrop
        always_apply: false
        height: 224
        interpolation: 1
        min_max_height:
        - 180
        - 224
        p: 0.1
        w2h_ratio: 1.0
        width: 224

  test:
    __version__: 1.3.1
    transform:
      __class_fullname__: Compose
      additional_targets: {}
      bbox_params: null
      is_check_shapes: true
      keypoint_params: null
      p: 1.0
      transforms:
      - __class_fullname__: Resize
        always_apply: false
        height: 224
        interpolation: 1
        p: 1
        width: 224

model:
  base: null
  name: AttUnet
  n_filters: [8,10,12,14,16] #[32, 48, 64, 96, 128] #[16,32,64,128,256] #[12,32,64,96,128] #[12, 24, 32, 48, 96] #[32,48,64,128,256] #[32, 64, 128,256] #[32,64,128,256,512]
  input_shape: [224, 224, 3]
  final_activation: softmax #sigmoid
  activation: relu
  backbone_name: EfficientNetB0  # "ResNet50", None
  pretrained: imagenet
  output_size: 32


callbacks:
  base: null
  measure_total_time: { class_name: MeasureTotalTime, params: {} }
  update_best_weights:
    {
      class_name: UpdateBestWeights,
      params: { metric_name: val_dice_score, mode: max },
    }
