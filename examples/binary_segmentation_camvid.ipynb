{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Road Segmentation**\n",
    "\n",
    "Using camvid dataset for road segmentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#from tf_seg.data import DataLoader\n",
    "from tf_seg.config import get_config\n",
    "from tf_seg.data import get_data_loader,get_camvid_data_loader\n",
    "from tf_seg.models import Unet\n",
    "from tf_seg.losses import FocalTverskyLoss,DiceLoss\n",
    "from tf_seg.metrics import DiceScore\n",
    "from tf_seg.train import Trainer\n",
    "from tf_seg.callbacks import get_callbacks\n",
    "from tf_seg.transformers import Transformer\n",
    "\n",
    "from tensorflow.keras.losses import binary_crossentropy,BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import binary_accuracy,BinaryAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config mananagment can be two ways: \n",
    "- First, you can use python dict object to configure the data,model etc.\n",
    "- Second, you can use a config file as yaml format. if you use this way, you must ```get_config``` function to get the config file and check if it is valid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camvid data config\n",
    "\n",
    "data_config = dict(\n",
    "    name=\"road_segmentation\",\n",
    "    function_name=\"camvid\",  # it is used camvid dataset to generate binary data\n",
    "    path=\"../dataset/camvid\",\n",
    "    classes=[\"Road\"],\n",
    "    normalizing=True,\n",
    "    palette=[(128, 64, 128)],\n",
    "    one_hot_encoding=True,  # target output shape\n",
    "    background_adding=False,  # add target background class\n",
    "    image_size=(512, 512),\n",
    "    batch_size=8,\n",
    "    # output_type=(\"tf.float32\", \"tf.float32\"),  # this is for camvid data types after data processing\n",
    "    channels=(3, 3),  # it is optional\n",
    ")\n",
    "\n",
    "model_config = dict(\n",
    "    # n_filters=[16, 32, 64, 128, 256],\n",
    "    # n_filters=[4, 8, 12, 16,24],\n",
    "    n_filters=[16, 24, 32, 64],  #\n",
    "    input_shape=[data_config[\"image_size\"][0], data_config[\"image_size\"][1], 3],\n",
    "    final_activation=\"sigmoid\",\n",
    "    activation=\"relu\",\n",
    "    backbone= \"EfficientNetB0\",# \"ResNet50\", None\n",
    "    pretrained=\"imagenet\",\n",
    "    output_size=1,\n",
    ")\n",
    "\n",
    "# we will load albermentations functions manually, so there is no need to all parameters like function \"path\"\n",
    "aug_config = dict(aug_type=\"albumentations\")\n",
    "# config file look like this\n",
    "\n",
    "# load_style: module # {module, file} # it find automatically\n",
    "# aug_type: albumentations\n",
    "# train:\n",
    "#    path: tf_seg.transformers.albumentations:get_train_transform\n",
    "#    parameters: { image_size: [512, 512], p: 0.5 }\n",
    "# val:\n",
    "#    path: tf_seg.transformers.albumentations:get_test_transform\n",
    "#    parameters: { image_size: [512, 512] }\n",
    "# test:\n",
    "#    path: #tf_seg.transformers.albumentations:get_test_transform\n",
    "#    parameters: { image_size: [512, 512] }\n",
    "\n",
    "\n",
    "trainer_config = dict(\n",
    "    epochs=20,\n",
    "    batch_size=8,\n",
    "    optimizer={\"name\": \"adam\", \"params\": {\"learning_rate\": 0.001}},\n",
    "    losses=[\"binary_crossentropy\"],\n",
    "    metrics=[\"binary_accuracy\"],\n",
    "    save_model=True,\n",
    "    save_name=\"test_efficientnetb0_binary_road\",\n",
    "    verbose=1,\n",
    "    deploy_onnx=True,\n",
    ")\n",
    "\n",
    "callbacks_config = dict(measure_total_time={\"class_name\": \"MeasureTotalTime\", \"params\": {}})\n",
    "\n",
    "config = dict(data=data_config, model=model_config, aug=aug_config, trainer=trainer_config, callbacks=callbacks_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_camvid_data_loader(data_config, train_data=True, val_data=True, test_data=False)\n",
    "# get_data_loader(data_config, train_data=True, val_data=True, test_data=False) #or, this is a selection function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader\n",
    "\n",
    "This function is support function getting a DataLoader object that is loading data from disk as tensorflow dataset. There are many special data loader functions for different dataset. Also, there is a custom data loader function for custom datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are three parts as train, val, test in camvid dataset\n",
    "train_data_loader, val_data_loader, test_data_loader = get_camvid_data_loader(data_config)\n",
    "# train_data_loader.load_data? # show docstring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset from data_loader object via load_data function\n",
    "train_dataset = train_data_loader.load_data()\n",
    "val_dataset = val_data_loader.load_data()\n",
    "test_dataset = test_data_loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_dataset.take(1):\n",
    "    print(i[0].shape)\n",
    "    print(i[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = i[0][0].numpy()\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(train_dataset=None, val_dataset=None, test_dataset=None):\n",
    "    \"support function to show data\"\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    if train_dataset:\n",
    "        for i, m in train_dataset.take(1):\n",
    "            plt.subplot(2, 3, 1)\n",
    "            plt.imshow(m[0])\n",
    "            plt.subplot(2, 3, 4)\n",
    "            plt.imshow(i[0].numpy())\n",
    "    if val_dataset:\n",
    "        for i, m in val_dataset.take(1):\n",
    "            plt.subplot(2, 3, 2)\n",
    "            plt.imshow(m[0])\n",
    "            plt.subplot(2, 3, 5)\n",
    "            plt.imshow(i[0].numpy())\n",
    "    if test_dataset:\n",
    "        for i, m in test_dataset.take(1):\n",
    "            plt.subplot(2, 3, 3)\n",
    "            plt.imshow(m[0])\n",
    "            plt.subplot(2, 3, 6)\n",
    "            plt.imshow(i[0].numpy())\n",
    "\n",
    "\n",
    "show_data(train_dataset, val_dataset, test_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With augmentation function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is ```albumentations``` function to augement the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_SIZE = data_config[\"image_size\"][0]\n",
    "\n",
    "\n",
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(IM_SIZE, IM_SIZE),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.RandomSizedCrop(min_max_height=(256, 256), height=IM_SIZE, width=IM_SIZE, p=0.5),\n",
    "                A.CenterCrop(height=IM_SIZE, width=IM_SIZE, p=0.5),\n",
    "                A.PadIfNeeded(min_height=IM_SIZE, min_width=IM_SIZE, p=0.5),\n",
    "            ],\n",
    "            p=1,\n",
    "        ),\n",
    "        A.OneOf([A.VerticalFlip(p=0.5), A.RandomRotate90(p=0.5), A.Transpose(p=0.5)]),\n",
    "        A.OneOf([A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.5), A.GridDistortion(p=0.5), A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=1)], p=0.8),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "test_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(IM_SIZE, IM_SIZE),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Transformer``` is a class to use albumentations fucntions or other augmentation packages with tf.data.Dataset.map function effectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_transforms_object = Transformer(aug_config, \"train\", train_transforms)\n",
    "ts_transforms_object = Transformer(aug_config, \"test\", test_transforms)\n",
    "\n",
    "# get datasets with augmentation\n",
    "\n",
    "train_dataset = train_data_loader.load_data(transform_func=tr_transforms_object)\n",
    "val_dataset = val_data_loader.load_data(transform_func=ts_transforms_object)\n",
    "test_dataset = test_data_loader.load_data(transform_func=ts_transforms_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(train_dataset, val_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_dataset.take(1):\n",
    "    print(i[0].shape)\n",
    "    print(i[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(**model_config).build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = get_callbacks(callbacks_config)\n",
    "callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_config = dict(model=model_config, data=data_config, trainer=trainer_config)\n",
    "trainer = Trainer(all_config, model, train_dataset, val_dataset, callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(continue_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_dataset.take(1):pass\n",
    "pred = model.predict(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(8):\n",
    "    r  = pred[a]\n",
    "    re = r>0.5\n",
    " \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(i[1][a])\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(re.astype(int))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14fd65a77c7a2c5efcd4f7ba6e068015b8f7e05adad28b56e1e2be17331d6d0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
