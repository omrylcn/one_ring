{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Road Segmentation**\n",
    "\n",
    "Using camvid dataset for road segmentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#from tf_seg.data import DataLoader\n",
    "from tf_seg.data.dataset import download_camvid_dataset\n",
    "from tf_seg.config import get_config\n",
    "from tf_seg.data import get_data_loader,get_camvid_data_loader\n",
    "from tf_seg.models import Unet,DeepLabV3Plus\n",
    "from tf_seg.losses import FocalTverskyLoss,DiceLoss\n",
    "from tf_seg.metrics import DiceScore\n",
    "from tf_seg.train import Trainer\n",
    "from tf_seg.callbacks import get_callbacks\n",
    "from tf_seg.transformers import Transformer\n",
    "\n",
    "from tensorflow.keras.losses import binary_crossentropy,BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import binary_accuracy,BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% | 574 MB | 0 sec elapsed"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/CamVid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m download_camvid_dataset()\n",
      "File \u001b[0;32m~/Desktop/tf_seg/tf_seg/examples/../tf_seg/data/dataset.py:42\u001b[0m, in \u001b[0;36mdownload_camvid_dataset\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     40\u001b[0m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39murlretrieve(url, filename\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marchive.zip\u001b[39m\u001b[39m\"\u001b[39m, reporthook \u001b[39m=\u001b[39m report_hook)\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(\u001b[39m\"\u001b[39m\u001b[39mdataset/camvid\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 42\u001b[0m     os\u001b[39m.\u001b[39;49mmkdir(\u001b[39m\"\u001b[39;49m\u001b[39mdataset/CamVid\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     43\u001b[0m \u001b[39mwith\u001b[39;00m zipfile\u001b[39m.\u001b[39mZipFile(\u001b[39m\"\u001b[39m\u001b[39marchive.zip\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m zip_ref:\n\u001b[1;32m     44\u001b[0m     zip_ref\u001b[39m.\u001b[39mextractall(\u001b[39m\"\u001b[39m\u001b[39mdataset/camvid\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/CamVid'"
     ]
    }
   ],
   "source": [
    "download_camvid_dataset()   # this function should call automatically in case of non-existence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config management can be two ways: \n",
    "- First, you can use python dict object to configure the data,model etc.\n",
    "- Second, you can use a config file as yaml format. if you use this way, you must ```get_config``` function to get the config file and check if it is valid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camvid data config\n",
    "\n",
    "data_config = dict(\n",
    "    name=\"road_segmentation\",\n",
    "    function_name=\"camvid\",  # it is used camvid dataset to generate binary data\n",
    "    path=\"../dataset/camvid\",\n",
    "    classes=[\"Road\"],\n",
    "    normalizing=True,\n",
    "    palette=[(128, 64, 128)],\n",
    "    one_hot_encoding=True,  # target output shape\n",
    "    background_adding=False,  # add target background class\n",
    "    image_size=(512, 512),\n",
    "    batch_size=8,\n",
    "    # output_type=(\"tf.float32\", \"tf.float32\"),  # this is for camvid data types after data processing\n",
    "    channels=(3, 3),  # it is optional\n",
    ")\n",
    "\n",
    "model_config = dict(\n",
    "    # n_filters=[16, 32, 64, 128, 256],\n",
    "    # n_filters=[4, 8, 12, 16,24],\n",
    "    n_filters=[16, 24, 32, 64],  #\n",
    "    input_shape=[data_config[\"image_size\"][0], data_config[\"image_size\"][1], 3],\n",
    "    final_activation=\"sigmoid\",\n",
    "    activation=\"relu\",\n",
    "    backbone= \"EfficientNetB0\",# \"ResNet50\", None\n",
    "    pretrained=\"imagenet\",\n",
    "    output_size=1,\n",
    ")\n",
    "\n",
    "# we will load albermentations functions manually, so there is no need to all parameters like function \"path\"\n",
    "aug_config = dict(aug_type=\"albumentations\")\n",
    "# config file look like this\n",
    "\n",
    "# load_style: module # {module, file} # it find automatically\n",
    "# aug_type: albumentations\n",
    "# train:\n",
    "#    path: tf_seg.transformers.albumentations:get_train_transform\n",
    "#    parameters: { image_size: [512, 512], p: 0.5 }\n",
    "# val:\n",
    "#    path: tf_seg.transformers.albumentations:get_test_transform\n",
    "#    parameters: { image_size: [512, 512] }\n",
    "# test:\n",
    "#    path: #tf_seg.transformers.albumentations:get_test_transform\n",
    "#    parameters: { image_size: [512, 512] }\n",
    "\n",
    "\n",
    "trainer_config = dict(\n",
    "    epochs=20,\n",
    "    batch_size=8,\n",
    "    optimizer={\"name\": \"adam\", \"params\": {\"learning_rate\": 0.001}},\n",
    "    losses=[\"binary_crossentropy\"],\n",
    "    metrics=[\"binary_accuracy\"],\n",
    "    save_model=True,\n",
    "    save_name=\"test_efficientnetb0_binary_road\",\n",
    "    verbose=1,\n",
    "    deploy_onnx=True,\n",
    ")\n",
    "\n",
    "callbacks_config = dict(measure_total_time={\"class_name\": \"MeasureTotalTime\", \"params\": {}})\n",
    "\n",
    "config = dict(data=data_config, model=model_config, aug=aug_config, trainer=trainer_config, callbacks=callbacks_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_camvid_data_loader(data_config, train_data=True, val_data=True, test_data=False)\n",
    "# get_data_loader(data_config, train_data=True, val_data=True, test_data=False) #or, this is a selection function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader\n",
    "\n",
    "This function is support function getting a DataLoader object that is loading data from disk as tensorflow dataset. There are many special data loader functions for different dataset. Also, there is a custom data loader function for custom datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Number of images and masks do not match!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# there are three parts as train, val, test in camvid dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_data_loader, val_data_loader, test_data_loader \u001b[39m=\u001b[39m get_camvid_data_loader(data_config)\n",
      "File \u001b[0;32m~/Desktop/tf_seg/tf_seg/examples/../tf_seg/data/loader_func.py:30\u001b[0m, in \u001b[0;36mget_camvid_data_loader\u001b[0;34m(data_config, train_data, val_data, test_data)\u001b[0m\n\u001b[1;32m     27\u001b[0m     train_image_paths \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(glob(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_config[\u001b[39m\"\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mtrain/*.png\u001b[39m\u001b[39m\"\u001b[39m)))\n\u001b[1;32m     28\u001b[0m     train_mask_paths \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(glob(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_config[\u001b[39m\"\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mtrain_labels/*.png\u001b[39m\u001b[39m\"\u001b[39m)))\n\u001b[0;32m---> 30\u001b[0m     train_data_loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m     31\u001b[0m         train_image_paths,\n\u001b[1;32m     32\u001b[0m         train_mask_paths,\n\u001b[1;32m     33\u001b[0m         name\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mtrain_\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m data_config[\u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m]),\n\u001b[1;32m     34\u001b[0m         image_size\u001b[39m=\u001b[39;49mdata_config[\u001b[39m\"\u001b[39;49m\u001b[39mimage_size\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     35\u001b[0m         normalizing\u001b[39m=\u001b[39;49mdata_config[\u001b[39m\"\u001b[39;49m\u001b[39mnormalizing\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     36\u001b[0m         batch_size\u001b[39m=\u001b[39;49mdata_config[\u001b[39m\"\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     37\u001b[0m         output_type\u001b[39m=\u001b[39;49moutput_type,  \u001b[39m# (image_output_type, mask_output_type),\u001b[39;49;00m\n\u001b[1;32m     38\u001b[0m         one_hot_encoding\u001b[39m=\u001b[39;49mdata_config[\u001b[39m\"\u001b[39;49m\u001b[39mone_hot_encoding\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     39\u001b[0m         channels\u001b[39m=\u001b[39;49mdata_config[\u001b[39m\"\u001b[39;49m\u001b[39mchannels\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     40\u001b[0m         palette\u001b[39m=\u001b[39;49mdata_config[\u001b[39m\"\u001b[39;49m\u001b[39mpalette\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     41\u001b[0m         background_adding\u001b[39m=\u001b[39;49mdata_config[\u001b[39m\"\u001b[39;49m\u001b[39mbackground_adding\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     44\u001b[0m     data_loader_list\u001b[39m.\u001b[39mappend(train_data_loader)\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m val_data:\n",
      "File \u001b[0;32m~/Desktop/tf_seg/tf_seg/examples/../tf_seg/data/data.py:104\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, image_paths, mask_paths, image_size, batch_size, channels, output_type, name, normalizing, extensions, one_hot_encoding, palette, background_adding, seed)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseed \u001b[39m=\u001b[39m seed\n\u001b[1;32m    103\u001b[0m \u001b[39m# check data ana get decode functions\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_data()\n",
      "File \u001b[0;32m~/Desktop/tf_seg/tf_seg/examples/../tf_seg/data/data.py:113\u001b[0m, in \u001b[0;36mDataLoader._check_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39mChecks the data for errors.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39m# TODO add logger check data information process\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \n\u001b[1;32m    112\u001b[0m \u001b[39m# check path\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_paths) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmask_paths) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_paths) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mNumber of images and masks do not match!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m \u001b[39m# check extensions\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextensions \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: Number of images and masks do not match!"
     ]
    }
   ],
   "source": [
    "# there are three parts as train, val, test in camvid dataset\n",
    "train_data_loader, val_data_loader, test_data_loader = get_camvid_data_loader(data_config)\n",
    "# train_data_loader.load_data? # show docstring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# generate dataset from data_loader object via load_data function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_dataset \u001b[39m=\u001b[39m train_data_loader\u001b[39m.\u001b[39mload_data()\n\u001b[1;32m      3\u001b[0m val_dataset \u001b[39m=\u001b[39m val_data_loader\u001b[39m.\u001b[39mload_data()\n\u001b[1;32m      4\u001b[0m test_dataset \u001b[39m=\u001b[39m test_data_loader\u001b[39m.\u001b[39mload_data()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# generate dataset from data_loader object via load_data function\n",
    "train_dataset = train_data_loader.load_data()\n",
    "val_dataset = val_data_loader.load_data()\n",
    "test_dataset = test_data_loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_dataset.take(1):\n",
    "    print(i[0].shape)\n",
    "    print(i[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = i[0][0].numpy()\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(train_dataset=None, val_dataset=None, test_dataset=None):\n",
    "    \"support function to show data\"\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    if train_dataset:\n",
    "        for i, m in train_dataset.take(1):\n",
    "            plt.subplot(2, 3, 1)\n",
    "            plt.imshow(m[0])\n",
    "            plt.subplot(2, 3, 4)\n",
    "            plt.imshow(i[0].numpy())\n",
    "    if val_dataset:\n",
    "        for i, m in val_dataset.take(1):\n",
    "            plt.subplot(2, 3, 2)\n",
    "            plt.imshow(m[0])\n",
    "            plt.subplot(2, 3, 5)\n",
    "            plt.imshow(i[0].numpy())\n",
    "    if test_dataset:\n",
    "        for i, m in test_dataset.take(1):\n",
    "            plt.subplot(2, 3, 3)\n",
    "            plt.imshow(m[0])\n",
    "            plt.subplot(2, 3, 6)\n",
    "            plt.imshow(i[0].numpy())\n",
    "\n",
    "\n",
    "show_data(train_dataset, val_dataset, test_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With augmentation function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is ```albumentations``` function to augement the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_SIZE = data_config[\"image_size\"][0]\n",
    "\n",
    "\n",
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(IM_SIZE, IM_SIZE),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.RandomSizedCrop(min_max_height=(256, 256), height=IM_SIZE, width=IM_SIZE, p=0.5),\n",
    "                A.CenterCrop(height=IM_SIZE, width=IM_SIZE, p=0.5),\n",
    "                A.PadIfNeeded(min_height=IM_SIZE, min_width=IM_SIZE, p=0.5),\n",
    "            ],\n",
    "            p=1,\n",
    "        ),\n",
    "        A.OneOf([A.VerticalFlip(p=0.5), A.RandomRotate90(p=0.5), A.Transpose(p=0.5)]),\n",
    "        A.OneOf([A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.5), A.GridDistortion(p=0.5), A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=1)], p=0.8),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "test_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(IM_SIZE, IM_SIZE),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Transformer``` is a class to use albumentations fucntions or other augmentation packages with tf.data.Dataset.map function effectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_transforms_object = Transformer(aug_config, \"train\", train_transforms)\n",
    "ts_transforms_object = Transformer(aug_config, \"test\", test_transforms)\n",
    "\n",
    "# get datasets with augmentation\n",
    "\n",
    "train_dataset = train_data_loader.load_data(transform_func=tr_transforms_object)\n",
    "val_dataset = val_data_loader.load_data(transform_func=ts_transforms_object)\n",
    "test_dataset = test_data_loader.load_data(transform_func=ts_transforms_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(train_dataset, val_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_dataset.take(1):\n",
    "    print(i[0].shape)\n",
    "    print(i[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = Unet(**model_config).build_model()\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab =DeepLabV3Plus(backbone=\"EfficientNetB0\",input_shape=(512,512,3),output_size=1,final_activation=\"sigmoid\",backbone_outputs_order=[1,-2],filters=256).build_model()\n",
    "keras.utils.plot_model(deeplab,\"deeplab.png\",show_shapes=True)\n",
    "deeplab.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = get_callbacks(callbacks_config)\n",
    "callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_config = dict(model=model_config, data=data_config, trainer=trainer_config)\n",
    "trainer = Trainer(all_config, deeplab, train_dataset, val_dataset, callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(continue_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_dataset.take(1):pass\n",
    "pred = model.predict(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(8):\n",
    "    r  = pred[a]\n",
    "    re = r>0.5\n",
    " \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(i[1][a])\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(re.astype(int))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf_seg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5e709fba4ec28a962ef38eca2f061f4aade275491a1bcbd59d8088c0d7c25f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
