{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XIe2Y2yKV6pN"
      },
      "source": [
        "**Clone Repo**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/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@github/omrylcn/tf_seg/blob/master/tf_seg_runner.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBG7RbAqxJIi",
        "outputId": "2ac8d58a-de9e-43bc-f715-369ed656cecf"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5EzjuyMwy65",
        "outputId": "2f4187cd-0400-4ed5-e982-22ec38ad56cf"
      },
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEJsoXvVV_f-"
      },
      "outputs": [],
      "source": [
        "# generate token, settings --> developer settings-->select repo --> click generate token button "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88j0KkdvFvRa",
        "outputId": "68b1e085-fcce-421a-84e2-f3ba2f73f52c"
      },
      "outputs": [],
      "source": [
        "!git clone https://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@github.com/omrylcn/tf_seg.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMYALwvyguSU",
        "outputId": "319dc838-b974-4d4d-b9b3-7b9df79d6d6b"
      },
      "outputs": [],
      "source": [
        "cd /content/tf_seg"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t8WdCjZuVa2-"
      },
      "source": [
        "**Data Download**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuCLuH_5WM-k"
      },
      "outputs": [],
      "source": [
        "# https://drive.google.com/file/d/1sVm-k9msvbOHc6tq7_eRwAgA-1nmoyek/view?usp=share_link # v5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP7FVX1RVC5c"
      },
      "outputs": [],
      "source": [
        "#file_id = '1ocsXypw_0a-7FR-puoDA5MoYTIm6V59n'  # data_v2\n",
        "# file_id = '1sVm-k9msvbOHc6tq7_eRwAgA-1nmoyek'\n",
        "# file_name = 'data.zip'\n",
        "# folder_name= 'data/v5'\n",
        "\n",
        "# !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate f'https://docs.google.com/uc?export=download&id={file_id}' -O- | sed -rn f's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id={file_id}\" -O '{file_name}' && rm -rf /tmp/cookies.txt\n",
        "\n",
        "!unzip \"{file_name}\" -d data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NKeGWl91Jd71"
      },
      "source": [
        "**Mount Save Path**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RemqZllBJcpH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# %cd  \"/content/drive/MyDrive/colabs/ignis_knowsmoke\"\n",
        "# !ls;\n",
        "save_path = \"/content/drive/MyDrive/colabs/runners\"\n",
        "\n",
        "!ls \"{save_path}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gGiokP8-SIIQ",
        "outputId": "15f61cb8-377e-4420-f9ae-6ca8b62a227f"
      },
      "outputs": [],
      "source": [
        "!pip3 install omegaconf tf2onnx onnxruntime  tensorflow==2.8.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Lu3kSgFuUyS",
        "outputId": "63fd17ee-bfee-4747-90ca-6611d3e470af"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**one_ring**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQGhhQVvIazA",
        "outputId": "f6e14d0c-32e3-4ced-e39a-513ec1b3ec8e"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "import one_ring\n",
        "from one_ring.config import get_config\n",
        "from one_ring.data import get_data_loader,get_camvid_data_loader\n",
        "from one_ring.transformers import Transformer\n",
        "from one_ring.models import Unet,DeepLabV3Plus,AttUnet\n",
        "from one_ring.losses import FocalTverskyLoss, DiceLoss\n",
        "from one_ring.train import Trainer\n",
        "from one_ring.callbacks import get_callbacks\n",
        "\n",
        "# import tf_seg\n",
        "# from tf_seg.config import get_config\n",
        "# from tf_seg.data import get_data_loader,get_camvid_data_loader\n",
        "# from tf_seg.transformers import Transformer\n",
        "# from tf_seg.models import Unet,DeepLabV3Plus,AttUnet\n",
        "# from tf_seg.losses import FocalTverskyLoss,DiceLoss\n",
        "# from tf_seg.metrics import DiceScore\n",
        "# from tf_seg.train import Trainer\n",
        "# from tf_seg.callbacks import get_callbacks\n",
        "\n",
        "\n",
        "print('tensorflow version :',tf.__version__)\n",
        "print('one_ring version :',one_ring.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MLFlow Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = np.random.rand(100, 28, 28, 1)\n",
        "y = np.random.randint(2, size=(100,1))\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlflow.set_experiment(\"test_auto_mlf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlflow.start_run(run_name=\"17\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#mlflow.tensorflow.autolog()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\", loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(X, y, epochs=2,batch_size=32)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with mlflow.start_run(run_name=\"17\",nested=True):\n",
        "  mlflow.log_param(\"epochs\", 48)\n",
        "  model.fit(X, y, epochs=48,batch_size=32,initial_epoch=5)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "h = model.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "with mlflow.start_run(run_name=\"16\",nested=True):\n",
        "    mlflow.log_param(\"epochs\", 53)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "active_run = mlflow.active_run()\n",
        "active_run.info.run_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "last_active_run = mlflow.last_active_run()\n",
        "last_active_run.info.run_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlflow.start_run(last_active_run.info.run_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlflow.end_run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run = mlflow.active_run()\n",
        "run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run = mlflow.last_active_run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#mlflow.create_experiment(\"tf_seg\")\n",
        "mlflow.set_experiment(\"tf_seg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlflow.run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run = mlflow.start_run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlflow.log_param(\"model\", \"Unet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlflow.log_metric(\"dice\", 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "array = np.asarray([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "dataset = mlflow.data.from_numpy(array, source=\"data.csv\")\n",
        "\n",
        "# Log an input dataset used for training\n",
        "#with mlflow.start_run():\n",
        "mlflow.log_input(dataset, context=\"training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        " mlflow.data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### One Ring"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EXL87FlcYN6f"
      },
      "source": [
        "**Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = get_config(config_filename=\"spinal_cord\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data_loader, val_data_loader = get_data_loader(config.data,train_data=True, val_data=True, test_data=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "kOUvtLLRYG02",
        "outputId": "57a97227-62f6-44a6-af55-195f76d1adfb"
      },
      "outputs": [],
      "source": [
        "#train_dataset =  train_data_loader.load_data()\n",
        "#val_dataset =  val_data_loader.load_data()\n",
        "\n",
        "IM_SIZE = config.data[\"image_size\"][0]\n",
        "p=0.3\n",
        "\n",
        "train_transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(IM_SIZE, IM_SIZE),\n",
        "        A.RandomBrightness(limit=0.2),\n",
        "        A.RandomContrast(limit=0.5),\n",
        "    \n",
        "        A.Rotate(limit=30,p=p),\n",
        "        A.RandomSizedCrop(min_max_height=(400, 512), height=IM_SIZE, width=IM_SIZE, p=p),\n",
        "        #A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        #A.RandomBrightness(limit=1)\n",
        "       \n",
        "        #   A.OneOf(\n",
        "        #       [\n",
        "        #           A.RandomSizedCrop(min_max_height=(256, 256), height=IM_SIZE, width=IM_SIZE, p=p),\n",
        "        #           A.CenterCrop(height=IM_SIZE, width=IM_SIZE, p=p),\n",
        "        #           #A.PadIfNeeded(min_height=IM_SIZE, min_width=IM_SIZE, p=p),\n",
        "        #       ],p=1),\n",
        "        # A.OneOf([A.Rotate(limit=45), A.Transpose(p=p)]), # A.VerticalFlip(p=p), \n",
        "        #A.OneOf([A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=p), A.GridDistortion(p=p), A.OpticalDistortion(distort_limit=2, shift_limit=p, p=1)], p=0.8),\n",
        "    ])\n",
        "\n",
        "\n",
        "test_transforms = A.Compose([\n",
        "    A.Resize(IM_SIZE, IM_SIZE),\n",
        "    #A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "tr_transforms_object = Transformer(config.augmentation, \"train\", train_transforms)\n",
        "ts_transforms_object = Transformer(config.augmentation, \"test\", test_transforms)\n",
        "\n",
        "train_dataset = train_data_loader.load_data(transform_func=tr_transforms_object).prefetch(32)\n",
        "val_dataset = val_data_loader.load_data(transform_func=ts_transforms_object,shuffle=False).prefetch(32)\n",
        "\n",
        "for i in train_dataset:\n",
        "     break\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(np.squeeze(i[1][1]))\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(i[0][1].numpy().astype(np.uint8))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ROhs3TJ9Ybg2"
      },
      "source": [
        "**Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYTQeHwYYP5V"
      },
      "outputs": [],
      "source": [
        "# model_config = dict(\n",
        "#     # n_filters=[16, 32, 64, 128, 256],\n",
        "#     n_filters=[4, 8, 12],\n",
        "#     #n_filters=[32,64,128,256,512],  #\n",
        "#     input_shape=[data_config[\"image_size\"][0], data_config[\"image_size\"][1], 3],\n",
        "#     final_activation=\"sigmoid\",\n",
        "#     activation=\"relu\",\n",
        "#     backbone_name= \"EfficientNetB0\",# \"ResNet50\", None\n",
        "#     pretrained=\"imagenet\",\n",
        "#     output_size=1,\n",
        "# )\n",
        "\n",
        "# trainer_config = dict(\n",
        "#     epochs=2,\n",
        "#     #batch_size=batch_size,\n",
        "#     optimizer={\"name\": \"adam\", \"params\": {\"learning_rate\": 0.0005}},\n",
        "#     losses=[\"dice_loss\"],\n",
        "#     metrics=[\"dice_score\"],\n",
        "#     save_model=True,\n",
        "#     save_path=\"unet_efficientnetb2_ignis_area\",\n",
        "#     verbose=1,\n",
        "#     deploy_onnx=True\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us2bVubQYgMb",
        "outputId": "32fd6867-2f5c-43b4-925e-c498274f668f"
      },
      "outputs": [],
      "source": [
        "model = AttUnet(**config.model).build_model()\n",
        "# model = Unet(**model_config).build_model()\n",
        "# model =DeepLabV3Plus(backbone_name=\"EfficientNetV2B3\",input_shape=(512,512,3),output_size=1,final_activation=\"sigmoid\",backbone_outputs_order=[1,-2],filters=256).build_model()\n",
        "\n",
        "# model.summary()\n",
        "#keras.utils.plot_model(model,\"deeplab.png\",show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "callbacks = get_callbacks(config.callbacks)\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch %50 == 0:\n",
        "        k = epoch//50\n",
        "        lr = lr-(lr*k*0.2)\n",
        "        return lr\n",
        "    else:  \n",
        "        return lr\n",
        "# Learning Rate\n",
        "total_steps = len(train_dataset)*config.trainer[\"epochs\"]\n",
        "decay_steps = total_steps * 0.5\n",
        "\n",
        "cosine_decay_scheduler = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate = config.trainer[\"optimizer\"][\"params\"][\"learning_rate\"],\n",
        "    decay_steps = decay_steps,\n",
        "    alpha=0.1\n",
        ")\n",
        "\n",
        "callbacks[\"lr_sch\"]= tf.keras.callbacks.LearningRateScheduler(cosine_decay_scheduler)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHNbNMRGYfex",
        "outputId": "3b92c070-507c-4134-a73f-aebf090b9199"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(callbacks.keys())\n",
        "# callbacks = list(callbacks.values())\n",
        "# configs = dict(model=model_config, data=data_config, trainer=trainer_config)\n",
        "# trainer = Trainer(configs, model, train_dataset, val_dataset, callbacks=callbacks)\n",
        "trainer = Trainer(config, model, train_dataset, val_dataset, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#trainer.compile_model()\n",
        "trainer.fit(continue_training=True)\n",
        "model = trainer._model\n",
        "#model.fit(train_dataset, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "model.evaluat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.evaluate(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = trainer.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history['loss'],label=\"loss\")\n",
        "plt.plot(history['val_loss'],label=\"val_loss\")\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history['dice_score'],label=\"dice_score\")\n",
        "plt.plot(history['val_dice_score'],label=\"val_dice_score\")\n",
        "plt.grid()\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save(path=\"effo/\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model.save_weights(\"model_weights\")\n",
        "#model.load_weights(\"model_weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from one_ring.utils import generate_overlay_image,calculate_confusion_matrix_and_report\n",
        "#from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# alpha = 0.6\n",
        "# threshold = 0.7\n",
        "\n",
        "# image = cv2.imread(\"data/spinal_primal/val_images/16_8.2020_A.png\")\n",
        "# target = cv2.imread(\"data/spinal_primal/val_masks/16_8.2020_A.png\",0)\n",
        "\n",
        "\n",
        "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "# image = cv2.resize(image,(512,512))\n",
        "# input_data = np.expand_dims(image, axis=0)\n",
        "# input_data = input_data.astype(np.float32)\n",
        "# pred_logit = model(input_data).numpy()[0]\n",
        "# pred_value = np.where(pred_logit > threshold, 1, 0)\n",
        "# pred_image = (pred_value * 255).astype(np.uint8)\n",
        "\n",
        "\n",
        "# overlay = generate_overlay_image(pred_image, image, alpha=0.3)\n",
        "\n",
        "# calculate_confusion_matrix_and_report(pred_value, target)\n",
        "\n",
        "# plt.imshow(overlay)\n",
        "# plt.grid(True)\n",
        "# plt.imshow(image)\n",
        "# plt.imshow(pred_mask)\n",
        "# plt.imshow(colored_pred_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "threshold = 0.6\n",
        "for i in val_dataset:\n",
        "    pred_logits = model.predict(i[0])\n",
        "\n",
        "\n",
        "\n",
        "    for n in range(len(i[0])): \n",
        "        image = i[0][n].numpy().astype(np.uint8)\n",
        "        pred_logit = pred_logits[n]\n",
        "     #   print(pred_logit.shape)\n",
        "        pred_value = np.where(pred_logit>threshold,1,0).reshape(512,512,1)\n",
        "        pred_mask = (pred_value*255).astype(np.uint8)\n",
        "\n",
        "    #    print(pred_mask.shape, image.shape)\n",
        "        overlay = generate_overlay_image(pred_mask, image, alpha=0.3)\n",
        "        target = i[1][n].numpy()\n",
        "        np.unique(target,return_counts=True)    \n",
        "\n",
        "        plt.figure(figsize=(10,10))\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.imshow(pred_value)\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.imshow(overlay)\n",
        "        plt.show()\n",
        "        \n",
        "\n",
        "        #print(pred_value.shape, target.shape)\n",
        "\n",
        "        cm,cr = calculate_confusion_matrix_and_report(pred_value, target)\n",
        "        print(cm)\n",
        "        print(cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.evaluate(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def iou_coef(y_true, y_pred, smooth=1e-6):\n",
        "    \"\"\"\n",
        "    Compute the Intersection over Union (Jaccard Index) between the predicted and true masks.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : tf.Tensor\n",
        "        The ground truth mask.\n",
        "    y_pred : tf.Tensor\n",
        "        The predicted mask.\n",
        "    smooth : float\n",
        "        A small value to avoid division by zero.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    tf.Tensor\n",
        "        The IoU score as a tensor.\n",
        "    \"\"\"\n",
        "    y_true = tf.cast(y_true > 0.5, tf.float32)\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
        "    iou = (intersection + smooth) / (union + smooth)\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s.from_predictions()a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def confusion_matrix(target,pred):\n",
        "  \n",
        "    target = target.flatten()\n",
        "    pred = pred.flatten()\n",
        "    tn = np.sum((target == 0) & (pred == 0))\n",
        "    fp = np.sum((target == 0) & (pred == 1))\n",
        "    fn = np.sum((target == 1) & (pred == 0))\n",
        "    tp = np.sum((target == 1) & (pred == 1))\n",
        "    return tn,fp,fn,tp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_overaly_image(pred_mask, input_image, alpha=0.5):\n",
        "\n",
        "    image = input_image.numpy().astype(np.uint8)\n",
        "    pred_mask = pred_mask.astype(np.uint8)\n",
        "    pred_mask = np.where(pred_mask>0.5, 255, 0).reshape(shape[0], shape[1]).astype(np.uint8)\n",
        "    #colored_pred_mask = cv2.merge((pred_mask, pred_mask, pred_mask)).astype(np.uint8)\n",
        "    #masked = cv2.bitwise_and(target, target, mask=pred_mask)\n",
        "    overlay = cv2.addWeighted(image, 0.50, colored_pred_mask, 0.50, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dice_score(y_true, y_pred):\n",
        "    y_true_f = y_true.flatten() \n",
        "    y_pred_f = y_pred.flatten()\n",
        "    intersection = np.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1) / (np.sum(y_true_f) + np.sum(y_pred_f) + 1)\n",
        "\n",
        "def jaccard_index(y_true, y_pred):\n",
        "    intersection = np.logical_and(y_true, y_pred)\n",
        "    union = np.logical_or(y_true, y_pred)\n",
        "    jaccard_index = np.sum(intersection) / np.sum(union)\n",
        "    return jaccard_index\n",
        "\n",
        "\n",
        "def plot_results(input_data, target, pred,n, p=0.5):\n",
        "    shape = target.shape\n",
        "    target = target.reshape((shape[0], shape[1]))\n",
        "    shape = pred.shape\n",
        "    pred = pred.reshape((shape[0], shape[1])) > 0.5\n",
        "    pred = pred.astype(int)\n",
        "\n",
        "    pred_flat = pred.flatten()\n",
        "    target_flat = target.flatten()\n",
        "#    cm = confusion_matrix(target_flat, pred_flat)\n",
        "\n",
        "    image = input_data.numpy().astype(np.uint8)\n",
        "    pred_mask = pred.astype(np.uint8)\n",
        "    pred_mask = np.where(pred_mask>0.5, 255, 0).reshape(shape[0], shape[1]).astype(np.uint8)\n",
        "    colored_pred_mask = cv2.merge((pred_mask, pred_mask, pred_mask)).astype(np.uint8)\n",
        "    masked = cv2.bitwise_and(target, target, mask=pred_mask)\n",
        "    overlay = cv2.addWeighted(image, 0.50, colored_pred_mask, 0.50, 0)\n",
        "    \n",
        " #   dice = dice_score(target, pred)\n",
        "    #print('Dice score:', dice)\n",
        "  #  jaccard = jaccard_index(target,pred)\n",
        "    #print('Jaccard index:',jaccard)\n",
        "    print(f'Target Image\\nDice Score: {dice:.2f} Jaccard Index: {jaccard:.2f}')\n",
        "    \n",
        "    fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(40,10))\n",
        "    axs[0].imshow(target)\n",
        "    axs[0].set_title('Real Region')\n",
        "    axs[0].grid(alpha=0.3)\n",
        "    axs[1].imshow(masked)\n",
        "    axs[1].set_title('Predicted Region')\n",
        "    axs[1].grid(alpha=0.3)\n",
        "    axs[2].imshow(overlay)\n",
        "    axs[2].set_title('Overlay Image')\n",
        "    axs[2].grid(alpha=0.3)\n",
        "   # sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm', ax=axs[3])\n",
        "    axs[3].set_title(f'Dice Score: {dice:.2f}| Jaccard Index: {jaccard:.2f}')\n",
        "    axs[3].set_xlabel('Predicted')\n",
        "    axs[3].set_ylabel('True')\n",
        "    plt.savefig(f'image_{n}.jpeg')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import albumentations as A\n",
        "\n",
        "# Define Albumentations transform\n",
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# transform_params = transform.to_dict()\n",
        "\n",
        "# Save transform parameters\n",
        "# with open('transform_params.json', 'w') as f:\n",
        "#     json.dump(transform_params, f)\n",
        "\n",
        "# import albumentations as A\n",
        "\n",
        "# def get_transform_instance(transform):\n",
        "#     classname = transform.pop(\"__class_fullname__\")\n",
        "#     if hasattr(A, classname):\n",
        "#         TransformClass = getattr(A, classname)\n",
        "#         instance = TransformClass(**transform)\n",
        "#         return instance\n",
        "#     else:\n",
        "#         raise ValueError(f\"Invalid class name: {classname}\")\n",
        "\n",
        "# def get_transform_from_config(config):\n",
        "#     transform_config = config[\"transform\"]\n",
        "#     transform_classname = transform_config[\"__class_fullname__\"]\n",
        "\n",
        "#     # Get a list of transform instances\n",
        "#     transforms = transform_config[\"transforms\"]\n",
        "#     transform_instances = [get_transform_instance(t) for t in transforms]\n",
        "\n",
        "#     # Get the Compose class and create an instance\n",
        "#     if hasattr(A, transform_classname):\n",
        "#         ComposeClass = getattr(A, transform_classname)\n",
        "#         composed_transform = ComposeClass(transform_instances)\n",
        "#         return composed_transform\n",
        "#     else:\n",
        "#         raise ValueError(f\"Invalid class name: {transform_classname}\")\n",
        "\n",
        "# # Now use the function to get the transform\n",
        "# composed_transform = get_transform_from_config(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Extract transform parameters\n",
        "transform_params = {\n",
        "    'HorizontalFlip': {'p': 0.5},\n",
        "    'RandomBrightnessContrast': {'p': 0.2},\n",
        "}\n",
        "\n",
        "# Save transform parameters\n",
        "with open('transform_params.json', 'w') as f:\n",
        "    json.dump(transform_params, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR5jjr4cww7t",
        "outputId": "15da21d5-947a-41c6-f5cf-7327fe9559a8"
      },
      "outputs": [],
      "source": [
        "trainer.train(continue_training=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.evaluate(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.evaluate(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gagcp6gHJNz",
        "outputId": "639792fc-ea73-4e16-b43d-deccde60c514"
      },
      "outputs": [],
      "source": [
        "for i in val_dataset:\n",
        "    break\n",
        "\n",
        "i[0][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ0rsZq5HZN0",
        "outputId": "4ef79aa0-1c9f-493b-a795-2f110cbf9b35"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAEpXam39pBc",
        "outputId": "54b5e3cb-e234-454d-975e-f4e89fead5f4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model.evaluate(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9bPoM0y-NoH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77h3vFAo-OVT",
        "outputId": "f81e85a8-c7bc-4ce4-d2d9-801c40e6dfcb"
      },
      "outputs": [],
      "source": [
        "trainer.history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1T1hRjlQ-OMq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbryLV7n-Nzz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
