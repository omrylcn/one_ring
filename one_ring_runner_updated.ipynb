{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQGhhQVvIazA",
        "outputId": "f6e14d0c-32e3-4ced-e39a-513ec1b3ec8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "tensorflow version : 2.15.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/yesili/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mlflow\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,backend as K\n",
        "from tensorflow.keras.metrics import Recall,Precision\n",
        "import  tensorflow_addons as tfa\n",
        "import logging\n",
        "\n",
        "import one_ring\n",
        "from one_ring.config import get_config\n",
        "# from one_ring.data import get_data_loader,get_camvid_data_loader\n",
        "from one_ring.transformers import Transformer\n",
        "from one_ring.models import Unet,DeepLabV3Plus,AttUnet\n",
        "from one_ring.losses import FocalTverskyLoss, DiceLoss,BASNetHybridLoss,JaccardLoss,LogCoshDiceLoss,ComboLoss,BoundaryDoULoss\n",
        "from one_ring.train import Trainer\n",
        "from one_ring.callbacks import get_callbacks\n",
        "from one_ring.losses import FocalTverskyLoss, DiceLoss,LogCoshDiceLoss,binary_focal_loss,categorical_focal_loss,FocalLoss,sym_unified_focal_loss,SymmetricUnifiedFocalLoss\n",
        "from one_ring.metrics import DiceScore,JaccardScore\n",
        "from one_ring.callbacks import ORLearningRateCallback\n",
        "from one_ring.scheduler import ORLearningRateScheduler\n",
        "from one_ring.utils import generate_overlay_image,calculate_confusion_matrix_and_report,plot_history_dict\n",
        "\n",
        "print('tensorflow version :',tf.__version__)\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"always\")\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = get_config(config_filename=\"multi_class\")\n",
        "# cfg = config[\"augmentation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "IM_SIZE = config.model.input_shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "ename": "ConfigAttributeError",
          "evalue": "Missing key augmentation\n    full_key: augmentation\n    object_type=dict",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConfigAttributeError\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 34\u001b[0m\n\u001b[1;32m     14\u001b[0m train_transforms \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mCompose(\n\u001b[1;32m     15\u001b[0m     [\n\u001b[1;32m     16\u001b[0m         A\u001b[38;5;241m.\u001b[39mResize(IM_SIZE, IM_SIZE),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     ]\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m test_transforms \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mCompose(\n\u001b[1;32m     28\u001b[0m     [\n\u001b[1;32m     29\u001b[0m         A\u001b[38;5;241m.\u001b[39mResize(IM_SIZE, IM_SIZE),\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;66;03m# A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     ]\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 34\u001b[0m tr_transforms_object \u001b[38;5;241m=\u001b[39m Transformer(\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugmentation\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_transforms)\u001b[38;5;66;03m#.from_dict()\u001b[39;00m\n\u001b[1;32m     35\u001b[0m ts_transforms_object \u001b[38;5;241m=\u001b[39m Transformer(config\u001b[38;5;241m.\u001b[39maugmentation, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_transforms)\u001b[38;5;66;03m#.from_dict()\u001b[39;00m\n\u001b[1;32m     36\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_data_loader\u001b[38;5;241m.\u001b[39mload_data(transform_func\u001b[38;5;241m=\u001b[39mtr_transforms_object)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/omegaconf/dictconfig.py:355\u001b[0m, in \u001b[0;36mDictConfig.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_impl(\n\u001b[1;32m    352\u001b[0m         key\u001b[38;5;241m=\u001b[39mkey, default_value\u001b[38;5;241m=\u001b[39m_DEFAULT_MARKER_, validate_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    353\u001b[0m     )\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConfigKeyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_and_raise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConfigAttributeError\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_and_raise(key\u001b[38;5;241m=\u001b[39mkey, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cause\u001b[38;5;241m=\u001b[39me)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/omegaconf/base.py:231\u001b[0m, in \u001b[0;36mNode._format_and_raise\u001b[0;34m(self, key, value, cause, msg, type_override)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_and_raise\u001b[39m(\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    225\u001b[0m     key: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m     type_override: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    230\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     \u001b[43mformat_and_raise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcause\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtype_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_override\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/omegaconf/_utils.py:899\u001b[0m, in \u001b[0;36mformat_and_raise\u001b[0;34m(node, key, value, msg, cause, type_override)\u001b[0m\n\u001b[1;32m    896\u001b[0m     ex\u001b[38;5;241m.\u001b[39mref_type \u001b[38;5;241m=\u001b[39m ref_type\n\u001b[1;32m    897\u001b[0m     ex\u001b[38;5;241m.\u001b[39mref_type_str \u001b[38;5;241m=\u001b[39m ref_type_str\n\u001b[0;32m--> 899\u001b[0m \u001b[43m_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/omegaconf/_utils.py:797\u001b[0m, in \u001b[0;36m_raise\u001b[0;34m(ex, cause)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    796\u001b[0m     ex\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 797\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/omegaconf/dictconfig.py:351\u001b[0m, in \u001b[0;36mDictConfig.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m()\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_DEFAULT_MARKER_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConfigKeyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_and_raise(\n\u001b[1;32m    356\u001b[0m         key\u001b[38;5;241m=\u001b[39mkey, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cause\u001b[38;5;241m=\u001b[39me, type_override\u001b[38;5;241m=\u001b[39mConfigAttributeError\n\u001b[1;32m    357\u001b[0m     )\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/omegaconf/dictconfig.py:442\u001b[0m, in \u001b[0;36mDictConfig._get_impl\u001b[0;34m(self, key, default_value, validate_key)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_impl\u001b[39m(\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m, key: DictKeyType, default_value: Any, validate_key: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    440\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m         node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_child\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthrow_on_missing_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_key\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (ConfigAttributeError, ConfigKeyError):\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m default_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _DEFAULT_MARKER_:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/omegaconf/basecontainer.py:73\u001b[0m, in \u001b[0;36mBaseContainer._get_child\u001b[0;34m(self, key, validate_access, validate_key, throw_on_missing_value, throw_on_missing_key)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_child\u001b[39m(\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     66\u001b[0m     key: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     throw_on_missing_key: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     71\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Optional[Node], List[Optional[Node]]]:\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Like _get_node, passing through to the nearest concrete Node.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     child \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthrow_on_missing_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_on_missing_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthrow_on_missing_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_on_missing_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child, UnionNode) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_special(child):\n\u001b[1;32m     81\u001b[0m         value \u001b[38;5;241m=\u001b[39m child\u001b[38;5;241m.\u001b[39m_value()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/omegaconf/dictconfig.py:480\u001b[0m, in \u001b[0;36mDictConfig._get_node\u001b[0;34m(self, key, validate_access, validate_key, throw_on_missing_value, throw_on_missing_key)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m throw_on_missing_key:\n\u001b[0;32m--> 480\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConfigKeyError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m throw_on_missing_value \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39m_is_missing():\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingMandatoryValue(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing mandatory value: $KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mConfigAttributeError\u001b[0m: Missing key augmentation\n    full_key: augmentation\n    object_type=dict"
          ]
        }
      ],
      "source": [
        "\n",
        "config = get_config(config_filename=\"multi_class\")\n",
        "# train_data_loader, val_data_loader = get_data_loader(config.data, train_data=True, val_data=True, test_data=False)\n",
        "\n",
        "\n",
        "# IM_SIZE = config.data[\"image_size\"][0]\n",
        "aug_config = {\n",
        "    \"aug_prob\": 0.1,\n",
        "    #\"random_contrast_limit\": 0.4,\n",
        "    #\"random_brightness_limit\": 0.3,\n",
        "    \"rotate_limit\": 10,\n",
        "}\n",
        "tracing_object = {\"mlflow\":{\"augmentation\":aug_config}}\n",
        "\n",
        "train_transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(IM_SIZE, IM_SIZE),\n",
        "        #A.GaussNoise(var_limit=(10.0, 50.0), p=aug_config[\"aug_prob\"]),\n",
        "        #A.CLAHE(p=aug_config[\"aug_prob\"]),\n",
        "       # A.RandomBrightnessContrast(p=aug_config[\"aug_prob\"], brightness_limit=aug_config[\"random_brightness_limit\"], contrast_limit=aug_config[\"random_contrast_limit\"]),\n",
        "       # A.RandomGamma(p=aug_config[\"aug_prob\"]),\n",
        "        A.HorizontalFlip(p=aug_config[\"aug_prob\"]),\n",
        "        A.VerticalFlip(p=aug_config[\"aug_prob\"]),\n",
        "        A.Rotate(limit=aug_config[\"rotate_limit\"], p=aug_config[\"aug_prob\"]),\n",
        "        A.RandomSizedCrop(min_max_height=(180, 224), height=IM_SIZE, width=IM_SIZE, p=aug_config[\"aug_prob\"]),\n",
        "    ]\n",
        ")\n",
        "test_transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(IM_SIZE, IM_SIZE),\n",
        "        # A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]\n",
        ")\n",
        "\n",
        "tr_transforms_object = Transformer(config.augmentation, \"train\", train_transforms)#.from_dict()\n",
        "ts_transforms_object = Transformer(config.augmentation, \"test\", test_transforms)#.from_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_DIR = \"dataset/spinal_sample_v3/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(img, mask):\n",
        "    img = tf.io.read_file(img)\n",
        "    img = tf.io.decode_png(img)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, (224, 224))\n",
        "\n",
        "    mask = tf.io.read_file(mask)\n",
        "    mask = tf.io.decode_png(mask)\n",
        "    one_hot_map = []\n",
        "    for colour in [(255, 255, 255)]:\n",
        "        eq = tf.equal(mask, colour)\n",
        "        class_map = tf.reduce_all(eq, axis=-1)\n",
        "        one_hot_map.append(class_map)\n",
        "    mask = tf.stack(one_hot_map, axis=-1)\n",
        "    mask = tf.cast(mask, tf.float32)\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "for img_path, mask_path in zip(glob(os.path.join(DATA_DIR, \"train_images\", \"*\")), glob(os.path.join(DATA_DIR, \"train_masks\", \"*\"))):\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'resize'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tf\u001b[38;5;241m.\u001b[39munique(\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
            "File \u001b[0;32m~/miniconda3/envs/ring/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py:261\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mravel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    254\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    255\u001b[0m   \u001b[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    257\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124m    If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124m    tf.experimental.numpy.experimental_enable_numpy_behavior()\u001b[39m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'resize'"
          ]
        }
      ],
      "source": [
        "tf.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#callbacks = get_callbacks(config.callbacks)\n",
        "callbacks = {}\n",
        "\n",
        "steps_per_epoch = len(train_dataset)\n",
        "lr_schedule = ORLearningRateScheduler(\n",
        "    strategy=config.train.lr_scheduler[\"name\"],\n",
        "    total_epochs=config.train.epochs,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    **config.train.lr_scheduler[\"params\"]\n",
        ").get()\n",
        "callbacks[\"lr_sch\"] = ORLearningRateCallback(lr_schedule)\n",
        "\n",
        "save_object = {\n",
        "    \"transformer\":{\n",
        "        \"train\":tr_transforms_object.to_dict(),\n",
        "        \"val\": ts_transforms_object.to_dict()\n",
        "    }\n",
        "}\n",
        "\n",
        "log_dir = f\"board_logs/{config.train.experiment_name}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "callbacks[\"tensorboard\"] = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_images=True, write_graph=True, update_freq='epoch')#, profile_batch='500,520')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_name = \"boundary_dou_loss\"\n",
        "params = {\n",
        "    \"gamma\": 4/3,\n",
        "    \"alpha\": 0.4,\n",
        "    \"loss_weight\": 0.4\n",
        "}\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "loss_dict = {\n",
        "    \"focal_loss\": FocalLoss,\n",
        "    \"dice_loss\": DiceLoss,\n",
        "    \"jaccard_loss\": JaccardLoss,\n",
        "    \"log_cosh_dice_loss\": LogCoshDiceLoss,\n",
        "    \"focal_tversky_loss\": FocalTverskyLoss,\n",
        "    \"symmetric_unified_focal_loss\": SymmetricUnifiedFocalLoss,\n",
        "    \"boundary_dou_loss\": BoundaryDoULoss\n",
        "}\n",
        "\n",
        "metrics_dict= {\n",
        "    \"recal\":Recall,\n",
        "    \"precision\":Precision,\n",
        "    \"jaccard_score\":JaccardScore\n",
        "}\n",
        "\n",
        "loss = loss_dict[loss_name](**params)\n",
        "metrics = [m() for m in metrics_dict.values()]\n",
        "callbacks = list(callbacks.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tuvis/tff/tf_seg/one_ring/logger.py:37: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/tuvis/tff/tf_seg/logs/trainer_log.log' mode='a' encoding='UTF-8'>\n",
            "  logger.handlers = []\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        }
      ],
      "source": [
        "#model = AttUnet(**config.model).build_model()\n",
        "model = DeepLabV3Plus(**config.model).build_model()\n",
        "#model = Unet(**config.model).build_model()\n",
        "\n",
        "#model.summary()\n",
        "#keras.utils.plot_model(model, show_shapes=True, to_file=f'{model.name}_model.png')\n",
        "trainer = Trainer(config, model, train_dataset, val_dataset, callbacks=liscallbacks, metrics=metrics,loss=loss,save_object=save_object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   0%|          | 0/49 [00:00<?, ?it/s]2024-09-09 01:49:33.015922: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inDeepLabV3Plus/EfficientNetB0_backbone/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
            "2024-09-09 01:49:34.355633: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
            "2024-09-09 01:49:34.416185: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
            "2024-09-09 01:49:35.449461: I external/local_xla/xla/service/service.cc:168] XLA service 0x7823b45dcea0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2024-09-09 01:49:35.449518: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
            "2024-09-09 01:49:35.455341: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1725835775.536720  326899 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "2024-09-09 01:49:53,472 - one_ring - INFO - Epoch 1 - New best model found with validation loss: 0.9821\n",
            "2024-09-09 01:49:53,474 - one_ring - INFO - Epoch 1/4 - 29.41s - loss: 0.9724 - recall: 0.9141 - precision: 0.1519 - jaccard_score: 0.2575 - dice_score: 0.3704 - val_loss: 0.9821 - val_recall: 0.9994 - val_precision: 0.3433 - val_jaccard_score: 0.3238 - val_dice_score: 0.4830\n",
            "2024-09-09 01:49:56,706 - one_ring - INFO - Epoch 2 - New best model found with validation loss: 0.9626\n",
            "2024-09-09 01:49:56,709 - one_ring - INFO - Epoch 2/4 - 3.23s - loss: 0.9091 - recall: 0.9768 - precision: 0.6448 - jaccard_score: 0.6237 - dice_score: 0.7543 - val_loss: 0.9626 - val_recall: 0.9327 - val_precision: 0.7525 - val_jaccard_score: 0.6841 - val_dice_score: 0.8087\n",
            "2024-09-09 01:49:59,845 - one_ring - INFO - Epoch 3 - New best model found with validation loss: 0.8705\n",
            "2024-09-09 01:49:59,847 - one_ring - INFO - Epoch 3/4 - 3.14s - loss: 0.7561 - recall: 0.9357 - precision: 0.8392 - jaccard_score: 0.7771 - dice_score: 0.8674 - val_loss: 0.8705 - val_recall: 0.8883 - val_precision: 0.8897 - val_jaccard_score: 0.7789 - val_dice_score: 0.8731\n",
            "2024-09-09 01:50:03,021 - one_ring - INFO - Epoch 4 - New best model found with validation loss: 0.6120\n",
            "2024-09-09 01:50:03,068 - one_ring - INFO - Epoch 4/4 - 3.22s - loss: 0.5240 - recall: 0.9249 - precision: 0.9072 - jaccard_score: 0.8360 - dice_score: 0.9086 - val_loss: 0.6120 - val_recall: 0.7836 - val_precision: 0.9846 - val_jaccard_score: 0.7540 - val_dice_score: 0.8526\n"
          ]
        }
      ],
      "source": [
        "# #trainer.compile()\n",
        "# print(trainer.loss)\n",
        "# print(trainer.optimizer)\n",
        "# print(trainer.callbacks)\n",
        "# print(trainer.metrics)\n",
        "history = trainer.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-09 01:50:07,711 - one_ring - INFO - Restored best model weights.\n",
            "2024-09-09 01:50:20,883 - one_ring - INFO - Saved TensorFlow model to models/20240909014923/saved_model\n",
            "INFO:one_ring:Saved TensorFlow model to models/20240909014923/saved_model\n",
            "2024-09-09 01:50:20,891 - one_ring - INFO - Saved metadata to models/20240909014923/meta_data\n",
            "INFO:one_ring:Saved metadata to models/20240909014923/meta_data\n",
            "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
            "2024-09-09 01:50:21.939926: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-09-09 01:50:21.940030: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "2024-09-09 01:50:21.940089: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2024-09-09 01:50:21.940384: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-09-09 01:50:21.940637: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-09-09 01:50:21.940742: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-09-09 01:50:21.940878: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-09-09 01:50:21.940980: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-09-09 01:50:21.941045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6027 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
            "2024-09-09 01:50:22.613238: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-09-09 01:50:22.613478: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-09-09 01:50:22.613598: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-09-09 01:50:22.613742: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-09-09 01:50:22.613852: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-09-09 01:50:22.613921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6027 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
            "2024-09-09 01:50:22.702311: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-09-09 01:50:22.702417: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "2024-09-09 01:50:22.702518: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2024-09-09 01:50:22.702790: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-09-09 01:50:22.702938: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-09-09 01:50:22.703038: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-09-09 01:50:22.703166: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-09-09 01:50:22.703266: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-09-09 01:50:22.703330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6027 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
            "2024-09-09 01:50:25,096 - one_ring - INFO - Saved ONNX model to models/20240909014923/onnx/model.onnx\n",
            "INFO:one_ring:Saved ONNX model to models/20240909014923/onnx/model.onnx\n",
            "2024-09-09 01:50:25,690 - one_ring - INFO - Model and comprehensive metadata saved to models/20240909014923\n",
            "INFO:one_ring:Model and comprehensive metadata saved to models/20240909014923\n",
            "2024-09-09 01:50:25,724 - one_ring - INFO - Finished model training\n",
            "INFO:one_ring:Finished model training\n"
          ]
        }
      ],
      "source": [
        "trainer.finalize_training()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#trainer.load(trainer.save_path,setup_components=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = trainer.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_binary_differece(target, pred):\n",
        "    # Calculate differences\n",
        "    tp = (pred == 1) & (target == 1)  # True Positives\n",
        "    fp = (pred == 1) & (target == 0)  # False Positives\n",
        "    fn = (pred == 0) & (target == 1)  # False Negatives\n",
        "\n",
        "    # Create an RGB image where each difference is colored differently\n",
        "    # Initialize with zeros (black) for the background\n",
        "    diff_image = np.zeros(target.shape + (3,), dtype=np.uint8)\n",
        "\n",
        "    # Assign colors (R, G, B)\n",
        "    # True Positives in green\n",
        "    diff_image[tp] = [0, 255, 0]\n",
        "    # False Positives in red\n",
        "    diff_image[fp] = [255, 0, 0]\n",
        "    # False Negatives in blue\n",
        "    diff_image[fn] = [0, 0, 255]\n",
        "\n",
        "    diff_image_corrected = np.squeeze(diff_image, axis=2)\n",
        "\n",
        "    return diff_image_corrected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "threshold = 0.6\n",
        "for i in val_dataset:\n",
        "    pred_logits = model.predict(i[0])\n",
        "\n",
        "    for n in range(len(i[0])): \n",
        "        image = i[0][n].numpy().astype(np.uint8)\n",
        "        pred_logit = pred_logits[n]\n",
        "     #   print(pred_logit.shape)\n",
        "        pred_value = np.where(pred_logit>threshold,1,0).reshape(224,224,1)\n",
        "        pred_mask = (pred_value*255).astype(np.uint8)\n",
        "\n",
        "    #    print(pred_mask.shape, image.shape)\n",
        "        overlay = generate_overlay_image(pred_mask, image, alpha=0.3)\n",
        "        target = i[1][n].numpy()\n",
        "        np.unique(target,return_counts=True)    \n",
        "\n",
        "        plt.figure(figsize=(20,10))\n",
        "        plt.subplot(1,3,1)\n",
        "        plt.title('target')\n",
        "        plt.imshow(target)\n",
        "        plt.grid(True)\n",
        "        plt.subplot(1,3,2)\n",
        "        plt.title('pred')\n",
        "        plt.imshow(pred_value)\n",
        "        plt.grid(True)\n",
        "        plt.subplot(1,3,3)\n",
        "        plt.imshow(overlay)\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "        #print(pred_value.shape, target.shape)\n",
        "\n",
        "        cm,cr = calculate_confusion_matrix_and_report(pred_value, target)\n",
        "        print(cm)\n",
        "        print(cr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy = tf.keras.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target = i[1][n]\n",
        "pred_logit.shape,target.shape\n",
        "\n",
        "a = accuracy(tf.squeeze(target),tf.squeeze(pred_logit))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss = DiceLoss()\n",
        "from one_ring.losses import dice_coef"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_value = (pred_logit>0.5).astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dice_coef(target,pred_logit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dice_coef(target,pred_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove dimension\n",
        "tf.squeeze(target).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inferencer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "import logging\n",
        "import hashlib\n",
        "from functools import lru_cache\n",
        "from typing import Dict, Union, Optional, List, Tuple, Any\n",
        "\n",
        "import numpy as np\n",
        "from omegaconf import DictConfig, ListConfig\n",
        "import matplotlib.pyplot as plt \n",
        "import cv2\n",
        "\n",
        "from one_ring.deploy.inferencer import Inferencer\n",
        "\n",
        "# from one_ring.utils import TensorLike\n",
        "# from one_ring.config import MODEL_TYPE_LIB\n",
        "# from one_ring.transformers import normalize\n",
        "# from one_ring.deploy import model_wrapper_lib,preprocessor_lib,postprocessor_lib\n",
        "# from one_ring.deploy.processing import VanillaPostprocessor\n",
        "\n",
        "# import json\n",
        "# import yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\n",
        "    #\"image_size\": [224, 224, 3],\n",
        "    \"model_type\": \"onnx\",\n",
        "    \"model_path\": \"models/20240909002117\",\n",
        "    \"preprocessor_type\": \"albumentations\",\n",
        "    \"postprocessor_type\": \"vanilla\",\n",
        "    \"device\": \"cpu\",\n",
        "    \"threshold\":0.6\n",
        "}\n",
        "\n",
        "\n",
        "inferencer = Inferencer(config, cache_size=256, log_level=\"INFO\")\n",
        "#inferencer.load_processor(\"preprocessor\")\n",
        "\n",
        "# inferencer.preprocessor = preprocessor\n",
        "# inferencer.postprocessor = postprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_path = \"examples/test_images/road_2.jpg\"\n",
        "image = plt.imread(image_path)\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "res = inferencer(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = inferencer.preprocessor.transform(image=image)[\"image\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imshow(res[1][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sequence Exp"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
